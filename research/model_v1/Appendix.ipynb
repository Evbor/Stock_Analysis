{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Investigating Slice Layer Bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must have preprocessing component ran and the DataFrame saved to disk, of the main notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries and Configuring virtual GPU\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fractions import Fraction\n",
    "from functools import reduce\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "visible_gpus = tf.config.experimental.get_visible_devices('GPU')\n",
    "print('GPUs: {}'.format(gpus))\n",
    "print('Visible GPUs: {}'.format(visible_gpus))\n",
    "\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7000)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Setting Random Seed\n",
    "seed = 15\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataFrame:\n",
      "    numbers letters\n",
      "25       26       z\n",
      "24       25       y\n",
      "23       24       x\n",
      "22       23       w\n",
      "21       22       v\n",
      "20       21       u\n",
      "19       20       t\n",
      "18       19       s\n",
      "17       18       r\n",
      "16       17       q\n",
      "15       16       p\n",
      "14       15       o\n",
      "13       14       n\n",
      "12       13       m\n",
      "11       12       l\n",
      "10       11       k\n",
      "9        10       j\n",
      "8         9       i\n",
      "7         8       h\n",
      "6         7       g\n",
      "5         6       f\n",
      "4         5       e\n",
      "3         4       d\n",
      "2         3       c\n",
      "1         2       b\n",
      "0         1       a\n",
      "\n",
      "Time Series DataFrame with a window size of n_trail+1\n",
      "    numbers(t-5) letters(t-5)  numbers(t-4) letters(t-4)  numbers(t-3)  \\\n",
      "24          20.0            t          21.0            u          22.0   \n",
      "23          19.0            s          20.0            t          21.0   \n",
      "22          18.0            r          19.0            s          20.0   \n",
      "21          17.0            q          18.0            r          19.0   \n",
      "20          16.0            p          17.0            q          18.0   \n",
      "19          15.0            o          16.0            p          17.0   \n",
      "18          14.0            n          15.0            o          16.0   \n",
      "17          13.0            m          14.0            n          15.0   \n",
      "16          12.0            l          13.0            m          14.0   \n",
      "15          11.0            k          12.0            l          13.0   \n",
      "14          10.0            j          11.0            k          12.0   \n",
      "13           9.0            i          10.0            j          11.0   \n",
      "12           8.0            h           9.0            i          10.0   \n",
      "11           7.0            g           8.0            h           9.0   \n",
      "10           6.0            f           7.0            g           8.0   \n",
      "9            5.0            e           6.0            f           7.0   \n",
      "8            4.0            d           5.0            e           6.0   \n",
      "7            3.0            c           4.0            d           5.0   \n",
      "6            2.0            b           3.0            c           4.0   \n",
      "5            1.0            a           2.0            b           3.0   \n",
      "\n",
      "   letters(t-3)  numbers(t-2) letters(t-2)  numbers(t-1) letters(t-1)  \\\n",
      "24            v          23.0            w          24.0            x   \n",
      "23            u          22.0            v          23.0            w   \n",
      "22            t          21.0            u          22.0            v   \n",
      "21            s          20.0            t          21.0            u   \n",
      "20            r          19.0            s          20.0            t   \n",
      "19            q          18.0            r          19.0            s   \n",
      "18            p          17.0            q          18.0            r   \n",
      "17            o          16.0            p          17.0            q   \n",
      "16            n          15.0            o          16.0            p   \n",
      "15            m          14.0            n          15.0            o   \n",
      "14            l          13.0            m          14.0            n   \n",
      "13            k          12.0            l          13.0            m   \n",
      "12            j          11.0            k          12.0            l   \n",
      "11            i          10.0            j          11.0            k   \n",
      "10            h           9.0            i          10.0            j   \n",
      "9             g           8.0            h           9.0            i   \n",
      "8             f           7.0            g           8.0            h   \n",
      "7             e           6.0            f           7.0            g   \n",
      "6             d           5.0            e           6.0            f   \n",
      "5             c           4.0            d           5.0            e   \n",
      "\n",
      "    numbers(t+0) letters(t+0)  numbers(t+1) letters(t+1)  \n",
      "24            25            y          26.0            z  \n",
      "23            24            x          25.0            y  \n",
      "22            23            w          24.0            x  \n",
      "21            22            v          23.0            w  \n",
      "20            21            u          22.0            v  \n",
      "19            20            t          21.0            u  \n",
      "18            19            s          20.0            t  \n",
      "17            18            r          19.0            s  \n",
      "16            17            q          18.0            r  \n",
      "15            16            p          17.0            q  \n",
      "14            15            o          16.0            p  \n",
      "13            14            n          15.0            o  \n",
      "12            13            m          14.0            n  \n",
      "11            12            l          13.0            m  \n",
      "10            11            k          12.0            l  \n",
      "9             10            j          11.0            k  \n",
      "8              9            i          10.0            j  \n",
      "7              8            h           9.0            i  \n",
      "6              7            g           8.0            h  \n",
      "5              6            f           7.0            g  \n"
     ]
    }
   ],
   "source": [
    "def to_time_series(df, columns, n_trail=1, n_lead=1):\n",
    "    '''\n",
    "    :param df: DataFrame, dataframe object where the columns are the features and labels and the rows are days\n",
    "    :param columns: list of strings, names of the features and labels (columns of df) to be used in the time series\n",
    "    :param n_trail: int, number of days behind day 0 that will be used to predict days after day 0\n",
    "    :param n_lead: int, number of days ahead of day 0 that will be predicted\n",
    "    \n",
    "    ---> DataFrame, dataframe object structured like a time series where each row represents an element in the time\n",
    "                    series, and each column is a feature or label a certain amount of days in the future or past.\n",
    "    '''\n",
    "    df = df[columns]\n",
    "    dfs = []\n",
    "    col_names = []\n",
    "    \n",
    "    # Create trailing columns\n",
    "    for i in range(n_trail, 0, -1):\n",
    "        dfs.append(df.shift(-i))\n",
    "        col_names += [(col_name + '(t-{})'.format(i)) for col_name in columns]\n",
    "        \n",
    "    # Create leading columns\n",
    "    for i in range(0, n_lead+1):\n",
    "        dfs.append(df.shift(i))\n",
    "        col_names += [(col_name + '(t+{})'.format(i)) for col_name in columns]\n",
    "        \n",
    "    agg = pd.concat(dfs, axis=1)\n",
    "    agg.columns = col_names\n",
    "    \n",
    "    agg.dropna(inplace=True)\n",
    "    \n",
    "    return agg\n",
    "\n",
    "# Testing Function\n",
    "test_df = pd.DataFrame([(1, 'a'), (2, 'b'), (3, 'c'),\n",
    "                        (4, 'd'), (5, 'e'), (6, 'f'),\n",
    "                        (7, 'g'), (8, 'h'), (9, 'i'),\n",
    "                        (10, 'j'), (11, 'k'), (12, 'l'),\n",
    "                        (13, 'm'), (14, 'n'), (15, 'o'),\n",
    "                        (16, 'p'), (17, 'q'), (18, 'r'),\n",
    "                        (19, 's'), (20, 't'), (21, 'u'),\n",
    "                        (22, 'v'), (23, 'w'), (24, 'x'),\n",
    "                        (25, 'y'), (26, 'z')], columns=['numbers', 'letters'])\n",
    "test_df = test_df.reindex(index=test_df.index[::-1])\n",
    "print('Test DataFrame:')\n",
    "print(test_df)\n",
    "df = to_time_series(test_df, columns=test_df.columns, n_trail=5)\n",
    "print()\n",
    "print('Time Series DataFrame with a window size of n_trail+1')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only pricing data from one ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>log_adj_daily_returns_WFC</th>\n",
       "      <th>log_adj_daily_returns_JPM</th>\n",
       "      <th>log_adj_daily_returns_BAC</th>\n",
       "      <th>log_adj_daily_returns_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  log_adj_daily_returns_WFC  log_adj_daily_returns_JPM  \\\n",
       "0 2019-10-22                   0.003166                   0.009986   \n",
       "1 2019-10-21                   0.009758                   0.024498   \n",
       "2 2019-10-18                   0.007230                   0.001743   \n",
       "3 2019-10-17                   0.000403                   0.005583   \n",
       "4 2019-10-16                  -0.010431                  -0.002337   \n",
       "5 2019-10-15                   0.016905                   0.029696   \n",
       "6 2019-10-14                   0.001219                   0.002666   \n",
       "7 2019-10-11                   0.011445                   0.016758   \n",
       "\n",
       "   log_adj_daily_returns_BAC  log_adj_daily_returns_C  \n",
       "0                   0.005786                 0.003475  \n",
       "1                   0.021836                 0.029250  \n",
       "2                   0.002970                 0.002009  \n",
       "3                   0.002979                 0.001438  \n",
       "4                   0.014691                -0.024447  \n",
       "5                   0.020045                 0.013856  \n",
       "6                   0.007924                 0.001995  \n",
       "7                   0.016039                 0.021339  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset_size = 1000\n",
    "batch_size = 1000\n",
    "\n",
    "preprocessed_df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "\n",
    "features_to_test = ['log_adj_daily_returns']\n",
    "data_df = preprocessed_df[['timestamp'] + ['_'.join([feature, t]) for t in tickers for feature in features_to_test]]\n",
    "data_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-5)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_C(t-5)</th>\n",
       "      <th>timestamp(t-4)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-4)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_C(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp(t+0)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+0)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_C(t+0)</th>\n",
       "      <th>timestamp(t+1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+1)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_C(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>-0.022548</td>\n",
       "      <td>-0.024313</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp(t-5)  log_adj_daily_returns_WFC(t-5)  \\\n",
       "1     2019-10-14                        0.001219   \n",
       "2     2019-10-11                        0.011445   \n",
       "3     2019-10-10                        0.010331   \n",
       "4     2019-10-09                        0.006877   \n",
       "5     2019-10-08                       -0.020491   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_BAC(t-5)  \\\n",
       "1                        0.002666                        0.007924   \n",
       "2                        0.016758                        0.016039   \n",
       "3                        0.013931                        0.019880   \n",
       "4                        0.007218                        0.009366   \n",
       "5                       -0.022548                       -0.024313   \n",
       "\n",
       "   log_adj_daily_returns_C(t-5) timestamp(t-4)  \\\n",
       "1                      0.001995     2019-10-15   \n",
       "2                      0.021339     2019-10-14   \n",
       "3                      0.017494     2019-10-11   \n",
       "4                      0.015393     2019-10-10   \n",
       "5                     -0.026014     2019-10-09   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-4)  log_adj_daily_returns_JPM(t-4)  \\\n",
       "1                        0.016905                        0.029696   \n",
       "2                        0.001219                        0.002666   \n",
       "3                        0.011445                        0.016758   \n",
       "4                        0.010331                        0.013931   \n",
       "5                        0.006877                        0.007218   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t-4)  log_adj_daily_returns_C(t-4)  ...  \\\n",
       "1                        0.020045                      0.013856  ...   \n",
       "2                        0.007924                      0.001995  ...   \n",
       "3                        0.016039                      0.021339  ...   \n",
       "4                        0.019880                      0.017494  ...   \n",
       "5                        0.009366                      0.015393  ...   \n",
       "\n",
       "  timestamp(t+0)  log_adj_daily_returns_WFC(t+0)  \\\n",
       "1     2019-10-21                        0.009758   \n",
       "2     2019-10-18                        0.007230   \n",
       "3     2019-10-17                        0.000403   \n",
       "4     2019-10-16                       -0.010431   \n",
       "5     2019-10-15                        0.016905   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t+0)  log_adj_daily_returns_BAC(t+0)  \\\n",
       "1                        0.024498                        0.021836   \n",
       "2                        0.001743                        0.002970   \n",
       "3                        0.005583                        0.002979   \n",
       "4                       -0.002337                        0.014691   \n",
       "5                        0.029696                        0.020045   \n",
       "\n",
       "   log_adj_daily_returns_C(t+0) timestamp(t+1)  \\\n",
       "1                      0.029250     2019-10-22   \n",
       "2                      0.002009     2019-10-21   \n",
       "3                      0.001438     2019-10-18   \n",
       "4                     -0.024447     2019-10-17   \n",
       "5                      0.013856     2019-10-16   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  log_adj_daily_returns_JPM(t+1)  \\\n",
       "1                        0.003166                        0.009986   \n",
       "2                        0.009758                        0.024498   \n",
       "3                        0.007230                        0.001743   \n",
       "4                        0.000403                        0.005583   \n",
       "5                       -0.010431                       -0.002337   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t+1)  log_adj_daily_returns_C(t+1)  \n",
       "1                        0.005786                      0.003475  \n",
       "2                        0.021836                      0.029250  \n",
       "3                        0.002970                      0.002009  \n",
       "4                        0.002979                      0.001438  \n",
       "5                        0.014691                     -0.024447  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_time_series(data_df, data_df.columns, n_trail=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['log_adj_daily_returns_WFC(t-5)', 'log_adj_daily_returns_WFC(t-4)', 'log_adj_daily_returns_WFC(t-3)', 'log_adj_daily_returns_WFC(t-2)', 'log_adj_daily_returns_WFC(t-1)', 'log_adj_daily_returns_WFC(t+0)', 'log_adj_daily_returns_WFC(t+1)'], ['log_adj_daily_returns_JPM(t-5)', 'log_adj_daily_returns_JPM(t-4)', 'log_adj_daily_returns_JPM(t-3)', 'log_adj_daily_returns_JPM(t-2)', 'log_adj_daily_returns_JPM(t-1)', 'log_adj_daily_returns_JPM(t+0)', 'log_adj_daily_returns_JPM(t+1)'], ['log_adj_daily_returns_BAC(t-5)', 'log_adj_daily_returns_BAC(t-4)', 'log_adj_daily_returns_BAC(t-3)', 'log_adj_daily_returns_BAC(t-2)', 'log_adj_daily_returns_BAC(t-1)', 'log_adj_daily_returns_BAC(t+0)', 'log_adj_daily_returns_BAC(t+1)'], ['log_adj_daily_returns_C(t-5)', 'log_adj_daily_returns_C(t-4)', 'log_adj_daily_returns_C(t-3)', 'log_adj_daily_returns_C(t-2)', 'log_adj_daily_returns_C(t-1)', 'log_adj_daily_returns_C(t+0)', 'log_adj_daily_returns_C(t+1)']]\n"
     ]
    }
   ],
   "source": [
    "column_names_by_ticker = [[name for name in df.columns if 'log_adj_daily_returns_' + t in name] for t in tickers]\n",
    "print(column_names_by_ticker)\n",
    "# Using only data from ticker WFC\n",
    "cols = column_names_by_ticker[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-3)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-2)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.009758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.007230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>-0.010431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_adj_daily_returns_WFC(t-5)  log_adj_daily_returns_WFC(t-4)  \\\n",
       "1                        0.001219                        0.016905   \n",
       "2                        0.011445                        0.001219   \n",
       "3                        0.010331                        0.011445   \n",
       "4                        0.006877                        0.010331   \n",
       "5                       -0.020491                        0.006877   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-3)  log_adj_daily_returns_WFC(t-2)  \\\n",
       "1                       -0.010431                        0.000403   \n",
       "2                        0.016905                       -0.010431   \n",
       "3                        0.001219                        0.016905   \n",
       "4                        0.011445                        0.001219   \n",
       "5                        0.010331                        0.011445   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-1)  log_adj_daily_returns_WFC(t+0)  \\\n",
       "1                        0.007230                        0.009758   \n",
       "2                        0.000403                        0.007230   \n",
       "3                       -0.010431                        0.000403   \n",
       "4                        0.016905                       -0.010431   \n",
       "5                        0.001219                        0.016905   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  \n",
       "1                        0.003166  \n",
       "2                        0.009758  \n",
       "3                        0.007230  \n",
       "4                        0.000403  \n",
       "5                       -0.010431  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if columns are still in the right order\n",
    "df[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Dataset: 5024\n"
     ]
    }
   ],
   "source": [
    "dataset = df[cols].values\n",
    "print('Length of Dataset: {}'.format(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00121852  0.01690521 -0.01043139  0.00040323  0.0072304   0.00975812\n",
      "  0.00316581]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled Dataset size: 1000\n"
     ]
    }
   ],
   "source": [
    "# Shuffling and Sampling Dataset\n",
    "shuffled_indices = np.random.choice(len(dataset), size=dataset_size, replace=False)\n",
    "assert (len(shuffled_indices) == dataset_size) and (shuffled_indices.dtype == np.int64)\n",
    "shuffled_dataset = dataset[shuffled_indices]\n",
    "print('Shuffled Dataset size: {}'.format(len(shuffled_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting Dataset into Features and Labels\n",
    "X, y = shuffled_dataset[:, :-1], shuffled_dataset[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/900\n",
      "1000/1000 [==============================] - 6s 6ms/sample - loss: 5.5342e-04 - val_loss: 9.4334e-04\n",
      "Epoch 2/900\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 9.4334e-04 - val_loss: 5.6727e-04\n",
      "Epoch 3/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.6727e-04 - val_loss: 6.2682e-04\n",
      "Epoch 4/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 6.2682e-04 - val_loss: 7.2747e-04\n",
      "Epoch 5/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 7.2747e-04 - val_loss: 6.8187e-04\n",
      "Epoch 6/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 6.8187e-04 - val_loss: 5.9401e-04\n",
      "Epoch 7/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.9401e-04 - val_loss: 5.5202e-04\n",
      "Epoch 8/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5202e-04 - val_loss: 5.6980e-04\n",
      "Epoch 9/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.6980e-04 - val_loss: 6.0640e-04\n",
      "Epoch 10/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 6.0640e-04 - val_loss: 6.1700e-04\n",
      "Epoch 11/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 6.1700e-04 - val_loss: 5.9880e-04\n",
      "Epoch 12/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.9880e-04 - val_loss: 5.7252e-04\n",
      "Epoch 13/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.7252e-04 - val_loss: 5.5519e-04\n",
      "Epoch 14/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5519e-04 - val_loss: 5.5169e-04\n",
      "Epoch 15/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5169e-04 - val_loss: 5.5797e-04\n",
      "Epoch 16/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5797e-04 - val_loss: 5.6661e-04\n",
      "Epoch 17/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.6661e-04 - val_loss: 5.7150e-04\n",
      "Epoch 18/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.7150e-04 - val_loss: 5.7037e-04\n",
      "Epoch 19/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.7037e-04 - val_loss: 5.6462e-04\n",
      "Epoch 20/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.6462e-04 - val_loss: 5.5762e-04\n",
      "Epoch 21/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5762e-04 - val_loss: 5.5266e-04\n",
      "Epoch 22/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5266e-04 - val_loss: 5.5149e-04\n",
      "Epoch 23/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5149e-04 - val_loss: 5.5378e-04\n",
      "Epoch 24/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5378e-04 - val_loss: 5.5746e-04\n",
      "Epoch 25/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5746e-04 - val_loss: 5.6000e-04\n",
      "Epoch 26/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.6000e-04 - val_loss: 5.5993e-04\n",
      "Epoch 27/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.5993e-04 - val_loss: 5.5757e-04\n",
      "Epoch 28/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5757e-04 - val_loss: 5.5442e-04\n",
      "Epoch 29/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5442e-04 - val_loss: 5.5210e-04\n",
      "Epoch 30/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5210e-04 - val_loss: 5.5142e-04\n",
      "Epoch 31/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5142e-04 - val_loss: 5.5222e-04\n",
      "Epoch 32/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5222e-04 - val_loss: 5.5366e-04\n",
      "Epoch 33/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5366e-04 - val_loss: 5.5480e-04\n",
      "Epoch 34/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5480e-04 - val_loss: 5.5506e-04\n",
      "Epoch 35/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5506e-04 - val_loss: 5.5437e-04\n",
      "Epoch 36/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5437e-04 - val_loss: 5.5316e-04\n",
      "Epoch 37/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5316e-04 - val_loss: 5.5202e-04\n",
      "Epoch 38/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5202e-04 - val_loss: 5.5144e-04\n",
      "Epoch 39/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5144e-04 - val_loss: 5.5154e-04\n",
      "Epoch 40/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5154e-04 - val_loss: 5.5210e-04\n",
      "Epoch 41/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5210e-04 - val_loss: 5.5269e-04\n",
      "Epoch 42/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5269e-04 - val_loss: 5.5297e-04\n",
      "Epoch 43/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5297e-04 - val_loss: 5.5279e-04\n",
      "Epoch 44/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5279e-04 - val_loss: 5.5230e-04\n",
      "Epoch 45/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5230e-04 - val_loss: 5.5177e-04\n",
      "Epoch 46/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5177e-04 - val_loss: 5.5144e-04\n",
      "Epoch 47/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5144e-04 - val_loss: 5.5143e-04\n",
      "Epoch 48/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5143e-04 - val_loss: 5.5165e-04\n",
      "Epoch 49/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5165e-04 - val_loss: 5.5192e-04\n",
      "Epoch 50/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5192e-04 - val_loss: 5.5207e-04\n",
      "Epoch 51/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5207e-04 - val_loss: 5.5202e-04\n",
      "Epoch 52/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.5202e-04 - val_loss: 5.5181e-04\n",
      "Epoch 53/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5181e-04 - val_loss: 5.5157e-04\n",
      "Epoch 54/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5157e-04 - val_loss: 5.5142e-04\n",
      "Epoch 55/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5142e-04 - val_loss: 5.5140e-04\n",
      "Epoch 56/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5140e-04 - val_loss: 5.5150e-04\n",
      "Epoch 57/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5150e-04 - val_loss: 5.5162e-04\n",
      "Epoch 58/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5162e-04 - val_loss: 5.5169e-04\n",
      "Epoch 59/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5169e-04 - val_loss: 5.5166e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5166e-04 - val_loss: 5.5156e-04\n",
      "Epoch 61/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 5.5156e-04 - val_loss: 5.5146e-04\n",
      "Epoch 62/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5146e-04 - val_loss: 5.5139e-04\n",
      "Epoch 63/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.5139e-04 - val_loss: 5.5140e-04\n",
      "Epoch 64/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5140e-04 - val_loss: 5.5145e-04\n",
      "Epoch 65/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5145e-04 - val_loss: 5.5150e-04\n",
      "Epoch 66/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5150e-04 - val_loss: 5.5152e-04\n",
      "Epoch 67/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5152e-04 - val_loss: 5.5150e-04\n",
      "Epoch 68/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5150e-04 - val_loss: 5.5145e-04\n",
      "Epoch 69/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5145e-04 - val_loss: 5.5140e-04\n",
      "Epoch 70/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.5140e-04 - val_loss: 5.5138e-04\n",
      "Epoch 71/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5138e-04 - val_loss: 5.5139e-04\n",
      "Epoch 72/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5139e-04 - val_loss: 5.5142e-04\n",
      "Epoch 73/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5142e-04 - val_loss: 5.5144e-04\n",
      "Epoch 74/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5144e-04 - val_loss: 5.5144e-04\n",
      "Epoch 75/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.5144e-04 - val_loss: 5.5142e-04\n",
      "Epoch 76/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5142e-04 - val_loss: 5.5139e-04\n",
      "Epoch 77/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5139e-04 - val_loss: 5.5137e-04\n",
      "Epoch 78/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5137e-04 - val_loss: 5.5137e-04\n",
      "Epoch 79/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5137e-04 - val_loss: 5.5138e-04\n",
      "Epoch 80/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5138e-04 - val_loss: 5.5140e-04\n",
      "Epoch 81/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 5.5140e-04 - val_loss: 5.5140e-04\n",
      "Epoch 82/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.5140e-04 - val_loss: 5.5139e-04\n",
      "Epoch 83/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5139e-04 - val_loss: 5.5138e-04\n",
      "Epoch 84/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5138e-04 - val_loss: 5.5137e-04\n",
      "Epoch 85/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.5137e-04 - val_loss: 5.5136e-04\n",
      "Epoch 86/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5136e-04 - val_loss: 5.5137e-04\n",
      "Epoch 87/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.5137e-04 - val_loss: 5.5137e-04\n",
      "Epoch 88/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5137e-04 - val_loss: 5.5138e-04\n",
      "Epoch 89/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.5138e-04 - val_loss: 5.5137e-04\n",
      "Epoch 90/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.5137e-04 - val_loss: 5.5137e-04\n",
      "Epoch 91/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 92/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 93/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 94/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 95/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 96/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5136e-04 - val_loss: 5.5136e-04\n",
      "Epoch 97/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5136e-04 - val_loss: 5.5135e-04\n",
      "Epoch 98/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 99/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 100/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 101/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 102/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 103/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5135e-04 - val_loss: 5.5135e-04\n",
      "Epoch 104/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5135e-04 - val_loss: 5.5134e-04\n",
      "Epoch 105/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 106/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 107/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 108/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 109/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5134e-04 - val_loss: 5.5134e-04\n",
      "Epoch 110/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5134e-04 - val_loss: 5.5133e-04\n",
      "Epoch 111/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 112/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 113/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 114/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 115/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5133e-04 - val_loss: 5.5133e-04\n",
      "Epoch 116/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5133e-04 - val_loss: 5.5132e-04\n",
      "Epoch 117/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 118/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 119/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 120/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 121/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5132e-04 - val_loss: 5.5132e-04\n",
      "Epoch 122/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5132e-04 - val_loss: 5.5131e-04\n",
      "Epoch 123/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 124/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 125/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 126/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5131e-04 - val_loss: 5.5131e-04\n",
      "Epoch 127/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5131e-04 - val_loss: 5.5130e-04\n",
      "Epoch 128/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n",
      "Epoch 129/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n",
      "Epoch 130/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5130e-04 - val_loss: 5.5130e-04\n",
      "Epoch 132/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5130e-04 - val_loss: 5.5129e-04\n",
      "Epoch 133/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 134/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 135/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 136/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5129e-04 - val_loss: 5.5129e-04\n",
      "Epoch 137/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5129e-04 - val_loss: 5.5128e-04\n",
      "Epoch 138/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5128e-04 - val_loss: 5.5128e-04\n",
      "Epoch 139/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5128e-04 - val_loss: 5.5128e-04\n",
      "Epoch 140/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5128e-04 - val_loss: 5.5128e-04\n",
      "Epoch 141/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5128e-04 - val_loss: 5.5127e-04\n",
      "Epoch 142/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5127e-04 - val_loss: 5.5127e-04\n",
      "Epoch 143/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5127e-04 - val_loss: 5.5127e-04\n",
      "Epoch 144/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5127e-04 - val_loss: 5.5127e-04\n",
      "Epoch 145/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5127e-04 - val_loss: 5.5126e-04\n",
      "Epoch 146/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5126e-04 - val_loss: 5.5126e-04\n",
      "Epoch 147/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5126e-04 - val_loss: 5.5126e-04\n",
      "Epoch 148/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5126e-04 - val_loss: 5.5126e-04\n",
      "Epoch 149/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5126e-04 - val_loss: 5.5125e-04\n",
      "Epoch 150/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5125e-04 - val_loss: 5.5125e-04\n",
      "Epoch 151/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5125e-04 - val_loss: 5.5125e-04\n",
      "Epoch 152/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5125e-04 - val_loss: 5.5124e-04\n",
      "Epoch 153/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5124e-04 - val_loss: 5.5124e-04\n",
      "Epoch 154/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5124e-04 - val_loss: 5.5124e-04\n",
      "Epoch 155/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5124e-04 - val_loss: 5.5124e-04\n",
      "Epoch 156/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5124e-04 - val_loss: 5.5123e-04\n",
      "Epoch 157/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5123e-04 - val_loss: 5.5123e-04\n",
      "Epoch 158/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5123e-04 - val_loss: 5.5123e-04\n",
      "Epoch 159/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5123e-04 - val_loss: 5.5122e-04\n",
      "Epoch 160/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5122e-04 - val_loss: 5.5122e-04\n",
      "Epoch 161/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5122e-04 - val_loss: 5.5122e-04\n",
      "Epoch 162/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5122e-04 - val_loss: 5.5121e-04\n",
      "Epoch 163/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5121e-04 - val_loss: 5.5121e-04\n",
      "Epoch 164/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5121e-04 - val_loss: 5.5120e-04\n",
      "Epoch 165/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5120e-04 - val_loss: 5.5120e-04\n",
      "Epoch 166/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5120e-04 - val_loss: 5.5120e-04\n",
      "Epoch 167/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5120e-04 - val_loss: 5.5119e-04\n",
      "Epoch 168/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5119e-04 - val_loss: 5.5119e-04\n",
      "Epoch 169/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5119e-04 - val_loss: 5.5118e-04\n",
      "Epoch 170/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5118e-04 - val_loss: 5.5118e-04\n",
      "Epoch 171/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5118e-04 - val_loss: 5.5117e-04\n",
      "Epoch 172/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5117e-04 - val_loss: 5.5117e-04\n",
      "Epoch 173/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5117e-04 - val_loss: 5.5117e-04\n",
      "Epoch 174/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5117e-04 - val_loss: 5.5116e-04\n",
      "Epoch 175/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5116e-04 - val_loss: 5.5116e-04\n",
      "Epoch 176/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5116e-04 - val_loss: 5.5115e-04\n",
      "Epoch 177/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5115e-04 - val_loss: 5.5115e-04\n",
      "Epoch 178/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5115e-04 - val_loss: 5.5114e-04\n",
      "Epoch 179/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5114e-04 - val_loss: 5.5114e-04\n",
      "Epoch 180/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5114e-04 - val_loss: 5.5113e-04\n",
      "Epoch 181/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5113e-04 - val_loss: 5.5112e-04\n",
      "Epoch 182/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5112e-04 - val_loss: 5.5112e-04\n",
      "Epoch 183/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5112e-04 - val_loss: 5.5111e-04\n",
      "Epoch 184/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5111e-04 - val_loss: 5.5111e-04\n",
      "Epoch 185/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5111e-04 - val_loss: 5.5110e-04\n",
      "Epoch 186/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5110e-04 - val_loss: 5.5109e-04\n",
      "Epoch 187/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5109e-04 - val_loss: 5.5109e-04\n",
      "Epoch 188/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5109e-04 - val_loss: 5.5108e-04\n",
      "Epoch 189/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5108e-04 - val_loss: 5.5107e-04\n",
      "Epoch 190/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5107e-04 - val_loss: 5.5107e-04\n",
      "Epoch 191/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5107e-04 - val_loss: 5.5106e-04\n",
      "Epoch 192/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5106e-04 - val_loss: 5.5105e-04\n",
      "Epoch 193/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5105e-04 - val_loss: 5.5104e-04\n",
      "Epoch 194/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5104e-04 - val_loss: 5.5103e-04\n",
      "Epoch 195/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5103e-04 - val_loss: 5.5103e-04\n",
      "Epoch 196/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5103e-04 - val_loss: 5.5102e-04\n",
      "Epoch 197/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5102e-04 - val_loss: 5.5101e-04\n",
      "Epoch 198/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5101e-04 - val_loss: 5.5100e-04\n",
      "Epoch 199/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5100e-04 - val_loss: 5.5099e-04\n",
      "Epoch 200/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5099e-04 - val_loss: 5.5098e-04\n",
      "Epoch 201/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5098e-04 - val_loss: 5.5097e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5097e-04 - val_loss: 5.5096e-04\n",
      "Epoch 203/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5096e-04 - val_loss: 5.5095e-04\n",
      "Epoch 204/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5095e-04 - val_loss: 5.5094e-04\n",
      "Epoch 205/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5094e-04 - val_loss: 5.5093e-04\n",
      "Epoch 206/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5093e-04 - val_loss: 5.5092e-04\n",
      "Epoch 207/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5092e-04 - val_loss: 5.5091e-04\n",
      "Epoch 208/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5091e-04 - val_loss: 5.5089e-04\n",
      "Epoch 209/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5089e-04 - val_loss: 5.5088e-04\n",
      "Epoch 210/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5088e-04 - val_loss: 5.5087e-04\n",
      "Epoch 211/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5087e-04 - val_loss: 5.5086e-04\n",
      "Epoch 212/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5086e-04 - val_loss: 5.5084e-04\n",
      "Epoch 213/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5084e-04 - val_loss: 5.5083e-04\n",
      "Epoch 214/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5083e-04 - val_loss: 5.5081e-04\n",
      "Epoch 215/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5081e-04 - val_loss: 5.5080e-04\n",
      "Epoch 216/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5080e-04 - val_loss: 5.5078e-04\n",
      "Epoch 217/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5078e-04 - val_loss: 5.5076e-04\n",
      "Epoch 218/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 5.5076e-04 - val_loss: 5.5075e-04\n",
      "Epoch 219/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5075e-04 - val_loss: 5.5073e-04\n",
      "Epoch 220/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5073e-04 - val_loss: 5.5071e-04\n",
      "Epoch 221/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5071e-04 - val_loss: 5.5069e-04\n",
      "Epoch 222/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5069e-04 - val_loss: 5.5067e-04\n",
      "Epoch 223/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5067e-04 - val_loss: 5.5065e-04\n",
      "Epoch 224/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5065e-04 - val_loss: 5.5063e-04\n",
      "Epoch 225/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5063e-04 - val_loss: 5.5061e-04\n",
      "Epoch 226/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5061e-04 - val_loss: 5.5059e-04\n",
      "Epoch 227/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 5.5059e-04 - val_loss: 5.5057e-04\n",
      "Epoch 228/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5057e-04 - val_loss: 5.5054e-04\n",
      "Epoch 229/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5054e-04 - val_loss: 5.5052e-04\n",
      "Epoch 230/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5052e-04 - val_loss: 5.5049e-04\n",
      "Epoch 231/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 5.5049e-04 - val_loss: 5.5046e-04\n",
      "Epoch 232/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5046e-04 - val_loss: 5.5043e-04\n",
      "Epoch 233/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5043e-04 - val_loss: 5.5041e-04\n",
      "Epoch 234/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5041e-04 - val_loss: 5.5038e-04\n",
      "Epoch 235/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5038e-04 - val_loss: 5.5034e-04\n",
      "Epoch 236/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.5034e-04 - val_loss: 5.5031e-04\n",
      "Epoch 237/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5031e-04 - val_loss: 5.5028e-04\n",
      "Epoch 238/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.5028e-04 - val_loss: 5.5024e-04\n",
      "Epoch 239/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5024e-04 - val_loss: 5.5020e-04\n",
      "Epoch 240/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5020e-04 - val_loss: 5.5017e-04\n",
      "Epoch 241/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5017e-04 - val_loss: 5.5013e-04\n",
      "Epoch 242/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5013e-04 - val_loss: 5.5008e-04\n",
      "Epoch 243/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5008e-04 - val_loss: 5.5004e-04\n",
      "Epoch 244/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5004e-04 - val_loss: 5.5000e-04\n",
      "Epoch 245/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.5000e-04 - val_loss: 5.4995e-04\n",
      "Epoch 246/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4995e-04 - val_loss: 5.4990e-04\n",
      "Epoch 247/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4990e-04 - val_loss: 5.4985e-04\n",
      "Epoch 248/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4985e-04 - val_loss: 5.4980e-04\n",
      "Epoch 249/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4980e-04 - val_loss: 5.4974e-04\n",
      "Epoch 250/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 5.4974e-04 - val_loss: 5.4968e-04\n",
      "Epoch 251/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4968e-04 - val_loss: 5.4962e-04\n",
      "Epoch 252/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4962e-04 - val_loss: 5.4956e-04\n",
      "Epoch 253/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4956e-04 - val_loss: 5.4950e-04\n",
      "Epoch 254/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4950e-04 - val_loss: 5.4943e-04\n",
      "Epoch 255/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4943e-04 - val_loss: 5.4936e-04\n",
      "Epoch 256/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4936e-04 - val_loss: 5.4928e-04\n",
      "Epoch 257/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4928e-04 - val_loss: 5.4921e-04\n",
      "Epoch 258/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4921e-04 - val_loss: 5.4913e-04\n",
      "Epoch 259/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4913e-04 - val_loss: 5.4905e-04\n",
      "Epoch 260/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4905e-04 - val_loss: 5.4896e-04\n",
      "Epoch 261/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4896e-04 - val_loss: 5.4888e-04\n",
      "Epoch 262/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4888e-04 - val_loss: 5.4879e-04\n",
      "Epoch 263/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4879e-04 - val_loss: 5.4869e-04\n",
      "Epoch 264/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4869e-04 - val_loss: 5.4860e-04\n",
      "Epoch 265/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4860e-04 - val_loss: 5.4850e-04\n",
      "Epoch 266/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4850e-04 - val_loss: 5.4840e-04\n",
      "Epoch 267/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4840e-04 - val_loss: 5.4829e-04\n",
      "Epoch 268/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4829e-04 - val_loss: 5.4819e-04\n",
      "Epoch 269/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4819e-04 - val_loss: 5.4808e-04\n",
      "Epoch 270/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4808e-04 - val_loss: 5.4797e-04\n",
      "Epoch 271/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4797e-04 - val_loss: 5.4786e-04\n",
      "Epoch 272/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4786e-04 - val_loss: 5.4776e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4776e-04 - val_loss: 5.4765e-04\n",
      "Epoch 274/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4765e-04 - val_loss: 5.4754e-04\n",
      "Epoch 275/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4754e-04 - val_loss: 5.4743e-04\n",
      "Epoch 276/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4743e-04 - val_loss: 5.4733e-04\n",
      "Epoch 277/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4733e-04 - val_loss: 5.4723e-04\n",
      "Epoch 278/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4723e-04 - val_loss: 5.4714e-04\n",
      "Epoch 279/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4714e-04 - val_loss: 5.4705e-04\n",
      "Epoch 280/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4705e-04 - val_loss: 5.4696e-04\n",
      "Epoch 281/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4696e-04 - val_loss: 5.4689e-04\n",
      "Epoch 282/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4689e-04 - val_loss: 5.4682e-04\n",
      "Epoch 283/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4682e-04 - val_loss: 5.4676e-04\n",
      "Epoch 284/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4676e-04 - val_loss: 5.4671e-04\n",
      "Epoch 285/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4671e-04 - val_loss: 5.4667e-04\n",
      "Epoch 286/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4667e-04 - val_loss: 5.4663e-04\n",
      "Epoch 287/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.4663e-04 - val_loss: 5.4661e-04\n",
      "Epoch 288/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4661e-04 - val_loss: 5.4665e-04\n",
      "Epoch 289/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4665e-04 - val_loss: 5.4748e-04\n",
      "Epoch 290/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4748e-04 - val_loss: 5.5622e-04\n",
      "Epoch 291/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.5622e-04 - val_loss: 5.7902e-04\n",
      "Epoch 292/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.7902e-04 - val_loss: 5.5763e-04\n",
      "Epoch 293/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5763e-04 - val_loss: 5.5668e-04\n",
      "Epoch 294/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5668e-04 - val_loss: 5.5424e-04\n",
      "Epoch 295/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.5424e-04 - val_loss: 5.5573e-04\n",
      "Epoch 296/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.5573e-04 - val_loss: 5.4783e-04\n",
      "Epoch 297/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4783e-04 - val_loss: 5.5567e-04\n",
      "Epoch 298/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.5567e-04 - val_loss: 5.4926e-04\n",
      "Epoch 299/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4926e-04 - val_loss: 5.4876e-04\n",
      "Epoch 300/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4876e-04 - val_loss: 5.5265e-04\n",
      "Epoch 301/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5265e-04 - val_loss: 5.4968e-04\n",
      "Epoch 302/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4968e-04 - val_loss: 5.4802e-04\n",
      "Epoch 303/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4802e-04 - val_loss: 5.5041e-04\n",
      "Epoch 304/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.5041e-04 - val_loss: 5.5072e-04\n",
      "Epoch 305/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.5072e-04 - val_loss: 5.4872e-04\n",
      "Epoch 306/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4872e-04 - val_loss: 5.4851e-04\n",
      "Epoch 307/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4851e-04 - val_loss: 5.4988e-04\n",
      "Epoch 308/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4988e-04 - val_loss: 5.4992e-04\n",
      "Epoch 309/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4992e-04 - val_loss: 5.4875e-04\n",
      "Epoch 310/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4875e-04 - val_loss: 5.4850e-04\n",
      "Epoch 311/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4850e-04 - val_loss: 5.4928e-04\n",
      "Epoch 312/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4928e-04 - val_loss: 5.4945e-04\n",
      "Epoch 313/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4945e-04 - val_loss: 5.4873e-04\n",
      "Epoch 314/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 5.4873e-04 - val_loss: 5.4834e-04\n",
      "Epoch 315/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4834e-04 - val_loss: 5.4873e-04\n",
      "Epoch 316/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4873e-04 - val_loss: 5.4895e-04\n",
      "Epoch 317/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4895e-04 - val_loss: 5.4849e-04\n",
      "Epoch 318/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4849e-04 - val_loss: 5.4810e-04\n",
      "Epoch 319/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4810e-04 - val_loss: 5.4826e-04\n",
      "Epoch 320/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4826e-04 - val_loss: 5.4842e-04\n",
      "Epoch 321/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4842e-04 - val_loss: 5.4809e-04\n",
      "Epoch 322/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4809e-04 - val_loss: 5.4774e-04\n",
      "Epoch 323/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4774e-04 - val_loss: 5.4781e-04\n",
      "Epoch 324/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4781e-04 - val_loss: 5.4787e-04\n",
      "Epoch 325/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4787e-04 - val_loss: 5.4756e-04\n",
      "Epoch 326/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4756e-04 - val_loss: 5.4730e-04\n",
      "Epoch 327/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4730e-04 - val_loss: 5.4736e-04\n",
      "Epoch 328/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4736e-04 - val_loss: 5.4730e-04\n",
      "Epoch 329/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4730e-04 - val_loss: 5.4699e-04\n",
      "Epoch 330/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4699e-04 - val_loss: 5.4689e-04\n",
      "Epoch 331/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4689e-04 - val_loss: 5.4692e-04\n",
      "Epoch 332/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4692e-04 - val_loss: 5.4671e-04\n",
      "Epoch 333/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4671e-04 - val_loss: 5.4654e-04\n",
      "Epoch 334/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4654e-04 - val_loss: 5.4657e-04\n",
      "Epoch 335/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4657e-04 - val_loss: 5.4643e-04\n",
      "Epoch 336/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4643e-04 - val_loss: 5.4628e-04\n",
      "Epoch 337/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4628e-04 - val_loss: 5.4631e-04\n",
      "Epoch 338/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4631e-04 - val_loss: 5.4621e-04\n",
      "Epoch 339/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4621e-04 - val_loss: 5.4611e-04\n",
      "Epoch 340/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4611e-04 - val_loss: 5.4615e-04\n",
      "Epoch 341/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4615e-04 - val_loss: 5.4605e-04\n",
      "Epoch 342/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 5.4605e-04 - val_loss: 5.4604e-04\n",
      "Epoch 343/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4604e-04 - val_loss: 5.4606e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4606e-04 - val_loss: 5.4598e-04\n",
      "Epoch 345/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4598e-04 - val_loss: 5.4603e-04\n",
      "Epoch 346/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4603e-04 - val_loss: 5.4600e-04\n",
      "Epoch 347/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4600e-04 - val_loss: 5.4599e-04\n",
      "Epoch 348/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4599e-04 - val_loss: 5.4601e-04\n",
      "Epoch 349/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4601e-04 - val_loss: 5.4596e-04\n",
      "Epoch 350/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4596e-04 - val_loss: 5.4599e-04\n",
      "Epoch 351/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4599e-04 - val_loss: 5.4595e-04\n",
      "Epoch 352/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4595e-04 - val_loss: 5.4594e-04\n",
      "Epoch 353/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4594e-04 - val_loss: 5.4593e-04\n",
      "Epoch 354/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4593e-04 - val_loss: 5.4589e-04\n",
      "Epoch 355/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4589e-04 - val_loss: 5.4589e-04\n",
      "Epoch 356/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4589e-04 - val_loss: 5.4584e-04\n",
      "Epoch 357/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4584e-04 - val_loss: 5.4583e-04\n",
      "Epoch 358/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4583e-04 - val_loss: 5.4580e-04\n",
      "Epoch 359/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4580e-04 - val_loss: 5.4578e-04\n",
      "Epoch 360/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4578e-04 - val_loss: 5.4576e-04\n",
      "Epoch 361/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4576e-04 - val_loss: 5.4573e-04\n",
      "Epoch 362/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4573e-04 - val_loss: 5.4572e-04\n",
      "Epoch 363/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4572e-04 - val_loss: 5.4569e-04\n",
      "Epoch 364/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4569e-04 - val_loss: 5.4567e-04\n",
      "Epoch 365/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4567e-04 - val_loss: 5.4566e-04\n",
      "Epoch 366/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4566e-04 - val_loss: 5.4563e-04\n",
      "Epoch 367/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4563e-04 - val_loss: 5.4562e-04\n",
      "Epoch 368/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4562e-04 - val_loss: 5.4560e-04\n",
      "Epoch 369/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4560e-04 - val_loss: 5.4558e-04\n",
      "Epoch 370/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4558e-04 - val_loss: 5.4557e-04\n",
      "Epoch 371/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4557e-04 - val_loss: 5.4554e-04\n",
      "Epoch 372/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4554e-04 - val_loss: 5.4553e-04\n",
      "Epoch 373/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4553e-04 - val_loss: 5.4551e-04\n",
      "Epoch 374/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4551e-04 - val_loss: 5.4549e-04\n",
      "Epoch 375/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 5.4549e-04 - val_loss: 5.4547e-04\n",
      "Epoch 376/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4547e-04 - val_loss: 5.4545e-04\n",
      "Epoch 377/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4545e-04 - val_loss: 5.4543e-04\n",
      "Epoch 378/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4543e-04 - val_loss: 5.4541e-04\n",
      "Epoch 379/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4541e-04 - val_loss: 5.4539e-04\n",
      "Epoch 380/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4539e-04 - val_loss: 5.4537e-04\n",
      "Epoch 381/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4537e-04 - val_loss: 5.4535e-04\n",
      "Epoch 382/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4535e-04 - val_loss: 5.4533e-04\n",
      "Epoch 383/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4533e-04 - val_loss: 5.4530e-04\n",
      "Epoch 384/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4530e-04 - val_loss: 5.4528e-04\n",
      "Epoch 385/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4528e-04 - val_loss: 5.4526e-04\n",
      "Epoch 386/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 5.4526e-04 - val_loss: 5.4524e-04\n",
      "Epoch 387/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4524e-04 - val_loss: 5.4521e-04\n",
      "Epoch 388/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4521e-04 - val_loss: 5.4519e-04\n",
      "Epoch 389/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4519e-04 - val_loss: 5.4517e-04\n",
      "Epoch 390/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.4517e-04 - val_loss: 5.4514e-04\n",
      "Epoch 391/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4514e-04 - val_loss: 5.4512e-04\n",
      "Epoch 392/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4512e-04 - val_loss: 5.4510e-04\n",
      "Epoch 393/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4510e-04 - val_loss: 5.4507e-04\n",
      "Epoch 394/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4507e-04 - val_loss: 5.4505e-04\n",
      "Epoch 395/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 5.4505e-04 - val_loss: 5.4502e-04\n",
      "Epoch 396/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4502e-04 - val_loss: 5.4500e-04\n",
      "Epoch 397/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4500e-04 - val_loss: 5.4497e-04\n",
      "Epoch 398/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4497e-04 - val_loss: 5.4495e-04\n",
      "Epoch 399/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 5.4494e-04 - val_loss: 5.4492e-04\n",
      "Epoch 400/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.4492e-04 - val_loss: 5.4489e-04\n",
      "Epoch 401/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.4489e-04 - val_loss: 5.4487e-04\n",
      "Epoch 402/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.4487e-04 - val_loss: 5.4484e-04\n",
      "Epoch 403/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4484e-04 - val_loss: 5.4481e-04\n",
      "Epoch 404/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4481e-04 - val_loss: 5.4478e-04\n",
      "Epoch 405/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4478e-04 - val_loss: 5.4475e-04\n",
      "Epoch 406/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4475e-04 - val_loss: 5.4472e-04\n",
      "Epoch 407/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4472e-04 - val_loss: 5.4470e-04\n",
      "Epoch 408/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4470e-04 - val_loss: 5.4467e-04\n",
      "Epoch 409/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4467e-04 - val_loss: 5.4464e-04\n",
      "Epoch 410/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4464e-04 - val_loss: 5.4460e-04\n",
      "Epoch 411/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4460e-04 - val_loss: 5.4457e-04\n",
      "Epoch 412/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4457e-04 - val_loss: 5.4454e-04\n",
      "Epoch 413/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4454e-04 - val_loss: 5.4451e-04\n",
      "Epoch 414/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4451e-04 - val_loss: 5.4448e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4448e-04 - val_loss: 5.4445e-04\n",
      "Epoch 416/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4445e-04 - val_loss: 5.4441e-04\n",
      "Epoch 417/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4441e-04 - val_loss: 5.4438e-04\n",
      "Epoch 418/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4438e-04 - val_loss: 5.4434e-04\n",
      "Epoch 419/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4434e-04 - val_loss: 5.4431e-04\n",
      "Epoch 420/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4431e-04 - val_loss: 5.4428e-04\n",
      "Epoch 421/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4428e-04 - val_loss: 5.4424e-04\n",
      "Epoch 422/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4424e-04 - val_loss: 5.4420e-04\n",
      "Epoch 423/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4420e-04 - val_loss: 5.4417e-04\n",
      "Epoch 424/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4417e-04 - val_loss: 5.4413e-04\n",
      "Epoch 425/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4413e-04 - val_loss: 5.4409e-04\n",
      "Epoch 426/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.4409e-04 - val_loss: 5.4405e-04\n",
      "Epoch 427/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4405e-04 - val_loss: 5.4401e-04\n",
      "Epoch 428/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4401e-04 - val_loss: 5.4397e-04\n",
      "Epoch 429/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4397e-04 - val_loss: 5.4393e-04\n",
      "Epoch 430/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4393e-04 - val_loss: 5.4389e-04\n",
      "Epoch 431/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4389e-04 - val_loss: 5.4385e-04\n",
      "Epoch 432/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4385e-04 - val_loss: 5.4381e-04\n",
      "Epoch 433/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4381e-04 - val_loss: 5.4377e-04\n",
      "Epoch 434/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4377e-04 - val_loss: 5.4372e-04\n",
      "Epoch 435/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4372e-04 - val_loss: 5.4368e-04\n",
      "Epoch 436/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4368e-04 - val_loss: 5.4364e-04\n",
      "Epoch 437/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4364e-04 - val_loss: 5.4359e-04\n",
      "Epoch 438/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4359e-04 - val_loss: 5.4354e-04\n",
      "Epoch 439/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4354e-04 - val_loss: 5.4350e-04\n",
      "Epoch 440/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4350e-04 - val_loss: 5.4345e-04\n",
      "Epoch 441/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.4345e-04 - val_loss: 5.4340e-04\n",
      "Epoch 442/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4340e-04 - val_loss: 5.4335e-04\n",
      "Epoch 443/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4335e-04 - val_loss: 5.4330e-04\n",
      "Epoch 444/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4330e-04 - val_loss: 5.4325e-04\n",
      "Epoch 445/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4325e-04 - val_loss: 5.4320e-04\n",
      "Epoch 446/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4320e-04 - val_loss: 5.4315e-04\n",
      "Epoch 447/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4315e-04 - val_loss: 5.4310e-04\n",
      "Epoch 448/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4310e-04 - val_loss: 5.4304e-04\n",
      "Epoch 449/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4304e-04 - val_loss: 5.4299e-04\n",
      "Epoch 450/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4299e-04 - val_loss: 5.4293e-04\n",
      "Epoch 451/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4293e-04 - val_loss: 5.4288e-04\n",
      "Epoch 452/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4288e-04 - val_loss: 5.4282e-04\n",
      "Epoch 453/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4282e-04 - val_loss: 5.4276e-04\n",
      "Epoch 454/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4276e-04 - val_loss: 5.4270e-04\n",
      "Epoch 455/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4270e-04 - val_loss: 5.4264e-04\n",
      "Epoch 456/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.4264e-04 - val_loss: 5.4258e-04\n",
      "Epoch 457/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4258e-04 - val_loss: 5.4252e-04\n",
      "Epoch 458/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4252e-04 - val_loss: 5.4246e-04\n",
      "Epoch 459/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.4246e-04 - val_loss: 5.4240e-04\n",
      "Epoch 460/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4240e-04 - val_loss: 5.4234e-04\n",
      "Epoch 461/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4234e-04 - val_loss: 5.4227e-04\n",
      "Epoch 462/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4227e-04 - val_loss: 5.4221e-04\n",
      "Epoch 463/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4221e-04 - val_loss: 5.4214e-04\n",
      "Epoch 464/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4214e-04 - val_loss: 5.4207e-04\n",
      "Epoch 465/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4207e-04 - val_loss: 5.4201e-04\n",
      "Epoch 466/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4201e-04 - val_loss: 5.4194e-04\n",
      "Epoch 467/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4194e-04 - val_loss: 5.4187e-04\n",
      "Epoch 468/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4187e-04 - val_loss: 5.4180e-04\n",
      "Epoch 469/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4180e-04 - val_loss: 5.4173e-04\n",
      "Epoch 470/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4173e-04 - val_loss: 5.4165e-04\n",
      "Epoch 471/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4165e-04 - val_loss: 5.4158e-04\n",
      "Epoch 472/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4158e-04 - val_loss: 5.4151e-04\n",
      "Epoch 473/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4151e-04 - val_loss: 5.4144e-04\n",
      "Epoch 474/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4144e-04 - val_loss: 5.4136e-04\n",
      "Epoch 475/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4136e-04 - val_loss: 5.4129e-04\n",
      "Epoch 476/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4129e-04 - val_loss: 5.4121e-04\n",
      "Epoch 477/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.4121e-04 - val_loss: 5.4113e-04\n",
      "Epoch 478/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4113e-04 - val_loss: 5.4106e-04\n",
      "Epoch 479/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4106e-04 - val_loss: 5.4098e-04\n",
      "Epoch 480/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.4098e-04 - val_loss: 5.4090e-04\n",
      "Epoch 481/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4090e-04 - val_loss: 5.4082e-04\n",
      "Epoch 482/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4083e-04 - val_loss: 5.4075e-04\n",
      "Epoch 483/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4075e-04 - val_loss: 5.4067e-04\n",
      "Epoch 484/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.4067e-04 - val_loss: 5.4059e-04\n",
      "Epoch 485/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4059e-04 - val_loss: 5.4051e-04\n",
      "Epoch 486/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.4051e-04 - val_loss: 5.4043e-04\n",
      "Epoch 487/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4043e-04 - val_loss: 5.4035e-04\n",
      "Epoch 488/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.4035e-04 - val_loss: 5.4027e-04\n",
      "Epoch 489/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.4027e-04 - val_loss: 5.4019e-04\n",
      "Epoch 490/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.4019e-04 - val_loss: 5.4011e-04\n",
      "Epoch 491/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.4011e-04 - val_loss: 5.4002e-04\n",
      "Epoch 492/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.4002e-04 - val_loss: 5.3994e-04\n",
      "Epoch 493/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3994e-04 - val_loss: 5.3986e-04\n",
      "Epoch 494/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3986e-04 - val_loss: 5.3978e-04\n",
      "Epoch 495/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3978e-04 - val_loss: 5.3970e-04\n",
      "Epoch 496/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3970e-04 - val_loss: 5.3962e-04\n",
      "Epoch 497/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3962e-04 - val_loss: 5.3954e-04\n",
      "Epoch 498/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3954e-04 - val_loss: 5.3945e-04\n",
      "Epoch 499/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.3945e-04 - val_loss: 5.3937e-04\n",
      "Epoch 500/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3937e-04 - val_loss: 5.3929e-04\n",
      "Epoch 501/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3929e-04 - val_loss: 5.3921e-04\n",
      "Epoch 502/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3921e-04 - val_loss: 5.3912e-04\n",
      "Epoch 503/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3912e-04 - val_loss: 5.3904e-04\n",
      "Epoch 504/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3904e-04 - val_loss: 5.3896e-04\n",
      "Epoch 505/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3896e-04 - val_loss: 5.3887e-04\n",
      "Epoch 506/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3887e-04 - val_loss: 5.3879e-04\n",
      "Epoch 507/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3879e-04 - val_loss: 5.3870e-04\n",
      "Epoch 508/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3870e-04 - val_loss: 5.3862e-04\n",
      "Epoch 509/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.3862e-04 - val_loss: 5.3853e-04\n",
      "Epoch 510/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3853e-04 - val_loss: 5.3844e-04\n",
      "Epoch 511/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3844e-04 - val_loss: 5.3835e-04\n",
      "Epoch 512/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.3835e-04 - val_loss: 5.3826e-04\n",
      "Epoch 513/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3826e-04 - val_loss: 5.3817e-04\n",
      "Epoch 514/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3817e-04 - val_loss: 5.3808e-04\n",
      "Epoch 515/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3808e-04 - val_loss: 5.3799e-04\n",
      "Epoch 516/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3799e-04 - val_loss: 5.3789e-04\n",
      "Epoch 517/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3789e-04 - val_loss: 5.3779e-04\n",
      "Epoch 518/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3779e-04 - val_loss: 5.3770e-04\n",
      "Epoch 519/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3770e-04 - val_loss: 5.3760e-04\n",
      "Epoch 520/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3760e-04 - val_loss: 5.3750e-04\n",
      "Epoch 521/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3750e-04 - val_loss: 5.3739e-04\n",
      "Epoch 522/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3739e-04 - val_loss: 5.3729e-04\n",
      "Epoch 523/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3729e-04 - val_loss: 5.3718e-04\n",
      "Epoch 524/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3718e-04 - val_loss: 5.3707e-04\n",
      "Epoch 525/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3707e-04 - val_loss: 5.3696e-04\n",
      "Epoch 526/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3696e-04 - val_loss: 5.3684e-04\n",
      "Epoch 527/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3684e-04 - val_loss: 5.3672e-04\n",
      "Epoch 528/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3672e-04 - val_loss: 5.3660e-04\n",
      "Epoch 529/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.3660e-04 - val_loss: 5.3648e-04\n",
      "Epoch 530/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3648e-04 - val_loss: 5.3635e-04\n",
      "Epoch 531/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3635e-04 - val_loss: 5.3623e-04\n",
      "Epoch 532/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.3623e-04 - val_loss: 5.3609e-04\n",
      "Epoch 533/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3609e-04 - val_loss: 5.3596e-04\n",
      "Epoch 534/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3596e-04 - val_loss: 5.3582e-04\n",
      "Epoch 535/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3582e-04 - val_loss: 5.3568e-04\n",
      "Epoch 536/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3568e-04 - val_loss: 5.3554e-04\n",
      "Epoch 537/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3554e-04 - val_loss: 5.3539e-04\n",
      "Epoch 538/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3539e-04 - val_loss: 5.3524e-04\n",
      "Epoch 539/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3524e-04 - val_loss: 5.3508e-04\n",
      "Epoch 540/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3508e-04 - val_loss: 5.3492e-04\n",
      "Epoch 541/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3492e-04 - val_loss: 5.3476e-04\n",
      "Epoch 542/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3476e-04 - val_loss: 5.3459e-04\n",
      "Epoch 543/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3459e-04 - val_loss: 5.3442e-04\n",
      "Epoch 544/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3442e-04 - val_loss: 5.3424e-04\n",
      "Epoch 545/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3424e-04 - val_loss: 5.3406e-04\n",
      "Epoch 546/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3406e-04 - val_loss: 5.3387e-04\n",
      "Epoch 547/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3387e-04 - val_loss: 5.3368e-04\n",
      "Epoch 548/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3368e-04 - val_loss: 5.3349e-04\n",
      "Epoch 549/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3349e-04 - val_loss: 5.3329e-04\n",
      "Epoch 550/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3329e-04 - val_loss: 5.3308e-04\n",
      "Epoch 551/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3308e-04 - val_loss: 5.3287e-04\n",
      "Epoch 552/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.3287e-04 - val_loss: 5.3265e-04\n",
      "Epoch 553/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3265e-04 - val_loss: 5.3242e-04\n",
      "Epoch 554/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3242e-04 - val_loss: 5.3219e-04\n",
      "Epoch 555/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.3219e-04 - val_loss: 5.3195e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3195e-04 - val_loss: 5.3171e-04\n",
      "Epoch 557/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.3171e-04 - val_loss: 5.3146e-04\n",
      "Epoch 558/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.3146e-04 - val_loss: 5.3120e-04\n",
      "Epoch 559/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3120e-04 - val_loss: 5.3093e-04\n",
      "Epoch 560/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.3093e-04 - val_loss: 5.3066e-04\n",
      "Epoch 561/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.3066e-04 - val_loss: 5.3037e-04\n",
      "Epoch 562/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3037e-04 - val_loss: 5.3008e-04\n",
      "Epoch 563/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.3008e-04 - val_loss: 5.2978e-04\n",
      "Epoch 564/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2978e-04 - val_loss: 5.2947e-04\n",
      "Epoch 565/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.2947e-04 - val_loss: 5.2915e-04\n",
      "Epoch 566/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2915e-04 - val_loss: 5.2882e-04\n",
      "Epoch 567/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.2882e-04 - val_loss: 5.2848e-04\n",
      "Epoch 568/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.2848e-04 - val_loss: 5.2814e-04\n",
      "Epoch 569/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2814e-04 - val_loss: 5.2777e-04\n",
      "Epoch 570/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2777e-04 - val_loss: 5.2740e-04\n",
      "Epoch 571/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.2740e-04 - val_loss: 5.2702e-04\n",
      "Epoch 572/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.2702e-04 - val_loss: 5.2662e-04\n",
      "Epoch 573/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.2662e-04 - val_loss: 5.2622e-04\n",
      "Epoch 574/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.2622e-04 - val_loss: 5.2580e-04\n",
      "Epoch 575/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2580e-04 - val_loss: 5.2536e-04\n",
      "Epoch 576/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.2536e-04 - val_loss: 5.2492e-04\n",
      "Epoch 577/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.2492e-04 - val_loss: 5.2446e-04\n",
      "Epoch 578/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.2446e-04 - val_loss: 5.2398e-04\n",
      "Epoch 579/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.2398e-04 - val_loss: 5.2350e-04\n",
      "Epoch 580/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.2350e-04 - val_loss: 5.2299e-04\n",
      "Epoch 581/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2299e-04 - val_loss: 5.2248e-04\n",
      "Epoch 582/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.2248e-04 - val_loss: 5.2195e-04\n",
      "Epoch 583/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2195e-04 - val_loss: 5.2140e-04\n",
      "Epoch 584/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.2140e-04 - val_loss: 5.2085e-04\n",
      "Epoch 585/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.2085e-04 - val_loss: 5.2027e-04\n",
      "Epoch 586/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2027e-04 - val_loss: 5.1969e-04\n",
      "Epoch 587/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.1969e-04 - val_loss: 5.1909e-04\n",
      "Epoch 588/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.1909e-04 - val_loss: 5.1848e-04\n",
      "Epoch 589/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.1848e-04 - val_loss: 5.1785e-04\n",
      "Epoch 590/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.1785e-04 - val_loss: 5.1722e-04\n",
      "Epoch 591/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.1722e-04 - val_loss: 5.1658e-04\n",
      "Epoch 592/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.1658e-04 - val_loss: 5.1593e-04\n",
      "Epoch 593/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1593e-04 - val_loss: 5.1527e-04\n",
      "Epoch 594/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1527e-04 - val_loss: 5.1461e-04\n",
      "Epoch 595/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1461e-04 - val_loss: 5.1395e-04\n",
      "Epoch 596/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1395e-04 - val_loss: 5.1329e-04\n",
      "Epoch 597/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1329e-04 - val_loss: 5.1263e-04\n",
      "Epoch 598/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.1263e-04 - val_loss: 5.1199e-04\n",
      "Epoch 599/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.1199e-04 - val_loss: 5.1135e-04\n",
      "Epoch 600/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1135e-04 - val_loss: 5.1072e-04\n",
      "Epoch 601/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1072e-04 - val_loss: 5.1012e-04\n",
      "Epoch 602/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.1012e-04 - val_loss: 5.0953e-04\n",
      "Epoch 603/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0953e-04 - val_loss: 5.0898e-04\n",
      "Epoch 604/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0898e-04 - val_loss: 5.0845e-04\n",
      "Epoch 605/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0845e-04 - val_loss: 5.0796e-04\n",
      "Epoch 606/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0796e-04 - val_loss: 5.0751e-04\n",
      "Epoch 607/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0751e-04 - val_loss: 5.0710e-04\n",
      "Epoch 608/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0710e-04 - val_loss: 5.0673e-04\n",
      "Epoch 609/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0673e-04 - val_loss: 5.0641e-04\n",
      "Epoch 610/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0641e-04 - val_loss: 5.0613e-04\n",
      "Epoch 611/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0613e-04 - val_loss: 5.0590e-04\n",
      "Epoch 612/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0590e-04 - val_loss: 5.0572e-04\n",
      "Epoch 613/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0572e-04 - val_loss: 5.0558e-04\n",
      "Epoch 614/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0558e-04 - val_loss: 5.0548e-04\n",
      "Epoch 615/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0548e-04 - val_loss: 5.0541e-04\n",
      "Epoch 616/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0541e-04 - val_loss: 5.0537e-04\n",
      "Epoch 617/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0537e-04 - val_loss: 5.0535e-04\n",
      "Epoch 618/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0535e-04 - val_loss: 5.0536e-04\n",
      "Epoch 619/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0536e-04 - val_loss: 5.0537e-04\n",
      "Epoch 620/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0537e-04 - val_loss: 5.0539e-04\n",
      "Epoch 621/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0539e-04 - val_loss: 5.0542e-04\n",
      "Epoch 622/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0542e-04 - val_loss: 5.0544e-04\n",
      "Epoch 623/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0544e-04 - val_loss: 5.0545e-04\n",
      "Epoch 624/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0545e-04 - val_loss: 5.0546e-04\n",
      "Epoch 625/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0546e-04 - val_loss: 5.0545e-04\n",
      "Epoch 626/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0545e-04 - val_loss: 5.0544e-04\n",
      "Epoch 627/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0544e-04 - val_loss: 5.0541e-04\n",
      "Epoch 628/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0541e-04 - val_loss: 5.0538e-04\n",
      "Epoch 629/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0538e-04 - val_loss: 5.0536e-04\n",
      "Epoch 630/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0536e-04 - val_loss: 5.0540e-04\n",
      "Epoch 631/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0540e-04 - val_loss: 5.0580e-04\n",
      "Epoch 632/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0580e-04 - val_loss: 5.0785e-04\n",
      "Epoch 633/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0785e-04 - val_loss: 5.1600e-04\n",
      "Epoch 634/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1600e-04 - val_loss: 5.3276e-04\n",
      "Epoch 635/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.3276e-04 - val_loss: 5.2725e-04\n",
      "Epoch 636/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.2725e-04 - val_loss: 5.0600e-04\n",
      "Epoch 637/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0600e-04 - val_loss: 5.2096e-04\n",
      "Epoch 638/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.2096e-04 - val_loss: 5.0736e-04\n",
      "Epoch 639/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0736e-04 - val_loss: 5.1734e-04\n",
      "Epoch 640/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.1734e-04 - val_loss: 5.0927e-04\n",
      "Epoch 641/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0927e-04 - val_loss: 5.1322e-04\n",
      "Epoch 642/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.1322e-04 - val_loss: 5.1207e-04\n",
      "Epoch 643/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.1207e-04 - val_loss: 5.0873e-04\n",
      "Epoch 644/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0873e-04 - val_loss: 5.1248e-04\n",
      "Epoch 645/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.1248e-04 - val_loss: 5.0710e-04\n",
      "Epoch 646/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0710e-04 - val_loss: 5.0975e-04\n",
      "Epoch 647/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0975e-04 - val_loss: 5.0737e-04\n",
      "Epoch 648/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0737e-04 - val_loss: 5.0715e-04\n",
      "Epoch 649/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0715e-04 - val_loss: 5.0767e-04\n",
      "Epoch 650/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0767e-04 - val_loss: 5.0618e-04\n",
      "Epoch 651/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0618e-04 - val_loss: 5.0764e-04\n",
      "Epoch 652/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0764e-04 - val_loss: 5.0627e-04\n",
      "Epoch 653/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0627e-04 - val_loss: 5.0723e-04\n",
      "Epoch 654/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0723e-04 - val_loss: 5.0641e-04\n",
      "Epoch 655/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0641e-04 - val_loss: 5.0653e-04\n",
      "Epoch 656/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0653e-04 - val_loss: 5.0611e-04\n",
      "Epoch 657/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0611e-04 - val_loss: 5.0595e-04\n",
      "Epoch 658/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0595e-04 - val_loss: 5.0556e-04\n",
      "Epoch 659/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0556e-04 - val_loss: 5.0574e-04\n",
      "Epoch 660/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0574e-04 - val_loss: 5.0514e-04\n",
      "Epoch 661/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0514e-04 - val_loss: 5.0576e-04\n",
      "Epoch 662/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0576e-04 - val_loss: 5.0495e-04\n",
      "Epoch 663/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0495e-04 - val_loss: 5.0570e-04\n",
      "Epoch 664/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0570e-04 - val_loss: 5.0496e-04\n",
      "Epoch 665/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0496e-04 - val_loss: 5.0540e-04\n",
      "Epoch 666/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0540e-04 - val_loss: 5.0501e-04\n",
      "Epoch 667/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0501e-04 - val_loss: 5.0500e-04\n",
      "Epoch 668/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0500e-04 - val_loss: 5.0500e-04\n",
      "Epoch 669/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0500e-04 - val_loss: 5.0470e-04\n",
      "Epoch 670/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0470e-04 - val_loss: 5.0493e-04\n",
      "Epoch 671/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0493e-04 - val_loss: 5.0458e-04\n",
      "Epoch 672/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0458e-04 - val_loss: 5.0488e-04\n",
      "Epoch 673/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 5.0488e-04 - val_loss: 5.0456e-04\n",
      "Epoch 674/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0456e-04 - val_loss: 5.0484e-04\n",
      "Epoch 675/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0484e-04 - val_loss: 5.0455e-04\n",
      "Epoch 676/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0455e-04 - val_loss: 5.0476e-04\n",
      "Epoch 677/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0476e-04 - val_loss: 5.0451e-04\n",
      "Epoch 678/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0451e-04 - val_loss: 5.0465e-04\n",
      "Epoch 679/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0465e-04 - val_loss: 5.0447e-04\n",
      "Epoch 680/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0447e-04 - val_loss: 5.0456e-04\n",
      "Epoch 681/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0456e-04 - val_loss: 5.0446e-04\n",
      "Epoch 682/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0446e-04 - val_loss: 5.0450e-04\n",
      "Epoch 683/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0450e-04 - val_loss: 5.0446e-04\n",
      "Epoch 684/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0446e-04 - val_loss: 5.0445e-04\n",
      "Epoch 685/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0445e-04 - val_loss: 5.0445e-04\n",
      "Epoch 686/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0445e-04 - val_loss: 5.0439e-04\n",
      "Epoch 687/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0439e-04 - val_loss: 5.0442e-04\n",
      "Epoch 688/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0442e-04 - val_loss: 5.0434e-04\n",
      "Epoch 689/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0434e-04 - val_loss: 5.0438e-04\n",
      "Epoch 690/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0438e-04 - val_loss: 5.0431e-04\n",
      "Epoch 691/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0431e-04 - val_loss: 5.0435e-04\n",
      "Epoch 692/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0435e-04 - val_loss: 5.0430e-04\n",
      "Epoch 693/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0430e-04 - val_loss: 5.0432e-04\n",
      "Epoch 694/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0432e-04 - val_loss: 5.0428e-04\n",
      "Epoch 695/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0428e-04 - val_loss: 5.0429e-04\n",
      "Epoch 696/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.0429e-04 - val_loss: 5.0426e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0426e-04 - val_loss: 5.0426e-04\n",
      "Epoch 698/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0426e-04 - val_loss: 5.0424e-04\n",
      "Epoch 699/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0424e-04 - val_loss: 5.0424e-04\n",
      "Epoch 700/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0424e-04 - val_loss: 5.0423e-04\n",
      "Epoch 701/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0423e-04 - val_loss: 5.0422e-04\n",
      "Epoch 702/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0422e-04 - val_loss: 5.0421e-04\n",
      "Epoch 703/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0421e-04 - val_loss: 5.0420e-04\n",
      "Epoch 704/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0420e-04 - val_loss: 5.0420e-04\n",
      "Epoch 705/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0420e-04 - val_loss: 5.0418e-04\n",
      "Epoch 706/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0418e-04 - val_loss: 5.0418e-04\n",
      "Epoch 707/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0418e-04 - val_loss: 5.0417e-04\n",
      "Epoch 708/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0417e-04 - val_loss: 5.0417e-04\n",
      "Epoch 709/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0417e-04 - val_loss: 5.0415e-04\n",
      "Epoch 710/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0415e-04 - val_loss: 5.0415e-04\n",
      "Epoch 711/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0415e-04 - val_loss: 5.0414e-04\n",
      "Epoch 712/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0414e-04 - val_loss: 5.0414e-04\n",
      "Epoch 713/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0414e-04 - val_loss: 5.0413e-04\n",
      "Epoch 714/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0413e-04 - val_loss: 5.0412e-04\n",
      "Epoch 715/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0412e-04 - val_loss: 5.0412e-04\n",
      "Epoch 716/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0412e-04 - val_loss: 5.0411e-04\n",
      "Epoch 717/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0411e-04 - val_loss: 5.0410e-04\n",
      "Epoch 718/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0410e-04 - val_loss: 5.0410e-04\n",
      "Epoch 719/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0410e-04 - val_loss: 5.0409e-04\n",
      "Epoch 720/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0409e-04 - val_loss: 5.0409e-04\n",
      "Epoch 721/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0409e-04 - val_loss: 5.0408e-04\n",
      "Epoch 722/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0408e-04 - val_loss: 5.0408e-04\n",
      "Epoch 723/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0408e-04 - val_loss: 5.0407e-04\n",
      "Epoch 724/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0407e-04 - val_loss: 5.0406e-04\n",
      "Epoch 725/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0406e-04 - val_loss: 5.0406e-04\n",
      "Epoch 726/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0406e-04 - val_loss: 5.0405e-04\n",
      "Epoch 727/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0405e-04 - val_loss: 5.0405e-04\n",
      "Epoch 728/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0405e-04 - val_loss: 5.0404e-04\n",
      "Epoch 729/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0404e-04 - val_loss: 5.0404e-04\n",
      "Epoch 730/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0404e-04 - val_loss: 5.0403e-04\n",
      "Epoch 731/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0403e-04 - val_loss: 5.0403e-04\n",
      "Epoch 732/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0403e-04 - val_loss: 5.0402e-04\n",
      "Epoch 733/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0402e-04 - val_loss: 5.0402e-04\n",
      "Epoch 734/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0402e-04 - val_loss: 5.0401e-04\n",
      "Epoch 735/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0401e-04 - val_loss: 5.0401e-04\n",
      "Epoch 736/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0401e-04 - val_loss: 5.0400e-04\n",
      "Epoch 737/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0400e-04 - val_loss: 5.0400e-04\n",
      "Epoch 738/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0400e-04 - val_loss: 5.0399e-04\n",
      "Epoch 739/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0399e-04 - val_loss: 5.0399e-04\n",
      "Epoch 740/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0399e-04 - val_loss: 5.0398e-04\n",
      "Epoch 741/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0398e-04 - val_loss: 5.0398e-04\n",
      "Epoch 742/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0398e-04 - val_loss: 5.0397e-04\n",
      "Epoch 743/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0397e-04 - val_loss: 5.0397e-04\n",
      "Epoch 744/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0397e-04 - val_loss: 5.0396e-04\n",
      "Epoch 745/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0396e-04 - val_loss: 5.0396e-04\n",
      "Epoch 746/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0396e-04 - val_loss: 5.0395e-04\n",
      "Epoch 747/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0395e-04 - val_loss: 5.0395e-04\n",
      "Epoch 748/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0395e-04 - val_loss: 5.0394e-04\n",
      "Epoch 749/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0394e-04 - val_loss: 5.0394e-04\n",
      "Epoch 750/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0394e-04 - val_loss: 5.0393e-04\n",
      "Epoch 751/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.0393e-04 - val_loss: 5.0393e-04\n",
      "Epoch 752/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0393e-04 - val_loss: 5.0392e-04\n",
      "Epoch 753/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0392e-04 - val_loss: 5.0392e-04\n",
      "Epoch 754/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0392e-04 - val_loss: 5.0391e-04\n",
      "Epoch 755/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0391e-04 - val_loss: 5.0391e-04\n",
      "Epoch 756/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0391e-04 - val_loss: 5.0390e-04\n",
      "Epoch 757/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0390e-04 - val_loss: 5.0390e-04\n",
      "Epoch 758/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0390e-04 - val_loss: 5.0389e-04\n",
      "Epoch 759/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0389e-04 - val_loss: 5.0389e-04\n",
      "Epoch 760/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0389e-04 - val_loss: 5.0388e-04\n",
      "Epoch 761/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0388e-04 - val_loss: 5.0388e-04\n",
      "Epoch 762/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0388e-04 - val_loss: 5.0387e-04\n",
      "Epoch 763/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0387e-04 - val_loss: 5.0387e-04\n",
      "Epoch 764/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0387e-04 - val_loss: 5.0386e-04\n",
      "Epoch 765/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0386e-04 - val_loss: 5.0386e-04\n",
      "Epoch 766/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0386e-04 - val_loss: 5.0385e-04\n",
      "Epoch 767/900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0385e-04 - val_loss: 5.0385e-04\n",
      "Epoch 768/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0385e-04 - val_loss: 5.0384e-04\n",
      "Epoch 769/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0384e-04 - val_loss: 5.0384e-04\n",
      "Epoch 770/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0384e-04 - val_loss: 5.0383e-04\n",
      "Epoch 771/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0383e-04 - val_loss: 5.0383e-04\n",
      "Epoch 772/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0383e-04 - val_loss: 5.0382e-04\n",
      "Epoch 773/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0382e-04 - val_loss: 5.0382e-04\n",
      "Epoch 774/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0382e-04 - val_loss: 5.0381e-04\n",
      "Epoch 775/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0381e-04 - val_loss: 5.0381e-04\n",
      "Epoch 776/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0380e-04 - val_loss: 5.0380e-04\n",
      "Epoch 777/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0380e-04 - val_loss: 5.0379e-04\n",
      "Epoch 778/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0379e-04 - val_loss: 5.0379e-04\n",
      "Epoch 779/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0379e-04 - val_loss: 5.0378e-04\n",
      "Epoch 780/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0378e-04 - val_loss: 5.0378e-04\n",
      "Epoch 781/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0378e-04 - val_loss: 5.0377e-04\n",
      "Epoch 782/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0377e-04 - val_loss: 5.0377e-04\n",
      "Epoch 783/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0377e-04 - val_loss: 5.0376e-04\n",
      "Epoch 784/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0376e-04 - val_loss: 5.0375e-04\n",
      "Epoch 785/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0375e-04 - val_loss: 5.0375e-04\n",
      "Epoch 786/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0375e-04 - val_loss: 5.0374e-04\n",
      "Epoch 787/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0374e-04 - val_loss: 5.0374e-04\n",
      "Epoch 788/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0374e-04 - val_loss: 5.0373e-04\n",
      "Epoch 789/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0373e-04 - val_loss: 5.0373e-04\n",
      "Epoch 790/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0373e-04 - val_loss: 5.0372e-04\n",
      "Epoch 791/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0372e-04 - val_loss: 5.0371e-04\n",
      "Epoch 792/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0371e-04 - val_loss: 5.0371e-04\n",
      "Epoch 793/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0371e-04 - val_loss: 5.0370e-04\n",
      "Epoch 794/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0370e-04 - val_loss: 5.0370e-04\n",
      "Epoch 795/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0370e-04 - val_loss: 5.0369e-04\n",
      "Epoch 796/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0369e-04 - val_loss: 5.0368e-04\n",
      "Epoch 797/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0368e-04 - val_loss: 5.0368e-04\n",
      "Epoch 798/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0368e-04 - val_loss: 5.0367e-04\n",
      "Epoch 799/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0367e-04 - val_loss: 5.0366e-04\n",
      "Epoch 800/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0366e-04 - val_loss: 5.0366e-04\n",
      "Epoch 801/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0366e-04 - val_loss: 5.0365e-04\n",
      "Epoch 802/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0365e-04 - val_loss: 5.0365e-04\n",
      "Epoch 803/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0365e-04 - val_loss: 5.0364e-04\n",
      "Epoch 804/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0364e-04 - val_loss: 5.0363e-04\n",
      "Epoch 805/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0363e-04 - val_loss: 5.0363e-04\n",
      "Epoch 806/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0363e-04 - val_loss: 5.0362e-04\n",
      "Epoch 807/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0362e-04 - val_loss: 5.0361e-04\n",
      "Epoch 808/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0361e-04 - val_loss: 5.0361e-04\n",
      "Epoch 809/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0361e-04 - val_loss: 5.0360e-04\n",
      "Epoch 810/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0360e-04 - val_loss: 5.0359e-04\n",
      "Epoch 811/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0359e-04 - val_loss: 5.0359e-04\n",
      "Epoch 812/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0359e-04 - val_loss: 5.0358e-04\n",
      "Epoch 813/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0358e-04 - val_loss: 5.0357e-04\n",
      "Epoch 814/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0357e-04 - val_loss: 5.0357e-04\n",
      "Epoch 815/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0357e-04 - val_loss: 5.0356e-04\n",
      "Epoch 816/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0356e-04 - val_loss: 5.0355e-04\n",
      "Epoch 817/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0355e-04 - val_loss: 5.0354e-04\n",
      "Epoch 818/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0354e-04 - val_loss: 5.0354e-04\n",
      "Epoch 819/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0354e-04 - val_loss: 5.0353e-04\n",
      "Epoch 820/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0353e-04 - val_loss: 5.0352e-04\n",
      "Epoch 821/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0352e-04 - val_loss: 5.0352e-04\n",
      "Epoch 822/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0352e-04 - val_loss: 5.0351e-04\n",
      "Epoch 823/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0351e-04 - val_loss: 5.0350e-04\n",
      "Epoch 824/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0350e-04 - val_loss: 5.0349e-04\n",
      "Epoch 825/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0349e-04 - val_loss: 5.0348e-04\n",
      "Epoch 826/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0348e-04 - val_loss: 5.0348e-04\n",
      "Epoch 827/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.0348e-04 - val_loss: 5.0347e-04\n",
      "Epoch 828/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0347e-04 - val_loss: 5.0346e-04\n",
      "Epoch 829/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0346e-04 - val_loss: 5.0345e-04\n",
      "Epoch 830/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0345e-04 - val_loss: 5.0345e-04\n",
      "Epoch 831/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.0345e-04 - val_loss: 5.0344e-04\n",
      "Epoch 832/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0344e-04 - val_loss: 5.0343e-04\n",
      "Epoch 833/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0343e-04 - val_loss: 5.0342e-04\n",
      "Epoch 834/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0342e-04 - val_loss: 5.0341e-04\n",
      "Epoch 835/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0341e-04 - val_loss: 5.0340e-04\n",
      "Epoch 836/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 5.0340e-04 - val_loss: 5.0340e-04\n",
      "Epoch 837/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0340e-04 - val_loss: 5.0339e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 838/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0339e-04 - val_loss: 5.0338e-04\n",
      "Epoch 839/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0338e-04 - val_loss: 5.0337e-04\n",
      "Epoch 840/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0337e-04 - val_loss: 5.0336e-04\n",
      "Epoch 841/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0336e-04 - val_loss: 5.0335e-04\n",
      "Epoch 842/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0335e-04 - val_loss: 5.0334e-04\n",
      "Epoch 843/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0334e-04 - val_loss: 5.0333e-04\n",
      "Epoch 844/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 5.0333e-04 - val_loss: 5.0332e-04\n",
      "Epoch 845/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0332e-04 - val_loss: 5.0332e-04\n",
      "Epoch 846/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0332e-04 - val_loss: 5.0331e-04\n",
      "Epoch 847/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0331e-04 - val_loss: 5.0330e-04\n",
      "Epoch 848/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0330e-04 - val_loss: 5.0329e-04\n",
      "Epoch 849/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 5.0329e-04 - val_loss: 5.0328e-04\n",
      "Epoch 850/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0328e-04 - val_loss: 5.0327e-04\n",
      "Epoch 851/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0327e-04 - val_loss: 5.0326e-04\n",
      "Epoch 852/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 5.0326e-04 - val_loss: 5.0325e-04\n",
      "Epoch 853/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0325e-04 - val_loss: 5.0324e-04\n",
      "Epoch 854/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0324e-04 - val_loss: 5.0323e-04\n",
      "Epoch 855/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0323e-04 - val_loss: 5.0322e-04\n",
      "Epoch 856/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0322e-04 - val_loss: 5.0321e-04\n",
      "Epoch 857/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0321e-04 - val_loss: 5.0319e-04\n",
      "Epoch 858/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.0319e-04 - val_loss: 5.0318e-04\n",
      "Epoch 859/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0318e-04 - val_loss: 5.0317e-04\n",
      "Epoch 860/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0317e-04 - val_loss: 5.0316e-04\n",
      "Epoch 861/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0316e-04 - val_loss: 5.0315e-04\n",
      "Epoch 862/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 5.0315e-04 - val_loss: 5.0314e-04\n",
      "Epoch 863/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0314e-04 - val_loss: 5.0313e-04\n",
      "Epoch 864/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0313e-04 - val_loss: 5.0312e-04\n",
      "Epoch 865/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0312e-04 - val_loss: 5.0310e-04\n",
      "Epoch 866/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0310e-04 - val_loss: 5.0309e-04\n",
      "Epoch 867/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0309e-04 - val_loss: 5.0308e-04\n",
      "Epoch 868/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0308e-04 - val_loss: 5.0307e-04\n",
      "Epoch 869/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0307e-04 - val_loss: 5.0305e-04\n",
      "Epoch 870/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0305e-04 - val_loss: 5.0304e-04\n",
      "Epoch 871/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0304e-04 - val_loss: 5.0303e-04\n",
      "Epoch 872/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0303e-04 - val_loss: 5.0301e-04\n",
      "Epoch 873/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0301e-04 - val_loss: 5.0300e-04\n",
      "Epoch 874/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0300e-04 - val_loss: 5.0299e-04\n",
      "Epoch 875/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0299e-04 - val_loss: 5.0297e-04\n",
      "Epoch 876/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0297e-04 - val_loss: 5.0296e-04\n",
      "Epoch 877/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 5.0296e-04 - val_loss: 5.0295e-04\n",
      "Epoch 878/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 5.0295e-04 - val_loss: 5.0293e-04\n",
      "Epoch 879/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 5.0293e-04 - val_loss: 5.0292e-04\n",
      "Epoch 880/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 5.0292e-04 - val_loss: 5.0290e-04\n",
      "Epoch 881/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0290e-04 - val_loss: 5.0289e-04\n",
      "Epoch 882/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0289e-04 - val_loss: 5.0287e-04\n",
      "Epoch 883/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0287e-04 - val_loss: 5.0285e-04\n",
      "Epoch 884/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0285e-04 - val_loss: 5.0284e-04\n",
      "Epoch 885/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 5.0284e-04 - val_loss: 5.0282e-04\n",
      "Epoch 886/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 5.0282e-04 - val_loss: 5.0281e-04\n",
      "Epoch 887/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0281e-04 - val_loss: 5.0279e-04\n",
      "Epoch 888/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0279e-04 - val_loss: 5.0277e-04\n",
      "Epoch 889/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0277e-04 - val_loss: 5.0275e-04\n",
      "Epoch 890/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0275e-04 - val_loss: 5.0274e-04\n",
      "Epoch 891/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 5.0274e-04 - val_loss: 5.0272e-04\n",
      "Epoch 892/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0272e-04 - val_loss: 5.0270e-04\n",
      "Epoch 893/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0270e-04 - val_loss: 5.0268e-04\n",
      "Epoch 894/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 5.0268e-04 - val_loss: 5.0266e-04\n",
      "Epoch 895/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0266e-04 - val_loss: 5.0264e-04\n",
      "Epoch 896/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 5.0264e-04 - val_loss: 5.0262e-04\n",
      "Epoch 897/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 5.0262e-04 - val_loss: 5.0260e-04\n",
      "Epoch 898/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 5.0260e-04 - val_loss: 5.0258e-04\n",
      "Epoch 899/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 5.0258e-04 - val_loss: 5.0256e-04\n",
      "Epoch 900/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 5.0256e-04 - val_loss: 5.0254e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_5)\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=900, validation_data=(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), tight_layout=True)\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.set_title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sampling a 1: 0.506\n",
      "Probability of sampling a 0: 0.494\n"
     ]
    }
   ],
   "source": [
    "# Mapping labels to categorical labels\n",
    "def to_categorical(el):\n",
    "    if el > 0:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = 0\n",
    "    return c\n",
    "\n",
    "y_cls = np.array(list(map(to_categorical, y)))\n",
    "print('Probability of sampling a 1: {}'.format(y_cls.sum()/len(y_cls)))\n",
    "print('Probability of sampling a 0: {}'.format((len(y_cls) - y_cls.sum())/len(y_cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/900\n",
      "1000/1000 [==============================] - 6s 6ms/sample - loss: 0.6931 - binary_accuracy: 0.4850 - precision: 0.4909 - recall: 0.4783 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 2/900\n",
      "1000/1000 [==============================] - 0s 80us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 3/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 4/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 5/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 6/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 7/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 8/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 9/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 10/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 11/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 12/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 13/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 14/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 15/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 16/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 17/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 18/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 19/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 20/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 21/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 22/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 23/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 24/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 25/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 26/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 27/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 28/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 30/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 31/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 32/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 33/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 34/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 35/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6931 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 36/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6931 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 37/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 38/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 39/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 40/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 41/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 42/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 43/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 44/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6930 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 1.0000\n",
      "Epoch 45/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 1.0000 - val_loss: 0.6929 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 0.9980\n",
      "Epoch 46/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6929 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 0.9980 - val_loss: 0.6929 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 0.9960\n",
      "Epoch 47/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6929 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 0.9960 - val_loss: 0.6929 - val_binary_accuracy: 0.5060 - val_precision: 0.5060 - val_recall: 0.9960\n",
      "Epoch 48/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6929 - binary_accuracy: 0.5060 - precision: 0.5060 - recall: 0.9960 - val_loss: 0.6928 - val_binary_accuracy: 0.5110 - val_precision: 0.5086 - val_recall: 0.9960\n",
      "Epoch 49/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6928 - binary_accuracy: 0.5110 - precision: 0.5086 - recall: 0.9960 - val_loss: 0.6928 - val_binary_accuracy: 0.5090 - val_precision: 0.5079 - val_recall: 0.9565\n",
      "Epoch 50/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6928 - binary_accuracy: 0.5090 - precision: 0.5079 - recall: 0.9565 - val_loss: 0.6927 - val_binary_accuracy: 0.5110 - val_precision: 0.5086 - val_recall: 0.9960\n",
      "Epoch 51/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6927 - binary_accuracy: 0.5110 - precision: 0.5086 - recall: 0.9960 - val_loss: 0.6926 - val_binary_accuracy: 0.5160 - val_precision: 0.5166 - val_recall: 0.6759\n",
      "Epoch 52/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6926 - binary_accuracy: 0.5160 - precision: 0.5166 - recall: 0.6759 - val_loss: 0.6923 - val_binary_accuracy: 0.5150 - val_precision: 0.5118 - val_recall: 0.8972\n",
      "Epoch 53/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6923 - binary_accuracy: 0.5150 - precision: 0.5118 - recall: 0.8972 - val_loss: 0.6922 - val_binary_accuracy: 0.5120 - val_precision: 0.5096 - val_recall: 0.9466\n",
      "Epoch 54/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6922 - binary_accuracy: 0.5120 - precision: 0.5096 - recall: 0.9466 - val_loss: 0.6924 - val_binary_accuracy: 0.5130 - val_precision: 0.5772 - val_recall: 0.1403\n",
      "Epoch 55/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6924 - binary_accuracy: 0.5130 - precision: 0.5772 - recall: 0.1403 - val_loss: 0.6919 - val_binary_accuracy: 0.5130 - val_precision: 0.5106 - val_recall: 0.9032\n",
      "Epoch 56/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6919 - binary_accuracy: 0.5130 - precision: 0.5106 - recall: 0.9032 - val_loss: 0.6917 - val_binary_accuracy: 0.5170 - val_precision: 0.5135 - val_recall: 0.8617\n",
      "Epoch 57/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6917 - binary_accuracy: 0.5170 - precision: 0.5135 - recall: 0.8617 - val_loss: 0.6925 - val_binary_accuracy: 0.5050 - val_precision: 0.5311 - val_recall: 0.1858\n",
      "Epoch 58/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6925 - binary_accuracy: 0.5050 - precision: 0.5311 - recall: 0.1858 - val_loss: 0.6915 - val_binary_accuracy: 0.5070 - val_precision: 0.5083 - val_recall: 0.7866\n",
      "Epoch 59/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6915 - binary_accuracy: 0.5070 - precision: 0.5083 - recall: 0.7866 - val_loss: 0.6919 - val_binary_accuracy: 0.5130 - val_precision: 0.5106 - val_recall: 0.9051\n",
      "Epoch 60/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6919 - binary_accuracy: 0.5130 - precision: 0.5106 - recall: 0.9051 - val_loss: 0.6913 - val_binary_accuracy: 0.5080 - val_precision: 0.5102 - val_recall: 0.6897\n",
      "Epoch 61/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6913 - binary_accuracy: 0.5080 - precision: 0.5102 - recall: 0.6897 - val_loss: 0.6915 - val_binary_accuracy: 0.5020 - val_precision: 0.5132 - val_recall: 0.3063\n",
      "Epoch 62/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6915 - binary_accuracy: 0.5020 - precision: 0.5132 - recall: 0.3063 - val_loss: 0.6914 - val_binary_accuracy: 0.5050 - val_precision: 0.5169 - val_recall: 0.3320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6914 - binary_accuracy: 0.5050 - precision: 0.5169 - recall: 0.3320 - val_loss: 0.6911 - val_binary_accuracy: 0.5230 - val_precision: 0.5228 - val_recall: 0.6561\n",
      "Epoch 64/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6911 - binary_accuracy: 0.5230 - precision: 0.5228 - recall: 0.6561 - val_loss: 0.6911 - val_binary_accuracy: 0.5150 - val_precision: 0.5122 - val_recall: 0.8696\n",
      "Epoch 65/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6911 - binary_accuracy: 0.5150 - precision: 0.5122 - recall: 0.8696 - val_loss: 0.6911 - val_binary_accuracy: 0.5150 - val_precision: 0.5118 - val_recall: 0.8992\n",
      "Epoch 66/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6911 - binary_accuracy: 0.5150 - precision: 0.5118 - recall: 0.8992 - val_loss: 0.6907 - val_binary_accuracy: 0.5120 - val_precision: 0.5112 - val_recall: 0.8103\n",
      "Epoch 67/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6907 - binary_accuracy: 0.5120 - precision: 0.5112 - recall: 0.8103 - val_loss: 0.6905 - val_binary_accuracy: 0.5160 - val_precision: 0.5208 - val_recall: 0.5435\n",
      "Epoch 68/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6905 - binary_accuracy: 0.5160 - precision: 0.5208 - recall: 0.5435 - val_loss: 0.6904 - val_binary_accuracy: 0.5030 - val_precision: 0.5117 - val_recall: 0.3893\n",
      "Epoch 69/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6904 - binary_accuracy: 0.5030 - precision: 0.5117 - recall: 0.3893 - val_loss: 0.6900 - val_binary_accuracy: 0.5160 - val_precision: 0.5202 - val_recall: 0.5593\n",
      "Epoch 70/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6900 - binary_accuracy: 0.5160 - precision: 0.5202 - recall: 0.5593 - val_loss: 0.6899 - val_binary_accuracy: 0.5200 - val_precision: 0.5171 - val_recall: 0.7767\n",
      "Epoch 71/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6899 - binary_accuracy: 0.5200 - precision: 0.5171 - recall: 0.7767 - val_loss: 0.6895 - val_binary_accuracy: 0.5280 - val_precision: 0.5241 - val_recall: 0.7312\n",
      "Epoch 72/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6895 - binary_accuracy: 0.5280 - precision: 0.5241 - recall: 0.7312 - val_loss: 0.6892 - val_binary_accuracy: 0.5160 - val_precision: 0.5234 - val_recall: 0.4862\n",
      "Epoch 73/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6892 - binary_accuracy: 0.5160 - precision: 0.5234 - recall: 0.4862 - val_loss: 0.6888 - val_binary_accuracy: 0.5140 - val_precision: 0.5216 - val_recall: 0.4783\n",
      "Epoch 74/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6888 - binary_accuracy: 0.5140 - precision: 0.5216 - recall: 0.4783 - val_loss: 0.6883 - val_binary_accuracy: 0.5210 - val_precision: 0.5201 - val_recall: 0.6917\n",
      "Epoch 75/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6883 - binary_accuracy: 0.5210 - precision: 0.5201 - recall: 0.6917 - val_loss: 0.6880 - val_binary_accuracy: 0.5220 - val_precision: 0.5183 - val_recall: 0.7826\n",
      "Epoch 76/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6880 - binary_accuracy: 0.5220 - precision: 0.5183 - recall: 0.7826 - val_loss: 0.6874 - val_binary_accuracy: 0.5190 - val_precision: 0.5197 - val_recall: 0.6522\n",
      "Epoch 77/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6874 - binary_accuracy: 0.5190 - precision: 0.5197 - recall: 0.6522 - val_loss: 0.6870 - val_binary_accuracy: 0.5290 - val_precision: 0.5386 - val_recall: 0.4822\n",
      "Epoch 78/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6870 - binary_accuracy: 0.5290 - precision: 0.5386 - recall: 0.4822 - val_loss: 0.6864 - val_binary_accuracy: 0.5360 - val_precision: 0.5378 - val_recall: 0.5909\n",
      "Epoch 79/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6864 - binary_accuracy: 0.5360 - precision: 0.5378 - recall: 0.5909 - val_loss: 0.6861 - val_binary_accuracy: 0.5420 - val_precision: 0.5347 - val_recall: 0.7312\n",
      "Epoch 80/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6861 - binary_accuracy: 0.5420 - precision: 0.5347 - recall: 0.7312 - val_loss: 0.6856 - val_binary_accuracy: 0.5420 - val_precision: 0.5506 - val_recall: 0.5158\n",
      "Epoch 81/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6856 - binary_accuracy: 0.5420 - precision: 0.5506 - recall: 0.5158 - val_loss: 0.6852 - val_binary_accuracy: 0.5420 - val_precision: 0.5500 - val_recall: 0.5217\n",
      "Epoch 82/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6852 - binary_accuracy: 0.5420 - precision: 0.5500 - recall: 0.5217 - val_loss: 0.6848 - val_binary_accuracy: 0.5540 - val_precision: 0.5463 - val_recall: 0.6996\n",
      "Epoch 83/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6848 - binary_accuracy: 0.5540 - precision: 0.5463 - recall: 0.6996 - val_loss: 0.6841 - val_binary_accuracy: 0.5550 - val_precision: 0.5552 - val_recall: 0.6067\n",
      "Epoch 84/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6841 - binary_accuracy: 0.5550 - precision: 0.5552 - recall: 0.6067 - val_loss: 0.6835 - val_binary_accuracy: 0.5610 - val_precision: 0.5720 - val_recall: 0.5257\n",
      "Epoch 85/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6835 - binary_accuracy: 0.5610 - precision: 0.5720 - recall: 0.5257 - val_loss: 0.6826 - val_binary_accuracy: 0.5570 - val_precision: 0.5552 - val_recall: 0.6265\n",
      "Epoch 86/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6826 - binary_accuracy: 0.5570 - precision: 0.5552 - recall: 0.6265 - val_loss: 0.6818 - val_binary_accuracy: 0.5570 - val_precision: 0.5519 - val_recall: 0.6621\n",
      "Epoch 87/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6818 - binary_accuracy: 0.5570 - precision: 0.5519 - recall: 0.6621 - val_loss: 0.6810 - val_binary_accuracy: 0.5640 - val_precision: 0.5781 - val_recall: 0.5119\n",
      "Epoch 88/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6810 - binary_accuracy: 0.5640 - precision: 0.5781 - recall: 0.5119 - val_loss: 0.6801 - val_binary_accuracy: 0.5680 - val_precision: 0.5615 - val_recall: 0.6680\n",
      "Epoch 89/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6801 - binary_accuracy: 0.5680 - precision: 0.5615 - recall: 0.6680 - val_loss: 0.6793 - val_binary_accuracy: 0.5670 - val_precision: 0.5672 - val_recall: 0.6087\n",
      "Epoch 90/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6793 - binary_accuracy: 0.5670 - precision: 0.5672 - recall: 0.6087 - val_loss: 0.6788 - val_binary_accuracy: 0.5630 - val_precision: 0.5729 - val_recall: 0.5356\n",
      "Epoch 91/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6788 - binary_accuracy: 0.5630 - precision: 0.5729 - recall: 0.5356 - val_loss: 0.6789 - val_binary_accuracy: 0.5550 - val_precision: 0.5461 - val_recall: 0.7134\n",
      "Epoch 92/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6789 - binary_accuracy: 0.5550 - precision: 0.5461 - recall: 0.7134 - val_loss: 0.6810 - val_binary_accuracy: 0.5430 - val_precision: 0.5968 - val_recall: 0.2984\n",
      "Epoch 93/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6810 - binary_accuracy: 0.5430 - precision: 0.5968 - recall: 0.2984 - val_loss: 0.6799 - val_binary_accuracy: 0.5590 - val_precision: 0.5470 - val_recall: 0.7470\n",
      "Epoch 94/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6799 - binary_accuracy: 0.5590 - precision: 0.5470 - recall: 0.7470 - val_loss: 0.6796 - val_binary_accuracy: 0.5630 - val_precision: 0.5522 - val_recall: 0.7213\n",
      "Epoch 95/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6796 - binary_accuracy: 0.5630 - precision: 0.5522 - recall: 0.7213 - val_loss: 0.6796 - val_binary_accuracy: 0.5780 - val_precision: 0.6186 - val_recall: 0.4328\n",
      "Epoch 96/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6796 - binary_accuracy: 0.5780 - precision: 0.6186 - recall: 0.4328 - val_loss: 0.6782 - val_binary_accuracy: 0.5840 - val_precision: 0.5991 - val_recall: 0.5375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6782 - binary_accuracy: 0.5840 - precision: 0.5991 - recall: 0.5375 - val_loss: 0.6801 - val_binary_accuracy: 0.5470 - val_precision: 0.5381 - val_recall: 0.7391\n",
      "Epoch 98/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6801 - binary_accuracy: 0.5470 - precision: 0.5381 - recall: 0.7391 - val_loss: 0.6779 - val_binary_accuracy: 0.5770 - val_precision: 0.5870 - val_recall: 0.5534\n",
      "Epoch 99/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6779 - binary_accuracy: 0.5770 - precision: 0.5870 - recall: 0.5534 - val_loss: 0.6785 - val_binary_accuracy: 0.5910 - val_precision: 0.6228 - val_recall: 0.4862\n",
      "Epoch 100/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6785 - binary_accuracy: 0.5910 - precision: 0.6228 - recall: 0.4862 - val_loss: 0.6775 - val_binary_accuracy: 0.5730 - val_precision: 0.5727 - val_recall: 0.6146\n",
      "Epoch 101/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6775 - binary_accuracy: 0.5730 - precision: 0.5727 - recall: 0.6146 - val_loss: 0.6780 - val_binary_accuracy: 0.5550 - val_precision: 0.5455 - val_recall: 0.7233\n",
      "Epoch 102/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6780 - binary_accuracy: 0.5550 - precision: 0.5455 - recall: 0.7233 - val_loss: 0.6775 - val_binary_accuracy: 0.5620 - val_precision: 0.5531 - val_recall: 0.6996\n",
      "Epoch 103/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6775 - binary_accuracy: 0.5620 - precision: 0.5531 - recall: 0.6996 - val_loss: 0.6770 - val_binary_accuracy: 0.5800 - val_precision: 0.5843 - val_recall: 0.5889\n",
      "Epoch 104/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6770 - binary_accuracy: 0.5800 - precision: 0.5843 - recall: 0.5889 - val_loss: 0.6774 - val_binary_accuracy: 0.5760 - val_precision: 0.6030 - val_recall: 0.4743\n",
      "Epoch 105/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6774 - binary_accuracy: 0.5760 - precision: 0.6030 - recall: 0.4743 - val_loss: 0.6768 - val_binary_accuracy: 0.5620 - val_precision: 0.5620 - val_recall: 0.6087\n",
      "Epoch 106/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6768 - binary_accuracy: 0.5620 - precision: 0.5620 - recall: 0.6087 - val_loss: 0.6773 - val_binary_accuracy: 0.5600 - val_precision: 0.5502 - val_recall: 0.7154\n",
      "Epoch 107/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6773 - binary_accuracy: 0.5600 - precision: 0.5502 - recall: 0.7154 - val_loss: 0.6767 - val_binary_accuracy: 0.5670 - val_precision: 0.5599 - val_recall: 0.6739\n",
      "Epoch 108/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6767 - binary_accuracy: 0.5670 - precision: 0.5599 - recall: 0.6739 - val_loss: 0.6767 - val_binary_accuracy: 0.5750 - val_precision: 0.5835 - val_recall: 0.5593\n",
      "Epoch 109/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6767 - binary_accuracy: 0.5750 - precision: 0.5835 - recall: 0.5593 - val_loss: 0.6768 - val_binary_accuracy: 0.5760 - val_precision: 0.5899 - val_recall: 0.5316\n",
      "Epoch 110/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6768 - binary_accuracy: 0.5760 - precision: 0.5899 - recall: 0.5316 - val_loss: 0.6764 - val_binary_accuracy: 0.5700 - val_precision: 0.5679 - val_recall: 0.6285\n",
      "Epoch 111/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6764 - binary_accuracy: 0.5700 - precision: 0.5679 - recall: 0.6285 - val_loss: 0.6764 - val_binary_accuracy: 0.5590 - val_precision: 0.5513 - val_recall: 0.6897\n",
      "Epoch 112/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6764 - binary_accuracy: 0.5590 - precision: 0.5513 - recall: 0.6897 - val_loss: 0.6762 - val_binary_accuracy: 0.5580 - val_precision: 0.5508 - val_recall: 0.6858\n",
      "Epoch 113/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6762 - binary_accuracy: 0.5580 - precision: 0.5508 - recall: 0.6858 - val_loss: 0.6759 - val_binary_accuracy: 0.5740 - val_precision: 0.5725 - val_recall: 0.6245\n",
      "Epoch 114/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6759 - binary_accuracy: 0.5740 - precision: 0.5725 - recall: 0.6245 - val_loss: 0.6760 - val_binary_accuracy: 0.5670 - val_precision: 0.5746 - val_recall: 0.5553\n",
      "Epoch 115/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6760 - binary_accuracy: 0.5670 - precision: 0.5746 - recall: 0.5553 - val_loss: 0.6756 - val_binary_accuracy: 0.5750 - val_precision: 0.5719 - val_recall: 0.6364\n",
      "Epoch 116/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6756 - binary_accuracy: 0.5750 - precision: 0.5719 - recall: 0.6364 - val_loss: 0.6757 - val_binary_accuracy: 0.5610 - val_precision: 0.5534 - val_recall: 0.6858\n",
      "Epoch 117/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6757 - binary_accuracy: 0.5610 - precision: 0.5534 - recall: 0.6858 - val_loss: 0.6756 - val_binary_accuracy: 0.5610 - val_precision: 0.5543 - val_recall: 0.6759\n",
      "Epoch 118/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6756 - binary_accuracy: 0.5610 - precision: 0.5543 - recall: 0.6759 - val_loss: 0.6754 - val_binary_accuracy: 0.5790 - val_precision: 0.5766 - val_recall: 0.6324\n",
      "Epoch 119/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6754 - binary_accuracy: 0.5790 - precision: 0.5766 - recall: 0.6324 - val_loss: 0.6753 - val_binary_accuracy: 0.5720 - val_precision: 0.5747 - val_recall: 0.5929\n",
      "Epoch 120/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6753 - binary_accuracy: 0.5720 - precision: 0.5747 - recall: 0.5929 - val_loss: 0.6750 - val_binary_accuracy: 0.5690 - val_precision: 0.5650 - val_recall: 0.6443\n",
      "Epoch 121/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6750 - binary_accuracy: 0.5690 - precision: 0.5650 - recall: 0.6443 - val_loss: 0.6750 - val_binary_accuracy: 0.5690 - val_precision: 0.5608 - val_recall: 0.6838\n",
      "Epoch 122/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6750 - binary_accuracy: 0.5690 - precision: 0.5608 - recall: 0.6838 - val_loss: 0.6746 - val_binary_accuracy: 0.5690 - val_precision: 0.5635 - val_recall: 0.6581\n",
      "Epoch 123/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6746 - binary_accuracy: 0.5690 - precision: 0.5635 - recall: 0.6581 - val_loss: 0.6745 - val_binary_accuracy: 0.5730 - val_precision: 0.5738 - val_recall: 0.6067\n",
      "Epoch 124/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6745 - binary_accuracy: 0.5730 - precision: 0.5738 - recall: 0.6067 - val_loss: 0.6742 - val_binary_accuracy: 0.5680 - val_precision: 0.5680 - val_recall: 0.6107\n",
      "Epoch 125/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6742 - binary_accuracy: 0.5680 - precision: 0.5680 - recall: 0.6107 - val_loss: 0.6740 - val_binary_accuracy: 0.5710 - val_precision: 0.5641 - val_recall: 0.6700\n",
      "Epoch 126/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6740 - binary_accuracy: 0.5710 - precision: 0.5641 - recall: 0.6700 - val_loss: 0.6738 - val_binary_accuracy: 0.5680 - val_precision: 0.5611 - val_recall: 0.6719\n",
      "Epoch 127/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6738 - binary_accuracy: 0.5680 - precision: 0.5611 - recall: 0.6719 - val_loss: 0.6735 - val_binary_accuracy: 0.5640 - val_precision: 0.5648 - val_recall: 0.6028\n",
      "Epoch 128/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6735 - binary_accuracy: 0.5640 - precision: 0.5648 - recall: 0.6028 - val_loss: 0.6732 - val_binary_accuracy: 0.5650 - val_precision: 0.5637 - val_recall: 0.6206\n",
      "Epoch 129/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6732 - binary_accuracy: 0.5650 - precision: 0.5637 - recall: 0.6206 - val_loss: 0.6730 - val_binary_accuracy: 0.5710 - val_precision: 0.5632 - val_recall: 0.6779\n",
      "Epoch 130/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6730 - binary_accuracy: 0.5710 - precision: 0.5632 - recall: 0.6779 - val_loss: 0.6727 - val_binary_accuracy: 0.5680 - val_precision: 0.5636 - val_recall: 0.6482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6727 - binary_accuracy: 0.5680 - precision: 0.5636 - recall: 0.6482 - val_loss: 0.6725 - val_binary_accuracy: 0.5720 - val_precision: 0.5717 - val_recall: 0.6146\n",
      "Epoch 132/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6725 - binary_accuracy: 0.5720 - precision: 0.5717 - recall: 0.6146 - val_loss: 0.6722 - val_binary_accuracy: 0.5720 - val_precision: 0.5641 - val_recall: 0.6779\n",
      "Epoch 133/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6722 - binary_accuracy: 0.5720 - precision: 0.5641 - recall: 0.6779 - val_loss: 0.6720 - val_binary_accuracy: 0.5690 - val_precision: 0.5654 - val_recall: 0.6403\n",
      "Epoch 134/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6720 - binary_accuracy: 0.5690 - precision: 0.5654 - recall: 0.6403 - val_loss: 0.6719 - val_binary_accuracy: 0.5800 - val_precision: 0.5796 - val_recall: 0.6186\n",
      "Epoch 135/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6719 - binary_accuracy: 0.5800 - precision: 0.5796 - recall: 0.6186 - val_loss: 0.6718 - val_binary_accuracy: 0.5750 - val_precision: 0.5659 - val_recall: 0.6877\n",
      "Epoch 136/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6718 - binary_accuracy: 0.5750 - precision: 0.5659 - recall: 0.6877 - val_loss: 0.6717 - val_binary_accuracy: 0.5870 - val_precision: 0.5882 - val_recall: 0.6126\n",
      "Epoch 137/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6717 - binary_accuracy: 0.5870 - precision: 0.5882 - recall: 0.6126 - val_loss: 0.6716 - val_binary_accuracy: 0.5700 - val_precision: 0.5617 - val_recall: 0.6838\n",
      "Epoch 138/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.6716 - binary_accuracy: 0.5700 - precision: 0.5617 - recall: 0.6838 - val_loss: 0.6712 - val_binary_accuracy: 0.5890 - val_precision: 0.5875 - val_recall: 0.6304\n",
      "Epoch 139/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6712 - binary_accuracy: 0.5890 - precision: 0.5875 - recall: 0.6304 - val_loss: 0.6709 - val_binary_accuracy: 0.5780 - val_precision: 0.5717 - val_recall: 0.6621\n",
      "Epoch 140/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6709 - binary_accuracy: 0.5780 - precision: 0.5717 - recall: 0.6621 - val_loss: 0.6707 - val_binary_accuracy: 0.5860 - val_precision: 0.5790 - val_recall: 0.6660\n",
      "Epoch 141/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.6707 - binary_accuracy: 0.5860 - precision: 0.5790 - recall: 0.6660 - val_loss: 0.6705 - val_binary_accuracy: 0.5900 - val_precision: 0.5886 - val_recall: 0.6304\n",
      "Epoch 142/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6705 - binary_accuracy: 0.5900 - precision: 0.5886 - recall: 0.6304 - val_loss: 0.6702 - val_binary_accuracy: 0.5810 - val_precision: 0.5721 - val_recall: 0.6818\n",
      "Epoch 143/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6702 - binary_accuracy: 0.5810 - precision: 0.5721 - recall: 0.6818 - val_loss: 0.6699 - val_binary_accuracy: 0.5850 - val_precision: 0.5814 - val_recall: 0.6423\n",
      "Epoch 144/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6699 - binary_accuracy: 0.5850 - precision: 0.5814 - recall: 0.6423 - val_loss: 0.6695 - val_binary_accuracy: 0.5850 - val_precision: 0.5802 - val_recall: 0.6502\n",
      "Epoch 145/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6695 - binary_accuracy: 0.5850 - precision: 0.5802 - recall: 0.6502 - val_loss: 0.6692 - val_binary_accuracy: 0.5870 - val_precision: 0.5789 - val_recall: 0.6739\n",
      "Epoch 146/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6692 - binary_accuracy: 0.5870 - precision: 0.5789 - recall: 0.6739 - val_loss: 0.6689 - val_binary_accuracy: 0.5850 - val_precision: 0.5800 - val_recall: 0.6522\n",
      "Epoch 147/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6689 - binary_accuracy: 0.5850 - precision: 0.5800 - recall: 0.6522 - val_loss: 0.6686 - val_binary_accuracy: 0.5920 - val_precision: 0.5854 - val_recall: 0.6640\n",
      "Epoch 148/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6686 - binary_accuracy: 0.5920 - precision: 0.5854 - recall: 0.6640 - val_loss: 0.6682 - val_binary_accuracy: 0.5900 - val_precision: 0.5822 - val_recall: 0.6719\n",
      "Epoch 149/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6682 - binary_accuracy: 0.5900 - precision: 0.5822 - recall: 0.6719 - val_loss: 0.6679 - val_binary_accuracy: 0.5870 - val_precision: 0.5782 - val_recall: 0.6798\n",
      "Epoch 150/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6679 - binary_accuracy: 0.5870 - precision: 0.5782 - recall: 0.6798 - val_loss: 0.6673 - val_binary_accuracy: 0.5970 - val_precision: 0.5921 - val_recall: 0.6542\n",
      "Epoch 151/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6673 - binary_accuracy: 0.5970 - precision: 0.5921 - recall: 0.6542 - val_loss: 0.6668 - val_binary_accuracy: 0.5910 - val_precision: 0.5821 - val_recall: 0.6798\n",
      "Epoch 152/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6668 - binary_accuracy: 0.5910 - precision: 0.5821 - recall: 0.6798 - val_loss: 0.6662 - val_binary_accuracy: 0.5940 - val_precision: 0.5871 - val_recall: 0.6660\n",
      "Epoch 153/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6662 - binary_accuracy: 0.5940 - precision: 0.5871 - recall: 0.6660 - val_loss: 0.6657 - val_binary_accuracy: 0.5900 - val_precision: 0.5836 - val_recall: 0.6621\n",
      "Epoch 154/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.6657 - binary_accuracy: 0.5900 - precision: 0.5836 - recall: 0.6621 - val_loss: 0.6652 - val_binary_accuracy: 0.5860 - val_precision: 0.5790 - val_recall: 0.6660\n",
      "Epoch 155/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6652 - binary_accuracy: 0.5860 - precision: 0.5790 - recall: 0.6660 - val_loss: 0.6648 - val_binary_accuracy: 0.5910 - val_precision: 0.5849 - val_recall: 0.6601\n",
      "Epoch 156/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.6648 - binary_accuracy: 0.5910 - precision: 0.5849 - recall: 0.6601 - val_loss: 0.6645 - val_binary_accuracy: 0.5900 - val_precision: 0.5857 - val_recall: 0.6482\n",
      "Epoch 157/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6645 - binary_accuracy: 0.5900 - precision: 0.5857 - recall: 0.6482 - val_loss: 0.6652 - val_binary_accuracy: 0.5840 - val_precision: 0.5792 - val_recall: 0.6502\n",
      "Epoch 158/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.6652 - binary_accuracy: 0.5840 - precision: 0.5792 - recall: 0.6502 - val_loss: 0.6632 - val_binary_accuracy: 0.5810 - val_precision: 0.5724 - val_recall: 0.6798\n",
      "Epoch 159/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6632 - binary_accuracy: 0.5810 - precision: 0.5724 - recall: 0.6798 - val_loss: 0.6631 - val_binary_accuracy: 0.6030 - val_precision: 0.6079 - val_recall: 0.6067\n",
      "Epoch 160/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6631 - binary_accuracy: 0.6030 - precision: 0.6079 - recall: 0.6067 - val_loss: 0.6638 - val_binary_accuracy: 0.5670 - val_precision: 0.5575 - val_recall: 0.6996\n",
      "Epoch 161/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.6638 - binary_accuracy: 0.5670 - precision: 0.5575 - recall: 0.6996 - val_loss: 0.6617 - val_binary_accuracy: 0.5740 - val_precision: 0.5660 - val_recall: 0.6779\n",
      "Epoch 162/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6617 - binary_accuracy: 0.5740 - precision: 0.5660 - recall: 0.6779 - val_loss: 0.6630 - val_binary_accuracy: 0.5990 - val_precision: 0.6048 - val_recall: 0.5988\n",
      "Epoch 163/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.6630 - binary_accuracy: 0.5990 - precision: 0.6048 - recall: 0.5988 - val_loss: 0.6614 - val_binary_accuracy: 0.5650 - val_precision: 0.5514 - val_recall: 0.7530\n",
      "Epoch 164/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6614 - binary_accuracy: 0.5650 - precision: 0.5514 - recall: 0.7530 - val_loss: 0.6624 - val_binary_accuracy: 0.5960 - val_precision: 0.6016 - val_recall: 0.5968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6624 - binary_accuracy: 0.5960 - precision: 0.6016 - recall: 0.5968 - val_loss: 0.6587 - val_binary_accuracy: 0.5890 - val_precision: 0.5832 - val_recall: 0.6581\n",
      "Epoch 166/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6587 - binary_accuracy: 0.5890 - precision: 0.5832 - recall: 0.6581 - val_loss: 0.6603 - val_binary_accuracy: 0.5850 - val_precision: 0.5740 - val_recall: 0.6976\n",
      "Epoch 167/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.6603 - binary_accuracy: 0.5850 - precision: 0.5740 - recall: 0.6976 - val_loss: 0.6582 - val_binary_accuracy: 0.6010 - val_precision: 0.6131 - val_recall: 0.5731\n",
      "Epoch 168/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.6582 - binary_accuracy: 0.6010 - precision: 0.6131 - recall: 0.5731 - val_loss: 0.6582 - val_binary_accuracy: 0.5830 - val_precision: 0.5728 - val_recall: 0.6917\n",
      "Epoch 169/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.6582 - binary_accuracy: 0.5830 - precision: 0.5728 - recall: 0.6917 - val_loss: 0.6575 - val_binary_accuracy: 0.5870 - val_precision: 0.5800 - val_recall: 0.6660\n",
      "Epoch 170/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6575 - binary_accuracy: 0.5870 - precision: 0.5800 - recall: 0.6660 - val_loss: 0.6556 - val_binary_accuracy: 0.6020 - val_precision: 0.6038 - val_recall: 0.6206\n",
      "Epoch 171/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.6556 - binary_accuracy: 0.6020 - precision: 0.6038 - recall: 0.6206 - val_loss: 0.6562 - val_binary_accuracy: 0.5850 - val_precision: 0.5735 - val_recall: 0.7016\n",
      "Epoch 172/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6562 - binary_accuracy: 0.5850 - precision: 0.5735 - recall: 0.7016 - val_loss: 0.6538 - val_binary_accuracy: 0.6020 - val_precision: 0.5996 - val_recall: 0.6423\n",
      "Epoch 173/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.6538 - binary_accuracy: 0.6020 - precision: 0.5996 - recall: 0.6423 - val_loss: 0.6535 - val_binary_accuracy: 0.6020 - val_precision: 0.5996 - val_recall: 0.6423\n",
      "Epoch 174/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.6535 - binary_accuracy: 0.6020 - precision: 0.5996 - recall: 0.6423 - val_loss: 0.6530 - val_binary_accuracy: 0.5910 - val_precision: 0.5823 - val_recall: 0.6779\n",
      "Epoch 175/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6530 - binary_accuracy: 0.5910 - precision: 0.5823 - recall: 0.6779 - val_loss: 0.6512 - val_binary_accuracy: 0.6030 - val_precision: 0.6030 - val_recall: 0.6304\n",
      "Epoch 176/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6512 - binary_accuracy: 0.6030 - precision: 0.6030 - recall: 0.6304 - val_loss: 0.6510 - val_binary_accuracy: 0.6010 - val_precision: 0.5896 - val_recall: 0.6957\n",
      "Epoch 177/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6510 - binary_accuracy: 0.6010 - precision: 0.5896 - recall: 0.6957 - val_loss: 0.6492 - val_binary_accuracy: 0.6010 - val_precision: 0.5964 - val_recall: 0.6542\n",
      "Epoch 178/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6492 - binary_accuracy: 0.6010 - precision: 0.5964 - recall: 0.6542 - val_loss: 0.6489 - val_binary_accuracy: 0.5970 - val_precision: 0.5899 - val_recall: 0.6680\n",
      "Epoch 179/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6489 - binary_accuracy: 0.5970 - precision: 0.5899 - recall: 0.6680 - val_loss: 0.6473 - val_binary_accuracy: 0.5940 - val_precision: 0.5916 - val_recall: 0.6383\n",
      "Epoch 180/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.6473 - binary_accuracy: 0.5940 - precision: 0.5916 - recall: 0.6383 - val_loss: 0.6471 - val_binary_accuracy: 0.5980 - val_precision: 0.5864 - val_recall: 0.6976\n",
      "Epoch 181/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6471 - binary_accuracy: 0.5980 - precision: 0.5864 - recall: 0.6976 - val_loss: 0.6464 - val_binary_accuracy: 0.6070 - val_precision: 0.6231 - val_recall: 0.5652\n",
      "Epoch 182/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6464 - binary_accuracy: 0.6070 - precision: 0.6231 - recall: 0.5652 - val_loss: 0.6547 - val_binary_accuracy: 0.5720 - val_precision: 0.5490 - val_recall: 0.8636\n",
      "Epoch 183/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6547 - binary_accuracy: 0.5720 - precision: 0.5490 - recall: 0.8636 - val_loss: 0.6558 - val_binary_accuracy: 0.5930 - val_precision: 0.6495 - val_recall: 0.4249\n",
      "Epoch 184/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6558 - binary_accuracy: 0.5930 - precision: 0.6495 - recall: 0.4249 - val_loss: 0.6486 - val_binary_accuracy: 0.6010 - val_precision: 0.6213 - val_recall: 0.5415\n",
      "Epoch 185/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6486 - binary_accuracy: 0.6010 - precision: 0.6213 - recall: 0.5415 - val_loss: 0.6465 - val_binary_accuracy: 0.5920 - val_precision: 0.5710 - val_recall: 0.7787\n",
      "Epoch 186/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.6465 - binary_accuracy: 0.5920 - precision: 0.5710 - recall: 0.7787 - val_loss: 0.6471 - val_binary_accuracy: 0.5850 - val_precision: 0.5633 - val_recall: 0.8004\n",
      "Epoch 187/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6471 - binary_accuracy: 0.5850 - precision: 0.5633 - recall: 0.8004 - val_loss: 0.6454 - val_binary_accuracy: 0.6070 - val_precision: 0.6151 - val_recall: 0.5968\n",
      "Epoch 188/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.6454 - binary_accuracy: 0.6070 - precision: 0.6151 - recall: 0.5968 - val_loss: 0.6463 - val_binary_accuracy: 0.5990 - val_precision: 0.5989 - val_recall: 0.6285\n",
      "Epoch 189/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6463 - binary_accuracy: 0.5990 - precision: 0.5989 - recall: 0.6285 - val_loss: 0.6442 - val_binary_accuracy: 0.5890 - val_precision: 0.5872 - val_recall: 0.6324\n",
      "Epoch 190/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6442 - binary_accuracy: 0.5890 - precision: 0.5872 - recall: 0.6324 - val_loss: 0.6430 - val_binary_accuracy: 0.5980 - val_precision: 0.5959 - val_recall: 0.6383\n",
      "Epoch 191/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6430 - binary_accuracy: 0.5980 - precision: 0.5959 - recall: 0.6383 - val_loss: 0.6426 - val_binary_accuracy: 0.6020 - val_precision: 0.5954 - val_recall: 0.6660\n",
      "Epoch 192/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.6426 - binary_accuracy: 0.6020 - precision: 0.5954 - recall: 0.6660 - val_loss: 0.6417 - val_binary_accuracy: 0.5870 - val_precision: 0.5817 - val_recall: 0.6542\n",
      "Epoch 193/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6417 - binary_accuracy: 0.5870 - precision: 0.5817 - recall: 0.6542 - val_loss: 0.6401 - val_binary_accuracy: 0.6020 - val_precision: 0.6120 - val_recall: 0.5830\n",
      "Epoch 194/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.6401 - binary_accuracy: 0.6020 - precision: 0.6120 - recall: 0.5830 - val_loss: 0.6396 - val_binary_accuracy: 0.6130 - val_precision: 0.6308 - val_recall: 0.5672\n",
      "Epoch 195/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.6396 - binary_accuracy: 0.6130 - precision: 0.6308 - recall: 0.5672 - val_loss: 0.6385 - val_binary_accuracy: 0.6050 - val_precision: 0.6061 - val_recall: 0.6265\n",
      "Epoch 196/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.6385 - binary_accuracy: 0.6050 - precision: 0.6061 - recall: 0.6265 - val_loss: 0.6377 - val_binary_accuracy: 0.5980 - val_precision: 0.5884 - val_recall: 0.6838\n",
      "Epoch 197/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6377 - binary_accuracy: 0.5980 - precision: 0.5884 - recall: 0.6838 - val_loss: 0.6370 - val_binary_accuracy: 0.5940 - val_precision: 0.5820 - val_recall: 0.7016\n",
      "Epoch 198/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.6370 - binary_accuracy: 0.5940 - precision: 0.5820 - recall: 0.7016 - val_loss: 0.6353 - val_binary_accuracy: 0.6080 - val_precision: 0.5997 - val_recall: 0.6779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6353 - binary_accuracy: 0.6080 - precision: 0.5997 - recall: 0.6779 - val_loss: 0.6348 - val_binary_accuracy: 0.6050 - val_precision: 0.6126 - val_recall: 0.5968\n",
      "Epoch 200/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.6348 - binary_accuracy: 0.6050 - precision: 0.6126 - recall: 0.5968 - val_loss: 0.6347 - val_binary_accuracy: 0.6050 - val_precision: 0.6188 - val_recall: 0.5711\n",
      "Epoch 201/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6347 - binary_accuracy: 0.6050 - precision: 0.6188 - recall: 0.5711 - val_loss: 0.6327 - val_binary_accuracy: 0.6070 - val_precision: 0.6119 - val_recall: 0.6107\n",
      "Epoch 202/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6327 - binary_accuracy: 0.6070 - precision: 0.6119 - recall: 0.6107 - val_loss: 0.6317 - val_binary_accuracy: 0.6080 - val_precision: 0.6022 - val_recall: 0.6640\n",
      "Epoch 203/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6317 - binary_accuracy: 0.6080 - precision: 0.6022 - recall: 0.6640 - val_loss: 0.6318 - val_binary_accuracy: 0.6060 - val_precision: 0.5949 - val_recall: 0.6937\n",
      "Epoch 204/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6318 - binary_accuracy: 0.6060 - precision: 0.5949 - recall: 0.6937 - val_loss: 0.6300 - val_binary_accuracy: 0.6110 - val_precision: 0.6085 - val_recall: 0.6482\n",
      "Epoch 205/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6300 - binary_accuracy: 0.6110 - precision: 0.6085 - recall: 0.6482 - val_loss: 0.6294 - val_binary_accuracy: 0.6100 - val_precision: 0.6169 - val_recall: 0.6047\n",
      "Epoch 206/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6294 - binary_accuracy: 0.6100 - precision: 0.6169 - recall: 0.6047 - val_loss: 0.6288 - val_binary_accuracy: 0.6120 - val_precision: 0.6239 - val_recall: 0.5870\n",
      "Epoch 207/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6288 - binary_accuracy: 0.6120 - precision: 0.6239 - recall: 0.5870 - val_loss: 0.6270 - val_binary_accuracy: 0.6130 - val_precision: 0.6192 - val_recall: 0.6107\n",
      "Epoch 208/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.6270 - binary_accuracy: 0.6130 - precision: 0.6192 - recall: 0.6107 - val_loss: 0.6265 - val_binary_accuracy: 0.6200 - val_precision: 0.6113 - val_recall: 0.6838\n",
      "Epoch 209/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.6265 - binary_accuracy: 0.6200 - precision: 0.6113 - recall: 0.6838 - val_loss: 0.6258 - val_binary_accuracy: 0.6200 - val_precision: 0.6094 - val_recall: 0.6937\n",
      "Epoch 210/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.6258 - binary_accuracy: 0.6200 - precision: 0.6094 - recall: 0.6937 - val_loss: 0.6241 - val_binary_accuracy: 0.6170 - val_precision: 0.6167 - val_recall: 0.6423\n",
      "Epoch 211/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6241 - binary_accuracy: 0.6170 - precision: 0.6167 - recall: 0.6423 - val_loss: 0.6235 - val_binary_accuracy: 0.6190 - val_precision: 0.6268 - val_recall: 0.6107\n",
      "Epoch 212/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.6235 - binary_accuracy: 0.6190 - precision: 0.6268 - recall: 0.6107 - val_loss: 0.6223 - val_binary_accuracy: 0.6180 - val_precision: 0.6270 - val_recall: 0.6047\n",
      "Epoch 213/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.6223 - binary_accuracy: 0.6180 - precision: 0.6270 - recall: 0.6047 - val_loss: 0.6210 - val_binary_accuracy: 0.6110 - val_precision: 0.6168 - val_recall: 0.6107\n",
      "Epoch 214/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6210 - binary_accuracy: 0.6110 - precision: 0.6168 - recall: 0.6107 - val_loss: 0.6203 - val_binary_accuracy: 0.6180 - val_precision: 0.6157 - val_recall: 0.6522\n",
      "Epoch 215/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.6203 - binary_accuracy: 0.6180 - precision: 0.6157 - recall: 0.6522 - val_loss: 0.6188 - val_binary_accuracy: 0.6210 - val_precision: 0.6252 - val_recall: 0.6265\n",
      "Epoch 216/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.6188 - binary_accuracy: 0.6210 - precision: 0.6252 - recall: 0.6265 - val_loss: 0.6177 - val_binary_accuracy: 0.6240 - val_precision: 0.6305 - val_recall: 0.6206\n",
      "Epoch 217/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.6177 - binary_accuracy: 0.6240 - precision: 0.6305 - recall: 0.6206 - val_loss: 0.6166 - val_binary_accuracy: 0.6260 - val_precision: 0.6369 - val_recall: 0.6067\n",
      "Epoch 218/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6166 - binary_accuracy: 0.6260 - precision: 0.6369 - recall: 0.6067 - val_loss: 0.6150 - val_binary_accuracy: 0.6270 - val_precision: 0.6322 - val_recall: 0.6285\n",
      "Epoch 219/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.6150 - binary_accuracy: 0.6270 - precision: 0.6322 - recall: 0.6285 - val_loss: 0.6140 - val_binary_accuracy: 0.6190 - val_precision: 0.6181 - val_recall: 0.6462\n",
      "Epoch 220/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6140 - binary_accuracy: 0.6190 - precision: 0.6181 - recall: 0.6462 - val_loss: 0.6125 - val_binary_accuracy: 0.6320 - val_precision: 0.6397 - val_recall: 0.6245\n",
      "Epoch 221/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6125 - binary_accuracy: 0.6320 - precision: 0.6397 - recall: 0.6245 - val_loss: 0.6113 - val_binary_accuracy: 0.6260 - val_precision: 0.6347 - val_recall: 0.6146\n",
      "Epoch 222/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.6113 - binary_accuracy: 0.6260 - precision: 0.6347 - recall: 0.6146 - val_loss: 0.6104 - val_binary_accuracy: 0.6350 - val_precision: 0.6613 - val_recall: 0.5711\n",
      "Epoch 223/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.6104 - binary_accuracy: 0.6350 - precision: 0.6613 - recall: 0.5711 - val_loss: 0.6113 - val_binary_accuracy: 0.6170 - val_precision: 0.6085 - val_recall: 0.6818\n",
      "Epoch 224/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6113 - binary_accuracy: 0.6170 - precision: 0.6085 - recall: 0.6818 - val_loss: 0.6148 - val_binary_accuracy: 0.6250 - val_precision: 0.6625 - val_recall: 0.5277\n",
      "Epoch 225/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.6148 - binary_accuracy: 0.6250 - precision: 0.6625 - recall: 0.5277 - val_loss: 0.6238 - val_binary_accuracy: 0.6240 - val_precision: 0.6016 - val_recall: 0.7609\n",
      "Epoch 226/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.6238 - binary_accuracy: 0.6240 - precision: 0.6016 - recall: 0.7609 - val_loss: 0.6112 - val_binary_accuracy: 0.6360 - val_precision: 0.6387 - val_recall: 0.6462\n",
      "Epoch 227/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.6112 - binary_accuracy: 0.6360 - precision: 0.6387 - recall: 0.6462 - val_loss: 0.6219 - val_binary_accuracy: 0.6210 - val_precision: 0.6667 - val_recall: 0.5020\n",
      "Epoch 228/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.6219 - binary_accuracy: 0.6210 - precision: 0.6667 - recall: 0.5020 - val_loss: 0.6057 - val_binary_accuracy: 0.6250 - val_precision: 0.6215 - val_recall: 0.6621\n",
      "Epoch 229/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.6057 - binary_accuracy: 0.6250 - precision: 0.6215 - recall: 0.6621 - val_loss: 0.6146 - val_binary_accuracy: 0.6290 - val_precision: 0.6119 - val_recall: 0.7292\n",
      "Epoch 230/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.6146 - binary_accuracy: 0.6290 - precision: 0.6119 - recall: 0.7292 - val_loss: 0.6043 - val_binary_accuracy: 0.6460 - val_precision: 0.6743 - val_recall: 0.5810\n",
      "Epoch 231/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.6043 - binary_accuracy: 0.6460 - precision: 0.6743 - recall: 0.5810 - val_loss: 0.6079 - val_binary_accuracy: 0.6520 - val_precision: 0.7124 - val_recall: 0.5237\n",
      "Epoch 232/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.6079 - binary_accuracy: 0.6520 - precision: 0.7124 - recall: 0.5237 - val_loss: 0.6013 - val_binary_accuracy: 0.6500 - val_precision: 0.6773 - val_recall: 0.5889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.6013 - binary_accuracy: 0.6500 - precision: 0.6773 - recall: 0.5889 - val_loss: 0.6035 - val_binary_accuracy: 0.6460 - val_precision: 0.6234 - val_recall: 0.7589\n",
      "Epoch 234/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.6035 - binary_accuracy: 0.6460 - precision: 0.6234 - recall: 0.7589 - val_loss: 0.5999 - val_binary_accuracy: 0.6370 - val_precision: 0.6288 - val_recall: 0.6897\n",
      "Epoch 235/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.5999 - binary_accuracy: 0.6370 - precision: 0.6288 - recall: 0.6897 - val_loss: 0.5980 - val_binary_accuracy: 0.6560 - val_precision: 0.7056 - val_recall: 0.5494\n",
      "Epoch 236/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.5980 - binary_accuracy: 0.6560 - precision: 0.7056 - recall: 0.5494 - val_loss: 0.5985 - val_binary_accuracy: 0.6590 - val_precision: 0.7177 - val_recall: 0.5375\n",
      "Epoch 237/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.5985 - binary_accuracy: 0.6590 - precision: 0.7177 - recall: 0.5375 - val_loss: 0.5942 - val_binary_accuracy: 0.6370 - val_precision: 0.6505 - val_recall: 0.6107\n",
      "Epoch 238/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.5942 - binary_accuracy: 0.6370 - precision: 0.6505 - recall: 0.6107 - val_loss: 0.5949 - val_binary_accuracy: 0.6430 - val_precision: 0.6244 - val_recall: 0.7391\n",
      "Epoch 239/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.5949 - binary_accuracy: 0.6430 - precision: 0.6244 - recall: 0.7391 - val_loss: 0.5916 - val_binary_accuracy: 0.6570 - val_precision: 0.6506 - val_recall: 0.6957\n",
      "Epoch 240/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.5916 - binary_accuracy: 0.6570 - precision: 0.6506 - recall: 0.6957 - val_loss: 0.5915 - val_binary_accuracy: 0.6490 - val_precision: 0.6815 - val_recall: 0.5751\n",
      "Epoch 241/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5915 - binary_accuracy: 0.6490 - precision: 0.6815 - recall: 0.5751 - val_loss: 0.5889 - val_binary_accuracy: 0.6560 - val_precision: 0.6884 - val_recall: 0.5850\n",
      "Epoch 242/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.5889 - binary_accuracy: 0.6560 - precision: 0.6884 - recall: 0.5850 - val_loss: 0.5884 - val_binary_accuracy: 0.6570 - val_precision: 0.6660 - val_recall: 0.6462\n",
      "Epoch 243/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.5884 - binary_accuracy: 0.6570 - precision: 0.6660 - recall: 0.6462 - val_loss: 0.5857 - val_binary_accuracy: 0.6530 - val_precision: 0.6492 - val_recall: 0.6838\n",
      "Epoch 244/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.5857 - binary_accuracy: 0.6530 - precision: 0.6492 - recall: 0.6838 - val_loss: 0.5851 - val_binary_accuracy: 0.6590 - val_precision: 0.6590 - val_recall: 0.6759\n",
      "Epoch 245/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.5851 - binary_accuracy: 0.6590 - precision: 0.6590 - recall: 0.6759 - val_loss: 0.5826 - val_binary_accuracy: 0.6750 - val_precision: 0.6828 - val_recall: 0.6680\n",
      "Epoch 246/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5826 - binary_accuracy: 0.6750 - precision: 0.6828 - recall: 0.6680 - val_loss: 0.5813 - val_binary_accuracy: 0.6550 - val_precision: 0.6777 - val_recall: 0.6067\n",
      "Epoch 247/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.5813 - binary_accuracy: 0.6550 - precision: 0.6777 - recall: 0.6067 - val_loss: 0.5800 - val_binary_accuracy: 0.6590 - val_precision: 0.6837 - val_recall: 0.6067\n",
      "Epoch 248/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.5800 - binary_accuracy: 0.6590 - precision: 0.6837 - recall: 0.6067 - val_loss: 0.5776 - val_binary_accuracy: 0.6630 - val_precision: 0.6749 - val_recall: 0.6443\n",
      "Epoch 249/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.5776 - binary_accuracy: 0.6630 - precision: 0.6749 - recall: 0.6443 - val_loss: 0.5770 - val_binary_accuracy: 0.6720 - val_precision: 0.6654 - val_recall: 0.7075\n",
      "Epoch 250/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.5770 - binary_accuracy: 0.6720 - precision: 0.6654 - recall: 0.7075 - val_loss: 0.5740 - val_binary_accuracy: 0.6780 - val_precision: 0.6870 - val_recall: 0.6680\n",
      "Epoch 251/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.5740 - binary_accuracy: 0.6780 - precision: 0.6870 - recall: 0.6680 - val_loss: 0.5732 - val_binary_accuracy: 0.6680 - val_precision: 0.6925 - val_recall: 0.6186\n",
      "Epoch 252/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.5732 - binary_accuracy: 0.6680 - precision: 0.6925 - recall: 0.6186 - val_loss: 0.5709 - val_binary_accuracy: 0.6770 - val_precision: 0.6943 - val_recall: 0.6462\n",
      "Epoch 253/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.5709 - binary_accuracy: 0.6770 - precision: 0.6943 - recall: 0.6462 - val_loss: 0.5692 - val_binary_accuracy: 0.6810 - val_precision: 0.6728 - val_recall: 0.7194\n",
      "Epoch 254/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.5692 - binary_accuracy: 0.6810 - precision: 0.6728 - recall: 0.7194 - val_loss: 0.5674 - val_binary_accuracy: 0.6730 - val_precision: 0.6679 - val_recall: 0.7036\n",
      "Epoch 255/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.5674 - binary_accuracy: 0.6730 - precision: 0.6679 - recall: 0.7036 - val_loss: 0.5648 - val_binary_accuracy: 0.6840 - val_precision: 0.6939 - val_recall: 0.6719\n",
      "Epoch 256/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.5648 - binary_accuracy: 0.6840 - precision: 0.6939 - recall: 0.6719 - val_loss: 0.5635 - val_binary_accuracy: 0.6860 - val_precision: 0.7051 - val_recall: 0.6522\n",
      "Epoch 257/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.5635 - binary_accuracy: 0.6860 - precision: 0.7051 - recall: 0.6522 - val_loss: 0.5606 - val_binary_accuracy: 0.6920 - val_precision: 0.7012 - val_recall: 0.6818\n",
      "Epoch 258/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.5606 - binary_accuracy: 0.6920 - precision: 0.7012 - recall: 0.6818 - val_loss: 0.5590 - val_binary_accuracy: 0.6900 - val_precision: 0.6856 - val_recall: 0.7154\n",
      "Epoch 259/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.5590 - binary_accuracy: 0.6900 - precision: 0.6856 - recall: 0.7154 - val_loss: 0.5563 - val_binary_accuracy: 0.6970 - val_precision: 0.7018 - val_recall: 0.6976\n",
      "Epoch 260/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.5563 - binary_accuracy: 0.6970 - precision: 0.7018 - recall: 0.6976 - val_loss: 0.5544 - val_binary_accuracy: 0.6920 - val_precision: 0.7152 - val_recall: 0.6502\n",
      "Epoch 261/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.5544 - binary_accuracy: 0.6920 - precision: 0.7152 - recall: 0.6502 - val_loss: 0.5517 - val_binary_accuracy: 0.6990 - val_precision: 0.7071 - val_recall: 0.6917\n",
      "Epoch 262/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.5517 - binary_accuracy: 0.6990 - precision: 0.7071 - recall: 0.6917 - val_loss: 0.5490 - val_binary_accuracy: 0.7020 - val_precision: 0.7000 - val_recall: 0.7194\n",
      "Epoch 263/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.5490 - binary_accuracy: 0.7020 - precision: 0.7000 - recall: 0.7194 - val_loss: 0.5461 - val_binary_accuracy: 0.7000 - val_precision: 0.7012 - val_recall: 0.7095\n",
      "Epoch 264/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.5461 - binary_accuracy: 0.7000 - precision: 0.7012 - recall: 0.7095 - val_loss: 0.5434 - val_binary_accuracy: 0.7090 - val_precision: 0.7292 - val_recall: 0.6759\n",
      "Epoch 265/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.5434 - binary_accuracy: 0.7090 - precision: 0.7292 - recall: 0.6759 - val_loss: 0.5401 - val_binary_accuracy: 0.7120 - val_precision: 0.7290 - val_recall: 0.6858\n",
      "Epoch 266/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.5401 - binary_accuracy: 0.7120 - precision: 0.7290 - recall: 0.6858 - val_loss: 0.5371 - val_binary_accuracy: 0.7110 - val_precision: 0.7166 - val_recall: 0.7095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5371 - binary_accuracy: 0.7110 - precision: 0.7166 - recall: 0.7095 - val_loss: 0.5336 - val_binary_accuracy: 0.7170 - val_precision: 0.7290 - val_recall: 0.7016\n",
      "Epoch 268/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.5336 - binary_accuracy: 0.7170 - precision: 0.7290 - recall: 0.7016 - val_loss: 0.5313 - val_binary_accuracy: 0.7130 - val_precision: 0.7386 - val_recall: 0.6700\n",
      "Epoch 269/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.5313 - binary_accuracy: 0.7130 - precision: 0.7386 - recall: 0.6700 - val_loss: 0.5339 - val_binary_accuracy: 0.7200 - val_precision: 0.7116 - val_recall: 0.7510\n",
      "Epoch 270/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.5339 - binary_accuracy: 0.7200 - precision: 0.7116 - recall: 0.7510 - val_loss: 0.5614 - val_binary_accuracy: 0.6730 - val_precision: 0.7254 - val_recall: 0.5692\n",
      "Epoch 271/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5614 - binary_accuracy: 0.6730 - precision: 0.7254 - recall: 0.5692 - val_loss: 0.5782 - val_binary_accuracy: 0.6620 - val_precision: 0.6391 - val_recall: 0.7628\n",
      "Epoch 272/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.5782 - binary_accuracy: 0.6620 - precision: 0.6391 - recall: 0.7628 - val_loss: 0.5545 - val_binary_accuracy: 0.6860 - val_precision: 0.6868 - val_recall: 0.6976\n",
      "Epoch 273/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.5545 - binary_accuracy: 0.6860 - precision: 0.6868 - recall: 0.6976 - val_loss: 0.5457 - val_binary_accuracy: 0.6980 - val_precision: 0.7073 - val_recall: 0.6877\n",
      "Epoch 274/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5457 - binary_accuracy: 0.6980 - precision: 0.7073 - recall: 0.6877 - val_loss: 0.5328 - val_binary_accuracy: 0.7030 - val_precision: 0.7370 - val_recall: 0.6423\n",
      "Epoch 275/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.5328 - binary_accuracy: 0.7030 - precision: 0.7370 - recall: 0.6423 - val_loss: 0.5389 - val_binary_accuracy: 0.7120 - val_precision: 0.7163 - val_recall: 0.7134\n",
      "Epoch 276/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.5389 - binary_accuracy: 0.7120 - precision: 0.7163 - recall: 0.7134 - val_loss: 0.5336 - val_binary_accuracy: 0.6940 - val_precision: 0.7703 - val_recall: 0.5632\n",
      "Epoch 277/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.5336 - binary_accuracy: 0.6940 - precision: 0.7703 - recall: 0.5632 - val_loss: 0.5191 - val_binary_accuracy: 0.7340 - val_precision: 0.7857 - val_recall: 0.6522\n",
      "Epoch 278/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5191 - binary_accuracy: 0.7340 - precision: 0.7857 - recall: 0.6522 - val_loss: 0.5224 - val_binary_accuracy: 0.7010 - val_precision: 0.6872 - val_recall: 0.7510\n",
      "Epoch 279/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.5224 - binary_accuracy: 0.7010 - precision: 0.6872 - recall: 0.7510 - val_loss: 0.5169 - val_binary_accuracy: 0.7020 - val_precision: 0.6763 - val_recall: 0.7885\n",
      "Epoch 280/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.5169 - binary_accuracy: 0.7020 - precision: 0.6763 - recall: 0.7885 - val_loss: 0.5067 - val_binary_accuracy: 0.7310 - val_precision: 0.7687 - val_recall: 0.6700\n",
      "Epoch 281/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.5067 - binary_accuracy: 0.7310 - precision: 0.7687 - recall: 0.6700 - val_loss: 0.5045 - val_binary_accuracy: 0.7260 - val_precision: 0.7959 - val_recall: 0.6166\n",
      "Epoch 282/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.5045 - binary_accuracy: 0.7260 - precision: 0.7959 - recall: 0.6166 - val_loss: 0.5000 - val_binary_accuracy: 0.7460 - val_precision: 0.7480 - val_recall: 0.7510\n",
      "Epoch 283/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.5000 - binary_accuracy: 0.7460 - precision: 0.7480 - recall: 0.7510 - val_loss: 0.4966 - val_binary_accuracy: 0.7360 - val_precision: 0.7224 - val_recall: 0.7767\n",
      "Epoch 284/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.4966 - binary_accuracy: 0.7360 - precision: 0.7224 - recall: 0.7767 - val_loss: 0.4880 - val_binary_accuracy: 0.7570 - val_precision: 0.7929 - val_recall: 0.7036\n",
      "Epoch 285/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.4880 - binary_accuracy: 0.7570 - precision: 0.7929 - recall: 0.7036 - val_loss: 0.4912 - val_binary_accuracy: 0.7490 - val_precision: 0.7972 - val_recall: 0.6759\n",
      "Epoch 286/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4912 - binary_accuracy: 0.7490 - precision: 0.7972 - recall: 0.6759 - val_loss: 0.4800 - val_binary_accuracy: 0.7630 - val_precision: 0.7751 - val_recall: 0.7490\n",
      "Epoch 287/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.4800 - binary_accuracy: 0.7630 - precision: 0.7751 - recall: 0.7490 - val_loss: 0.4777 - val_binary_accuracy: 0.7550 - val_precision: 0.7495 - val_recall: 0.7747\n",
      "Epoch 288/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.4777 - binary_accuracy: 0.7550 - precision: 0.7495 - recall: 0.7747 - val_loss: 0.4730 - val_binary_accuracy: 0.7670 - val_precision: 0.7714 - val_recall: 0.7668\n",
      "Epoch 289/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.4730 - binary_accuracy: 0.7670 - precision: 0.7714 - recall: 0.7668 - val_loss: 0.4705 - val_binary_accuracy: 0.7570 - val_precision: 0.8009 - val_recall: 0.6917\n",
      "Epoch 290/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4705 - binary_accuracy: 0.7570 - precision: 0.8009 - recall: 0.6917 - val_loss: 0.4618 - val_binary_accuracy: 0.7640 - val_precision: 0.8013 - val_recall: 0.7095\n",
      "Epoch 291/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.4618 - binary_accuracy: 0.7640 - precision: 0.8013 - recall: 0.7095 - val_loss: 0.4611 - val_binary_accuracy: 0.7620 - val_precision: 0.7648 - val_recall: 0.7648\n",
      "Epoch 292/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.4611 - binary_accuracy: 0.7620 - precision: 0.7648 - recall: 0.7648 - val_loss: 0.4553 - val_binary_accuracy: 0.7650 - val_precision: 0.7853 - val_recall: 0.7372\n",
      "Epoch 293/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.4553 - binary_accuracy: 0.7650 - precision: 0.7853 - recall: 0.7372 - val_loss: 0.4502 - val_binary_accuracy: 0.7770 - val_precision: 0.7979 - val_recall: 0.7490\n",
      "Epoch 294/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.4502 - binary_accuracy: 0.7770 - precision: 0.7979 - recall: 0.7490 - val_loss: 0.4439 - val_binary_accuracy: 0.7830 - val_precision: 0.7774 - val_recall: 0.8004\n",
      "Epoch 295/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.4439 - binary_accuracy: 0.7830 - precision: 0.7774 - recall: 0.8004 - val_loss: 0.4413 - val_binary_accuracy: 0.7830 - val_precision: 0.7873 - val_recall: 0.7826\n",
      "Epoch 296/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.4413 - binary_accuracy: 0.7830 - precision: 0.7873 - recall: 0.7826 - val_loss: 0.4372 - val_binary_accuracy: 0.7820 - val_precision: 0.8051 - val_recall: 0.7510\n",
      "Epoch 297/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.4372 - binary_accuracy: 0.7820 - precision: 0.8051 - recall: 0.7510 - val_loss: 0.4336 - val_binary_accuracy: 0.7940 - val_precision: 0.8151 - val_recall: 0.7668\n",
      "Epoch 298/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.4336 - binary_accuracy: 0.7940 - precision: 0.8151 - recall: 0.7668 - val_loss: 0.4347 - val_binary_accuracy: 0.7880 - val_precision: 0.7579 - val_recall: 0.8538\n",
      "Epoch 299/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4347 - binary_accuracy: 0.7880 - precision: 0.7579 - recall: 0.8538 - val_loss: 0.4365 - val_binary_accuracy: 0.7730 - val_precision: 0.8462 - val_recall: 0.6739\n",
      "Epoch 300/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.4365 - binary_accuracy: 0.7730 - precision: 0.8462 - recall: 0.6739 - val_loss: 0.4296 - val_binary_accuracy: 0.7850 - val_precision: 0.7437 - val_recall: 0.8775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4296 - binary_accuracy: 0.7850 - precision: 0.7437 - recall: 0.8775 - val_loss: 0.4217 - val_binary_accuracy: 0.7990 - val_precision: 0.8144 - val_recall: 0.7806\n",
      "Epoch 302/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.4217 - binary_accuracy: 0.7990 - precision: 0.8144 - recall: 0.7806 - val_loss: 0.4225 - val_binary_accuracy: 0.8170 - val_precision: 0.8473 - val_recall: 0.7787\n",
      "Epoch 303/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.4225 - binary_accuracy: 0.8170 - precision: 0.8473 - recall: 0.7787 - val_loss: 0.4045 - val_binary_accuracy: 0.8160 - val_precision: 0.8061 - val_recall: 0.8379\n",
      "Epoch 304/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.4045 - binary_accuracy: 0.8160 - precision: 0.8061 - recall: 0.8379 - val_loss: 0.4077 - val_binary_accuracy: 0.8110 - val_precision: 0.8176 - val_recall: 0.8063\n",
      "Epoch 305/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4077 - binary_accuracy: 0.8110 - precision: 0.8176 - recall: 0.8063 - val_loss: 0.4178 - val_binary_accuracy: 0.7910 - val_precision: 0.7839 - val_recall: 0.8103\n",
      "Epoch 306/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.4178 - binary_accuracy: 0.7910 - precision: 0.7839 - recall: 0.8103 - val_loss: 0.3974 - val_binary_accuracy: 0.8130 - val_precision: 0.8344 - val_recall: 0.7866\n",
      "Epoch 307/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.3974 - binary_accuracy: 0.8130 - precision: 0.8344 - recall: 0.7866 - val_loss: 0.3979 - val_binary_accuracy: 0.8140 - val_precision: 0.7797 - val_recall: 0.8814\n",
      "Epoch 308/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.3979 - binary_accuracy: 0.8140 - precision: 0.7797 - recall: 0.8814 - val_loss: 0.3922 - val_binary_accuracy: 0.8200 - val_precision: 0.8368 - val_recall: 0.8004\n",
      "Epoch 309/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.3922 - binary_accuracy: 0.8200 - precision: 0.8368 - recall: 0.8004 - val_loss: 0.3854 - val_binary_accuracy: 0.8190 - val_precision: 0.8806 - val_recall: 0.7431\n",
      "Epoch 310/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.3854 - binary_accuracy: 0.8190 - precision: 0.8806 - recall: 0.7431 - val_loss: 0.3823 - val_binary_accuracy: 0.8230 - val_precision: 0.7774 - val_recall: 0.9111\n",
      "Epoch 311/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.3823 - binary_accuracy: 0.8230 - precision: 0.7774 - recall: 0.9111 - val_loss: 0.3709 - val_binary_accuracy: 0.8340 - val_precision: 0.8220 - val_recall: 0.8577\n",
      "Epoch 312/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.3709 - binary_accuracy: 0.8340 - precision: 0.8220 - recall: 0.8577 - val_loss: 0.3739 - val_binary_accuracy: 0.8250 - val_precision: 0.8913 - val_recall: 0.7451\n",
      "Epoch 313/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.3739 - binary_accuracy: 0.8250 - precision: 0.8913 - recall: 0.7451 - val_loss: 0.3639 - val_binary_accuracy: 0.8470 - val_precision: 0.8227 - val_recall: 0.8893\n",
      "Epoch 314/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.3639 - binary_accuracy: 0.8470 - precision: 0.8227 - recall: 0.8893 - val_loss: 0.3594 - val_binary_accuracy: 0.8470 - val_precision: 0.8287 - val_recall: 0.8794\n",
      "Epoch 315/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.3594 - binary_accuracy: 0.8470 - precision: 0.8287 - recall: 0.8794 - val_loss: 0.3569 - val_binary_accuracy: 0.8370 - val_precision: 0.8924 - val_recall: 0.7708\n",
      "Epoch 316/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.3569 - binary_accuracy: 0.8370 - precision: 0.8924 - recall: 0.7708 - val_loss: 0.3470 - val_binary_accuracy: 0.8480 - val_precision: 0.8540 - val_recall: 0.8439\n",
      "Epoch 317/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.3470 - binary_accuracy: 0.8480 - precision: 0.8540 - recall: 0.8439 - val_loss: 0.3527 - val_binary_accuracy: 0.8370 - val_precision: 0.7922 - val_recall: 0.9190\n",
      "Epoch 318/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.3527 - binary_accuracy: 0.8370 - precision: 0.7922 - recall: 0.9190 - val_loss: 0.3531 - val_binary_accuracy: 0.8480 - val_precision: 0.8703 - val_recall: 0.8221\n",
      "Epoch 319/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.3531 - binary_accuracy: 0.8480 - precision: 0.8703 - recall: 0.8221 - val_loss: 0.3771 - val_binary_accuracy: 0.8110 - val_precision: 0.8126 - val_recall: 0.8142\n",
      "Epoch 320/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3771 - binary_accuracy: 0.8110 - precision: 0.8126 - recall: 0.8142 - val_loss: 0.3794 - val_binary_accuracy: 0.8250 - val_precision: 0.8214 - val_recall: 0.8360\n",
      "Epoch 321/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3794 - binary_accuracy: 0.8250 - precision: 0.8214 - recall: 0.8360 - val_loss: 0.3526 - val_binary_accuracy: 0.8490 - val_precision: 0.8233 - val_recall: 0.8933\n",
      "Epoch 322/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3526 - binary_accuracy: 0.8490 - precision: 0.8233 - recall: 0.8933 - val_loss: 0.3410 - val_binary_accuracy: 0.8520 - val_precision: 0.8874 - val_recall: 0.8103\n",
      "Epoch 323/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.3410 - binary_accuracy: 0.8520 - precision: 0.8874 - recall: 0.8103 - val_loss: 0.3586 - val_binary_accuracy: 0.8340 - val_precision: 0.8498 - val_recall: 0.8162\n",
      "Epoch 324/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.3586 - binary_accuracy: 0.8340 - precision: 0.8498 - recall: 0.8162 - val_loss: 0.3297 - val_binary_accuracy: 0.8560 - val_precision: 0.8131 - val_recall: 0.9289\n",
      "Epoch 325/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.3297 - binary_accuracy: 0.8560 - precision: 0.8131 - recall: 0.9289 - val_loss: 0.3268 - val_binary_accuracy: 0.8620 - val_precision: 0.8651 - val_recall: 0.8617\n",
      "Epoch 326/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.3268 - binary_accuracy: 0.8620 - precision: 0.8651 - recall: 0.8617 - val_loss: 0.3216 - val_binary_accuracy: 0.8610 - val_precision: 0.9069 - val_recall: 0.8083\n",
      "Epoch 327/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.3216 - binary_accuracy: 0.8610 - precision: 0.9069 - recall: 0.8083 - val_loss: 0.3181 - val_binary_accuracy: 0.8700 - val_precision: 0.8469 - val_recall: 0.9071\n",
      "Epoch 328/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.3181 - binary_accuracy: 0.8700 - precision: 0.8469 - recall: 0.9071 - val_loss: 0.3056 - val_binary_accuracy: 0.8720 - val_precision: 0.8677 - val_recall: 0.8814\n",
      "Epoch 329/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.3056 - binary_accuracy: 0.8720 - precision: 0.8677 - recall: 0.8814 - val_loss: 0.3068 - val_binary_accuracy: 0.8780 - val_precision: 0.9120 - val_recall: 0.8399\n",
      "Epoch 330/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.3068 - binary_accuracy: 0.8780 - precision: 0.9120 - recall: 0.8399 - val_loss: 0.2955 - val_binary_accuracy: 0.8760 - val_precision: 0.8617 - val_recall: 0.8992\n",
      "Epoch 331/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.2955 - binary_accuracy: 0.8760 - precision: 0.8617 - recall: 0.8992 - val_loss: 0.2960 - val_binary_accuracy: 0.8810 - val_precision: 0.8486 - val_recall: 0.9308\n",
      "Epoch 332/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.2960 - binary_accuracy: 0.8810 - precision: 0.8486 - recall: 0.9308 - val_loss: 0.2834 - val_binary_accuracy: 0.8790 - val_precision: 0.8782 - val_recall: 0.8834\n",
      "Epoch 333/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.2834 - binary_accuracy: 0.8790 - precision: 0.8782 - recall: 0.8834 - val_loss: 0.2872 - val_binary_accuracy: 0.8800 - val_precision: 0.9055 - val_recall: 0.8518\n",
      "Epoch 334/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.2872 - binary_accuracy: 0.8800 - precision: 0.9055 - recall: 0.8518 - val_loss: 0.2788 - val_binary_accuracy: 0.8950 - val_precision: 0.8878 - val_recall: 0.9071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.2788 - binary_accuracy: 0.8950 - precision: 0.8878 - recall: 0.9071 - val_loss: 0.2793 - val_binary_accuracy: 0.8870 - val_precision: 0.8579 - val_recall: 0.9308\n",
      "Epoch 336/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.2793 - binary_accuracy: 0.8870 - precision: 0.8579 - recall: 0.9308 - val_loss: 0.2684 - val_binary_accuracy: 0.8900 - val_precision: 0.9125 - val_recall: 0.8656\n",
      "Epoch 337/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.2684 - binary_accuracy: 0.8900 - precision: 0.9125 - recall: 0.8656 - val_loss: 0.2628 - val_binary_accuracy: 0.9010 - val_precision: 0.9046 - val_recall: 0.8992\n",
      "Epoch 338/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.2628 - binary_accuracy: 0.9010 - precision: 0.9046 - recall: 0.8992 - val_loss: 0.2578 - val_binary_accuracy: 0.9050 - val_precision: 0.8813 - val_recall: 0.9387\n",
      "Epoch 339/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.2578 - binary_accuracy: 0.9050 - precision: 0.8813 - recall: 0.9387 - val_loss: 0.2528 - val_binary_accuracy: 0.9020 - val_precision: 0.8953 - val_recall: 0.9130\n",
      "Epoch 340/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.2528 - binary_accuracy: 0.9020 - precision: 0.8953 - recall: 0.9130 - val_loss: 0.2516 - val_binary_accuracy: 0.8970 - val_precision: 0.9155 - val_recall: 0.8775\n",
      "Epoch 341/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.2516 - binary_accuracy: 0.8970 - precision: 0.9155 - recall: 0.8775 - val_loss: 0.2497 - val_binary_accuracy: 0.9050 - val_precision: 0.8944 - val_recall: 0.9209\n",
      "Epoch 342/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.2497 - binary_accuracy: 0.9050 - precision: 0.8944 - recall: 0.9209 - val_loss: 0.2568 - val_binary_accuracy: 0.8960 - val_precision: 0.8641 - val_recall: 0.9427\n",
      "Epoch 343/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.2568 - binary_accuracy: 0.8960 - precision: 0.8641 - recall: 0.9427 - val_loss: 0.2761 - val_binary_accuracy: 0.8760 - val_precision: 0.9099 - val_recall: 0.8379\n",
      "Epoch 344/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.2761 - binary_accuracy: 0.8760 - precision: 0.9099 - recall: 0.8379 - val_loss: 0.3024 - val_binary_accuracy: 0.8610 - val_precision: 0.8522 - val_recall: 0.8775\n",
      "Epoch 345/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.3024 - binary_accuracy: 0.8610 - precision: 0.8522 - recall: 0.8775 - val_loss: 0.2476 - val_binary_accuracy: 0.9140 - val_precision: 0.8875 - val_recall: 0.9506\n",
      "Epoch 346/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.2476 - binary_accuracy: 0.9140 - precision: 0.8875 - recall: 0.9506 - val_loss: 0.2971 - val_binary_accuracy: 0.8700 - val_precision: 0.9178 - val_recall: 0.8162\n",
      "Epoch 347/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.2971 - binary_accuracy: 0.8700 - precision: 0.9178 - recall: 0.8162 - val_loss: 0.3423 - val_binary_accuracy: 0.8340 - val_precision: 0.8269 - val_recall: 0.8498\n",
      "Epoch 348/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.3423 - binary_accuracy: 0.8340 - precision: 0.8269 - recall: 0.8498 - val_loss: 0.2537 - val_binary_accuracy: 0.8920 - val_precision: 0.8685 - val_recall: 0.9269\n",
      "Epoch 349/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.2537 - binary_accuracy: 0.8920 - precision: 0.8685 - recall: 0.9269 - val_loss: 0.3255 - val_binary_accuracy: 0.8540 - val_precision: 0.8830 - val_recall: 0.8202\n",
      "Epoch 350/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.3255 - binary_accuracy: 0.8540 - precision: 0.8830 - recall: 0.8202 - val_loss: 0.2331 - val_binary_accuracy: 0.9220 - val_precision: 0.9084 - val_recall: 0.9407\n",
      "Epoch 351/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.2331 - binary_accuracy: 0.9220 - precision: 0.9084 - recall: 0.9407 - val_loss: 0.2849 - val_binary_accuracy: 0.8690 - val_precision: 0.8641 - val_recall: 0.8794\n",
      "Epoch 352/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.2849 - binary_accuracy: 0.8690 - precision: 0.8641 - recall: 0.8794 - val_loss: 0.2255 - val_binary_accuracy: 0.9110 - val_precision: 0.9353 - val_recall: 0.8854\n",
      "Epoch 353/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.2255 - binary_accuracy: 0.9110 - precision: 0.9353 - recall: 0.8854 - val_loss: 0.2647 - val_binary_accuracy: 0.8930 - val_precision: 0.8950 - val_recall: 0.8933\n",
      "Epoch 354/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.2647 - binary_accuracy: 0.8930 - precision: 0.8950 - recall: 0.8933 - val_loss: 0.2279 - val_binary_accuracy: 0.9200 - val_precision: 0.8859 - val_recall: 0.9664\n",
      "Epoch 355/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.2279 - binary_accuracy: 0.9200 - precision: 0.8859 - recall: 0.9664 - val_loss: 0.2408 - val_binary_accuracy: 0.9100 - val_precision: 0.9160 - val_recall: 0.9051\n",
      "Epoch 356/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.2408 - binary_accuracy: 0.9100 - precision: 0.9160 - recall: 0.9051 - val_loss: 0.2103 - val_binary_accuracy: 0.9260 - val_precision: 0.9337 - val_recall: 0.9190\n",
      "Epoch 357/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.2103 - binary_accuracy: 0.9260 - precision: 0.9337 - recall: 0.9190 - val_loss: 0.2314 - val_binary_accuracy: 0.9050 - val_precision: 0.9022 - val_recall: 0.9111\n",
      "Epoch 358/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.2314 - binary_accuracy: 0.9050 - precision: 0.9022 - recall: 0.9111 - val_loss: 0.2099 - val_binary_accuracy: 0.9250 - val_precision: 0.9105 - val_recall: 0.9447\n",
      "Epoch 359/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.2099 - binary_accuracy: 0.9250 - precision: 0.9105 - recall: 0.9447 - val_loss: 0.2062 - val_binary_accuracy: 0.9300 - val_precision: 0.9431 - val_recall: 0.9170\n",
      "Epoch 360/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.2062 - binary_accuracy: 0.9300 - precision: 0.9431 - recall: 0.9170 - val_loss: 0.1997 - val_binary_accuracy: 0.9350 - val_precision: 0.9401 - val_recall: 0.9308\n",
      "Epoch 361/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.1997 - binary_accuracy: 0.9350 - precision: 0.9401 - recall: 0.9308 - val_loss: 0.1952 - val_binary_accuracy: 0.9310 - val_precision: 0.9039 - val_recall: 0.9664\n",
      "Epoch 362/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1952 - binary_accuracy: 0.9310 - precision: 0.9039 - recall: 0.9664 - val_loss: 0.1885 - val_binary_accuracy: 0.9360 - val_precision: 0.9234 - val_recall: 0.9526\n",
      "Epoch 363/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1885 - binary_accuracy: 0.9360 - precision: 0.9234 - recall: 0.9526 - val_loss: 0.1870 - val_binary_accuracy: 0.9410 - val_precision: 0.9589 - val_recall: 0.9229\n",
      "Epoch 364/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.1870 - binary_accuracy: 0.9410 - precision: 0.9589 - recall: 0.9229 - val_loss: 0.1799 - val_binary_accuracy: 0.9400 - val_precision: 0.9390 - val_recall: 0.9427\n",
      "Epoch 365/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.1799 - binary_accuracy: 0.9400 - precision: 0.9390 - recall: 0.9427 - val_loss: 0.1774 - val_binary_accuracy: 0.9430 - val_precision: 0.9342 - val_recall: 0.9545\n",
      "Epoch 366/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1774 - binary_accuracy: 0.9430 - precision: 0.9342 - recall: 0.9545 - val_loss: 0.1676 - val_binary_accuracy: 0.9510 - val_precision: 0.9454 - val_recall: 0.9585\n",
      "Epoch 367/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1676 - binary_accuracy: 0.9510 - precision: 0.9454 - recall: 0.9585 - val_loss: 0.1684 - val_binary_accuracy: 0.9470 - val_precision: 0.9557 - val_recall: 0.9387\n",
      "Epoch 368/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.1684 - binary_accuracy: 0.9470 - precision: 0.9557 - recall: 0.9387 - val_loss: 0.1622 - val_binary_accuracy: 0.9550 - val_precision: 0.9493 - val_recall: 0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1622 - binary_accuracy: 0.9550 - precision: 0.9493 - recall: 0.9625 - val_loss: 0.1550 - val_binary_accuracy: 0.9570 - val_precision: 0.9513 - val_recall: 0.9644\n",
      "Epoch 370/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.1550 - binary_accuracy: 0.9570 - precision: 0.9513 - recall: 0.9644 - val_loss: 0.1548 - val_binary_accuracy: 0.9590 - val_precision: 0.9568 - val_recall: 0.9625\n",
      "Epoch 371/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.1548 - binary_accuracy: 0.9590 - precision: 0.9568 - recall: 0.9625 - val_loss: 0.1477 - val_binary_accuracy: 0.9620 - val_precision: 0.9625 - val_recall: 0.9625\n",
      "Epoch 372/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1477 - binary_accuracy: 0.9620 - precision: 0.9625 - recall: 0.9625 - val_loss: 0.1438 - val_binary_accuracy: 0.9590 - val_precision: 0.9586 - val_recall: 0.9605\n",
      "Epoch 373/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.1438 - binary_accuracy: 0.9590 - precision: 0.9586 - recall: 0.9605 - val_loss: 0.1417 - val_binary_accuracy: 0.9610 - val_precision: 0.9587 - val_recall: 0.9644\n",
      "Epoch 374/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.1417 - binary_accuracy: 0.9610 - precision: 0.9587 - recall: 0.9644 - val_loss: 0.1368 - val_binary_accuracy: 0.9650 - val_precision: 0.9663 - val_recall: 0.9644\n",
      "Epoch 375/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1368 - binary_accuracy: 0.9650 - precision: 0.9663 - recall: 0.9644 - val_loss: 0.1335 - val_binary_accuracy: 0.9690 - val_precision: 0.9684 - val_recall: 0.9704\n",
      "Epoch 376/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.1335 - binary_accuracy: 0.9690 - precision: 0.9684 - recall: 0.9704 - val_loss: 0.1274 - val_binary_accuracy: 0.9690 - val_precision: 0.9684 - val_recall: 0.9704\n",
      "Epoch 377/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.1274 - binary_accuracy: 0.9690 - precision: 0.9684 - recall: 0.9704 - val_loss: 0.1274 - val_binary_accuracy: 0.9730 - val_precision: 0.9724 - val_recall: 0.9743\n",
      "Epoch 378/900\n",
      "1000/1000 [==============================] - 0s 87us/sample - loss: 0.1274 - binary_accuracy: 0.9730 - precision: 0.9724 - recall: 0.9743 - val_loss: 0.1202 - val_binary_accuracy: 0.9770 - val_precision: 0.9801 - val_recall: 0.9743\n",
      "Epoch 379/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1202 - binary_accuracy: 0.9770 - precision: 0.9801 - recall: 0.9743 - val_loss: 0.1191 - val_binary_accuracy: 0.9770 - val_precision: 0.9763 - val_recall: 0.9783\n",
      "Epoch 380/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.1191 - binary_accuracy: 0.9770 - precision: 0.9763 - recall: 0.9783 - val_loss: 0.1139 - val_binary_accuracy: 0.9790 - val_precision: 0.9783 - val_recall: 0.9802\n",
      "Epoch 381/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1139 - binary_accuracy: 0.9790 - precision: 0.9783 - recall: 0.9802 - val_loss: 0.1116 - val_binary_accuracy: 0.9790 - val_precision: 0.9764 - val_recall: 0.9822\n",
      "Epoch 382/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.1116 - binary_accuracy: 0.9790 - precision: 0.9764 - recall: 0.9822 - val_loss: 0.1077 - val_binary_accuracy: 0.9810 - val_precision: 0.9803 - val_recall: 0.9822\n",
      "Epoch 383/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.1077 - binary_accuracy: 0.9810 - precision: 0.9803 - recall: 0.9822 - val_loss: 0.1041 - val_binary_accuracy: 0.9820 - val_precision: 0.9822 - val_recall: 0.9822\n",
      "Epoch 384/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1041 - binary_accuracy: 0.9820 - precision: 0.9822 - recall: 0.9822 - val_loss: 0.1016 - val_binary_accuracy: 0.9830 - val_precision: 0.9842 - val_recall: 0.9822\n",
      "Epoch 385/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1016 - binary_accuracy: 0.9830 - precision: 0.9842 - recall: 0.9822 - val_loss: 0.0970 - val_binary_accuracy: 0.9850 - val_precision: 0.9861 - val_recall: 0.9842\n",
      "Epoch 386/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0970 - binary_accuracy: 0.9850 - precision: 0.9861 - recall: 0.9842 - val_loss: 0.0953 - val_binary_accuracy: 0.9850 - val_precision: 0.9861 - val_recall: 0.9842\n",
      "Epoch 387/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0953 - binary_accuracy: 0.9850 - precision: 0.9861 - recall: 0.9842 - val_loss: 0.0912 - val_binary_accuracy: 0.9850 - val_precision: 0.9842 - val_recall: 0.9862\n",
      "Epoch 388/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0912 - binary_accuracy: 0.9850 - precision: 0.9842 - recall: 0.9862 - val_loss: 0.0888 - val_binary_accuracy: 0.9830 - val_precision: 0.9842 - val_recall: 0.9822\n",
      "Epoch 389/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0888 - binary_accuracy: 0.9830 - precision: 0.9842 - recall: 0.9822 - val_loss: 0.0854 - val_binary_accuracy: 0.9870 - val_precision: 0.9843 - val_recall: 0.9901\n",
      "Epoch 390/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0854 - binary_accuracy: 0.9870 - precision: 0.9843 - recall: 0.9901 - val_loss: 0.0827 - val_binary_accuracy: 0.9900 - val_precision: 0.9901 - val_recall: 0.9901\n",
      "Epoch 391/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0827 - binary_accuracy: 0.9900 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.0798 - val_binary_accuracy: 0.9880 - val_precision: 0.9862 - val_recall: 0.9901\n",
      "Epoch 392/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0798 - binary_accuracy: 0.9880 - precision: 0.9862 - recall: 0.9901 - val_loss: 0.0767 - val_binary_accuracy: 0.9890 - val_precision: 0.9901 - val_recall: 0.9881\n",
      "Epoch 393/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0767 - binary_accuracy: 0.9890 - precision: 0.9901 - recall: 0.9881 - val_loss: 0.0745 - val_binary_accuracy: 0.9920 - val_precision: 0.9882 - val_recall: 0.9960\n",
      "Epoch 394/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0745 - binary_accuracy: 0.9920 - precision: 0.9882 - recall: 0.9960 - val_loss: 0.0714 - val_binary_accuracy: 0.9950 - val_precision: 0.9960 - val_recall: 0.9941\n",
      "Epoch 395/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0714 - binary_accuracy: 0.9950 - precision: 0.9960 - recall: 0.9941 - val_loss: 0.0695 - val_binary_accuracy: 0.9920 - val_precision: 0.9882 - val_recall: 0.9960\n",
      "Epoch 396/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0695 - binary_accuracy: 0.9920 - precision: 0.9882 - recall: 0.9960 - val_loss: 0.0675 - val_binary_accuracy: 0.9940 - val_precision: 0.9960 - val_recall: 0.9921\n",
      "Epoch 397/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0675 - binary_accuracy: 0.9940 - precision: 0.9960 - recall: 0.9921 - val_loss: 0.0679 - val_binary_accuracy: 0.9890 - val_precision: 0.9825 - val_recall: 0.9960\n",
      "Epoch 398/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0679 - binary_accuracy: 0.9890 - precision: 0.9825 - recall: 0.9960 - val_loss: 0.0732 - val_binary_accuracy: 0.9880 - val_precision: 1.0000 - val_recall: 0.9763\n",
      "Epoch 399/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0732 - binary_accuracy: 0.9880 - precision: 1.0000 - recall: 0.9763 - val_loss: 0.0892 - val_binary_accuracy: 0.9740 - val_precision: 0.9511 - val_recall: 1.0000\n",
      "Epoch 400/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0892 - binary_accuracy: 0.9740 - precision: 0.9511 - recall: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 0.9510 - val_precision: 1.0000 - val_recall: 0.9032\n",
      "Epoch 401/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.1213 - binary_accuracy: 0.9510 - precision: 1.0000 - recall: 0.9032 - val_loss: 0.1359 - val_binary_accuracy: 0.9490 - val_precision: 0.9129 - val_recall: 0.9941\n",
      "Epoch 402/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.1359 - binary_accuracy: 0.9490 - precision: 0.9129 - recall: 0.9941 - val_loss: 0.1934 - val_binary_accuracy: 0.9230 - val_precision: 0.9351 - val_recall: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/900\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.1934 - binary_accuracy: 0.9230 - precision: 0.9351 - recall: 0.9111 - val_loss: 0.3141 - val_binary_accuracy: 0.8760 - val_precision: 0.9505 - val_recall: 0.7964\n",
      "Epoch 404/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.3141 - binary_accuracy: 0.8760 - precision: 0.9505 - recall: 0.7964 - val_loss: 0.3272 - val_binary_accuracy: 0.8710 - val_precision: 0.7997 - val_recall: 0.9941\n",
      "Epoch 405/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.3272 - binary_accuracy: 0.8710 - precision: 0.7997 - recall: 0.9941 - val_loss: 0.2221 - val_binary_accuracy: 0.9080 - val_precision: 0.8935 - val_recall: 0.9289\n",
      "Epoch 406/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.2221 - binary_accuracy: 0.9080 - precision: 0.8935 - recall: 0.9289 - val_loss: 0.2248 - val_binary_accuracy: 0.9190 - val_precision: 0.9691 - val_recall: 0.8676\n",
      "Epoch 407/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.2248 - binary_accuracy: 0.9190 - precision: 0.9691 - recall: 0.8676 - val_loss: 0.2568 - val_binary_accuracy: 0.8980 - val_precision: 0.9509 - val_recall: 0.8419\n",
      "Epoch 408/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.2568 - binary_accuracy: 0.8980 - precision: 0.9509 - recall: 0.8419 - val_loss: 0.1391 - val_binary_accuracy: 0.9510 - val_precision: 0.9369 - val_recall: 0.9684\n",
      "Epoch 409/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.1391 - binary_accuracy: 0.9510 - precision: 0.9369 - recall: 0.9684 - val_loss: 0.2502 - val_binary_accuracy: 0.8920 - val_precision: 0.8579 - val_recall: 0.9427\n",
      "Epoch 410/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.2502 - binary_accuracy: 0.8920 - precision: 0.8579 - recall: 0.9427 - val_loss: 0.1124 - val_binary_accuracy: 0.9660 - val_precision: 0.9487 - val_recall: 0.9862\n",
      "Epoch 411/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.1124 - binary_accuracy: 0.9660 - precision: 0.9487 - recall: 0.9862 - val_loss: 0.1784 - val_binary_accuracy: 0.9280 - val_precision: 0.9306 - val_recall: 0.9269\n",
      "Epoch 412/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.1784 - binary_accuracy: 0.9280 - precision: 0.9306 - recall: 0.9269 - val_loss: 0.1323 - val_binary_accuracy: 0.9590 - val_precision: 0.9895 - val_recall: 0.9289\n",
      "Epoch 413/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.1323 - binary_accuracy: 0.9590 - precision: 0.9895 - recall: 0.9289 - val_loss: 0.1205 - val_binary_accuracy: 0.9670 - val_precision: 0.9896 - val_recall: 0.9447\n",
      "Epoch 414/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.1205 - binary_accuracy: 0.9670 - precision: 0.9896 - recall: 0.9447 - val_loss: 0.1398 - val_binary_accuracy: 0.9610 - val_precision: 0.9624 - val_recall: 0.9605\n",
      "Epoch 415/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.1398 - binary_accuracy: 0.9610 - precision: 0.9624 - recall: 0.9605 - val_loss: 0.0951 - val_binary_accuracy: 0.9790 - val_precision: 0.9709 - val_recall: 0.9881\n",
      "Epoch 416/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0951 - binary_accuracy: 0.9790 - precision: 0.9709 - recall: 0.9881 - val_loss: 0.1213 - val_binary_accuracy: 0.9720 - val_precision: 0.9668 - val_recall: 0.9783\n",
      "Epoch 417/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.1213 - binary_accuracy: 0.9720 - precision: 0.9668 - recall: 0.9783 - val_loss: 0.0926 - val_binary_accuracy: 0.9850 - val_precision: 0.9881 - val_recall: 0.9822\n",
      "Epoch 418/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0926 - binary_accuracy: 0.9850 - precision: 0.9881 - recall: 0.9822 - val_loss: 0.0848 - val_binary_accuracy: 0.9850 - val_precision: 0.9920 - val_recall: 0.9783\n",
      "Epoch 419/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0848 - binary_accuracy: 0.9850 - precision: 0.9920 - recall: 0.9783 - val_loss: 0.0853 - val_binary_accuracy: 0.9850 - val_precision: 0.9842 - val_recall: 0.9862\n",
      "Epoch 420/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0853 - binary_accuracy: 0.9850 - precision: 0.9842 - recall: 0.9862 - val_loss: 0.0805 - val_binary_accuracy: 0.9860 - val_precision: 0.9824 - val_recall: 0.9901\n",
      "Epoch 421/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0805 - binary_accuracy: 0.9860 - precision: 0.9824 - recall: 0.9901 - val_loss: 0.0739 - val_binary_accuracy: 0.9890 - val_precision: 0.9843 - val_recall: 0.9941\n",
      "Epoch 422/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0739 - binary_accuracy: 0.9890 - precision: 0.9843 - recall: 0.9941 - val_loss: 0.0716 - val_binary_accuracy: 0.9890 - val_precision: 0.9882 - val_recall: 0.9901\n",
      "Epoch 423/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0716 - binary_accuracy: 0.9890 - precision: 0.9882 - recall: 0.9901 - val_loss: 0.0687 - val_binary_accuracy: 0.9940 - val_precision: 0.9960 - val_recall: 0.9921\n",
      "Epoch 424/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0687 - binary_accuracy: 0.9940 - precision: 0.9960 - recall: 0.9921 - val_loss: 0.0627 - val_binary_accuracy: 0.9920 - val_precision: 0.9940 - val_recall: 0.9901\n",
      "Epoch 425/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0627 - binary_accuracy: 0.9920 - precision: 0.9940 - recall: 0.9901 - val_loss: 0.0601 - val_binary_accuracy: 0.9940 - val_precision: 0.9921 - val_recall: 0.9960\n",
      "Epoch 426/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0601 - binary_accuracy: 0.9940 - precision: 0.9921 - recall: 0.9960 - val_loss: 0.0626 - val_binary_accuracy: 0.9920 - val_precision: 0.9902 - val_recall: 0.9941\n",
      "Epoch 427/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0626 - binary_accuracy: 0.9920 - precision: 0.9902 - recall: 0.9941 - val_loss: 0.0610 - val_binary_accuracy: 0.9910 - val_precision: 0.9901 - val_recall: 0.9921\n",
      "Epoch 428/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0610 - binary_accuracy: 0.9910 - precision: 0.9901 - recall: 0.9921 - val_loss: 0.0518 - val_binary_accuracy: 0.9970 - val_precision: 1.0000 - val_recall: 0.9941\n",
      "Epoch 429/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0518 - binary_accuracy: 0.9970 - precision: 1.0000 - recall: 0.9941 - val_loss: 0.0494 - val_binary_accuracy: 0.9970 - val_precision: 1.0000 - val_recall: 0.9941\n",
      "Epoch 430/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0494 - binary_accuracy: 0.9970 - precision: 1.0000 - recall: 0.9941 - val_loss: 0.0519 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 431/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0519 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0488 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 432/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0488 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0471 - val_binary_accuracy: 0.9970 - val_precision: 0.9961 - val_recall: 0.9980\n",
      "Epoch 433/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0471 - binary_accuracy: 0.9970 - precision: 0.9961 - recall: 0.9980 - val_loss: 0.0440 - val_binary_accuracy: 0.9970 - val_precision: 0.9961 - val_recall: 0.9980\n",
      "Epoch 434/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0440 - binary_accuracy: 0.9970 - precision: 0.9961 - recall: 0.9980 - val_loss: 0.0419 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 435/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0419 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0428 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 436/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0428 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0406 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0406 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0383 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 438/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0383 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0367 - val_binary_accuracy: 0.9980 - val_precision: 1.0000 - val_recall: 0.9960\n",
      "Epoch 439/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0367 - binary_accuracy: 0.9980 - precision: 1.0000 - recall: 0.9960 - val_loss: 0.0358 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 440/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0358 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0354 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 441/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0354 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0341 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 442/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0341 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0330 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 443/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0330 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0326 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 444/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0326 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0315 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 445/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0315 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0301 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 446/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0301 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0295 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 447/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0295 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0288 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 448/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0288 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0277 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 449/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0277 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0273 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 450/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0273 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0269 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 451/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0269 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0260 - val_binary_accuracy: 0.9990 - val_precision: 1.0000 - val_recall: 0.9980\n",
      "Epoch 452/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0260 - binary_accuracy: 0.9990 - precision: 1.0000 - recall: 0.9980 - val_loss: 0.0252 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 453/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0252 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0247 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 454/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0247 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0241 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 455/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0241 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0235 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 456/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0235 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0231 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 457/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0231 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0227 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 458/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0227 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0221 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 459/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0221 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0216 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 460/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0216 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0211 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 461/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0211 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0208 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 462/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0208 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0204 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 463/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0204 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0199 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 464/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0199 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0196 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 465/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0196 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0192 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 466/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0192 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0188 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 467/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0188 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0184 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 468/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0184 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0181 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 469/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0181 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0178 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 470/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0178 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0174 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0174 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0171 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 472/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0171 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0169 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 473/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0169 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0166 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 474/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0166 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0163 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 475/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0163 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0160 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 476/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0160 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0157 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 477/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0157 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0155 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 478/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0155 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0152 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 479/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0152 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0150 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 480/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0150 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0147 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 481/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0147 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0145 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 482/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0145 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0143 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 483/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0143 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0141 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 484/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0141 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0139 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 485/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0139 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0136 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 486/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0136 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0134 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 487/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0134 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0132 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 488/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0132 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0130 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 489/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0130 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0129 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 490/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0129 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0127 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 491/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0127 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0125 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 492/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0125 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0123 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 493/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0123 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0122 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 494/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0122 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0120 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 495/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0120 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0118 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 496/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0118 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0117 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 497/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0117 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0115 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 498/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0115 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0114 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 499/900\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.0114 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0112 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 500/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0112 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0111 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 501/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0111 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0109 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 502/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0109 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0108 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 503/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0108 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0106 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 504/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0106 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0105 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0105 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0104 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 506/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0104 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0102 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 507/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0102 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0101 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 508/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0101 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0100 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 509/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0100 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0099 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 510/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0099 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0098 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 511/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0098 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0096 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 512/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0096 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0095 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 513/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0095 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0094 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 514/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0094 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 515/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0093 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0092 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 516/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0092 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 517/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0091 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 518/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0090 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0089 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 519/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0089 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0088 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 520/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0088 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 521/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0087 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0086 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 522/900\n",
      "1000/1000 [==============================] - 0s 94us/sample - loss: 0.0086 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 523/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0085 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 524/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0084 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 525/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0083 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 526/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0082 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 527/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0081 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 528/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0081 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 529/900\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 0.0080 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 530/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0079 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 531/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0078 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 532/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0077 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 533/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0077 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 534/900\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0076 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 535/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0075 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 536/900\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.0074 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 537/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0074 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 538/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0073 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 539/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0072 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 540/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0071 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 541/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0071 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 542/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0070 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 543/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0069 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 544/900\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 0.0069 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 545/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0068 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 546/900\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 0.0067 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 547/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0067 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 548/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0066 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 549/900\n",
      "1000/1000 [==============================] - 0s 103us/sample - loss: 0.0066 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 550/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0065 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0064 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 551/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0064 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0064 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 552/900\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.0064 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 553/900\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.0063 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 554/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0063 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0062 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 555/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0062 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0062 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 556/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0062 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0061 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 557/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0061 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0061 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 558/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0061 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0060 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 559/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0060 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 560/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0059 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 561/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0059 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0058 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 562/900\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0058 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0058 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 563/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0058 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0057 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 564/900\n",
      "1000/1000 [==============================] - 0s 106us/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0057 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 565/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0057 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 566/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0056 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 567/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0056 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0056 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 568/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0056 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0055 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 569/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0055 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0055 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 570/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0055 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 571/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0054 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 572/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0054 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 573/900\n",
      "1000/1000 [==============================] - 0s 99us/sample - loss: 0.0053 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 574/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0053 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0053 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 575/900\n",
      "1000/1000 [==============================] - 0s 90us/sample - loss: 0.0053 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0052 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 576/900\n",
      "1000/1000 [==============================] - 0s 97us/sample - loss: 0.0052 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0052 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 577/900\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.0052 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0051 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 578/900\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.0051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0051 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 579/900\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0051 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 580/900\n",
      "1000/1000 [==============================] - 0s 135us/sample - loss: 0.0051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0050 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 581/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0050 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 582/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0050 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 583/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0049 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 584/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0049 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 585/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0049 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0048 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 586/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0048 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 587/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0048 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 588/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 589/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0047 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 590/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0047 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0047 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 591/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0047 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0046 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 592/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0046 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0046 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 593/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0046 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 594/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 595/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 596/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 597/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0044 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 598/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0044 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 599/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0044 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 600/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0044 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 601/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0043 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 602/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0043 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0043 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 603/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0043 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 604/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 605/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 606/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0042 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 608/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 609/900\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0041 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 610/900\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 611/900\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 612/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 613/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0040 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 614/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0040 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 615/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 616/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 617/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 618/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0039 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 619/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 620/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 621/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0038 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 622/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 623/900\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 624/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 625/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 626/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0037 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 627/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 628/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 629/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 630/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 631/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 632/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 633/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 634/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0035 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 635/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0035 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 636/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 637/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 638/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 639/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 640/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 642/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 643/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 644/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0033 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 645/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0033 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 646/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 647/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 648/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 649/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 650/900\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 651/900\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 652/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 653/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 654/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 655/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 656/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 657/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0031 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 658/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 659/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 660/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 661/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 662/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 663/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 664/900\n",
      "1000/1000 [==============================] - 0s 133us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 665/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 666/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 667/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 668/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 669/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 670/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 671/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 672/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 673/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 674/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 675/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 676/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0028 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 677/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 678/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 679/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 680/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 681/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 682/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0027 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 683/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 684/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 685/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 686/900\n",
      "1000/1000 [==============================] - 0s 131us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 687/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 688/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 689/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 690/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 691/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 692/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 693/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 694/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 695/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 696/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 697/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 698/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 699/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 700/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 701/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 702/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 703/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 704/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 705/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 706/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 707/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 708/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 710/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 711/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 712/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 713/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 714/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 715/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 716/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 717/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 718/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 719/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 720/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 721/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 722/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 723/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 724/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 725/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 726/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 727/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 728/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 729/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 730/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 731/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 732/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 733/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 734/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 735/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 736/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 737/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 738/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 739/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 740/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 741/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 742/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 743/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 744/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 745/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 746/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 747/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 748/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 749/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 750/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 751/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 752/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 753/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 754/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 755/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 756/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 757/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 758/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 759/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 760/900\n",
      "1000/1000 [==============================] - 0s 107us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 761/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 762/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 763/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 764/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 765/900\n",
      "1000/1000 [==============================] - 0s 120us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 766/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 767/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 768/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 769/900\n",
      "1000/1000 [==============================] - 0s 117us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 770/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 771/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 772/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 773/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 774/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 775/900\n",
      "1000/1000 [==============================] - 0s 119us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 776/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 777/900\n",
      "1000/1000 [==============================] - 0s 114us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 778/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 779/900\n",
      "1000/1000 [==============================] - 0s 121us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 780/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 781/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 782/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 783/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 784/900\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 785/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 786/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 787/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 788/900\n",
      "1000/1000 [==============================] - 0s 116us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 789/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 790/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 791/900\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 792/900\n",
      "1000/1000 [==============================] - 0s 118us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 793/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 794/900\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 795/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 796/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 797/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 798/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 799/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 800/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 801/900\n",
      "1000/1000 [==============================] - 0s 112us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 802/900\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 803/900\n",
      "1000/1000 [==============================] - 0s 125us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 804/900\n",
      "1000/1000 [==============================] - 0s 132us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 805/900\n",
      "1000/1000 [==============================] - 0s 123us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 806/900\n",
      "1000/1000 [==============================] - 0s 128us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 807/900\n",
      "1000/1000 [==============================] - 0s 124us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 808/900\n",
      "1000/1000 [==============================] - 0s 127us/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 809/900\n",
      "1000/1000 [==============================] - 0s 126us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 810/900\n",
      "1000/1000 [==============================] - 0s 129us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811/900\n",
      "1000/1000 [==============================] - 0s 113us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 812/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 813/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 814/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 815/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 816/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 817/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 818/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 819/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 820/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 821/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 822/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 823/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 824/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 825/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 826/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 827/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 828/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 829/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 830/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 831/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 832/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 833/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 834/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 835/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 836/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 837/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 838/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 839/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 840/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 841/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 842/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 843/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 844/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 845/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 846/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 847/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 848/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 849/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 850/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 851/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 852/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 853/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 854/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 855/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 856/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 857/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 858/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 859/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 860/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 861/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 862/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 863/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 864/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 865/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 866/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 867/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 868/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 869/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 870/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 871/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 872/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 873/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 874/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 875/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 876/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 877/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 878/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 880/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 881/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 882/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 883/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 884/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 885/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 886/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 887/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 888/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 889/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 890/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 891/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 892/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 893/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 894/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 895/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 896/900\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 897/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 898/900\n",
      "1000/1000 [==============================] - 0s 111us/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 899/900\n",
      "1000/1000 [==============================] - 0s 108us/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 900/900\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model for classification\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1, activation='sigmoid')(ts_layer_5)\n",
    "\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "print(model.summary())\n",
    "\n",
    "history_cls = model.fit(x=X, y=y_cls, batch_size=batch_size, epochs=900, validation_data =(X, y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(10, 10), tight_layout=True)\n",
    "ax[0].plot(history_cls.history['val_loss'])\n",
    "ax[0].plot(history_cls.history['loss'])\n",
    "ax[0].set_title('loss: Binary Cross Entropy')\n",
    "ax[1].plot(history_cls.history['binary_accuracy'])\n",
    "ax[1].plot(history_cls.history['val_binary_accuracy'])\n",
    "ax[1].set_title('Binary Accuracy')\n",
    "ax[2].plot(history_cls.history['precision'])\n",
    "ax[2].plot(history_cls.history['val_precision'])\n",
    "ax[2].set_title('Precision')\n",
    "ax[3].plot(history_cls.history['recall'])\n",
    "ax[3].plot(history_cls.history['val_recall'])\n",
    "ax[3].set_title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only pricing data from all tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>log_adj_daily_returns_WFC</th>\n",
       "      <th>log_adj_daily_returns_JPM</th>\n",
       "      <th>log_adj_daily_returns_BAC</th>\n",
       "      <th>log_adj_daily_returns_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  log_adj_daily_returns_WFC  log_adj_daily_returns_JPM  \\\n",
       "0 2019-10-22                   0.003166                   0.009986   \n",
       "1 2019-10-21                   0.009758                   0.024498   \n",
       "2 2019-10-18                   0.007230                   0.001743   \n",
       "3 2019-10-17                   0.000403                   0.005583   \n",
       "4 2019-10-16                  -0.010431                  -0.002337   \n",
       "5 2019-10-15                   0.016905                   0.029696   \n",
       "6 2019-10-14                   0.001219                   0.002666   \n",
       "7 2019-10-11                   0.011445                   0.016758   \n",
       "\n",
       "   log_adj_daily_returns_BAC  log_adj_daily_returns_C  \n",
       "0                   0.005786                 0.003475  \n",
       "1                   0.021836                 0.029250  \n",
       "2                   0.002970                 0.002009  \n",
       "3                   0.002979                 0.001438  \n",
       "4                   0.014691                -0.024447  \n",
       "5                   0.020045                 0.013856  \n",
       "6                   0.007924                 0.001995  \n",
       "7                   0.016039                 0.021339  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset_size_by_ticker = [200, 100, 50, 300]\n",
    "batch_size = 650\n",
    "assert batch_size == sum(dataset_size_by_ticker)\n",
    "\n",
    "preprocessed_df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "\n",
    "features_to_test = ['log_adj_daily_returns']\n",
    "data_df = preprocessed_df[['timestamp'] + ['_'.join([feature, t]) for t in tickers for feature in features_to_test]]\n",
    "data_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-5)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_C(t-5)</th>\n",
       "      <th>timestamp(t-4)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-4)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-4)</th>\n",
       "      <th>log_adj_daily_returns_C(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp(t+0)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+0)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+0)</th>\n",
       "      <th>log_adj_daily_returns_C(t+0)</th>\n",
       "      <th>timestamp(t+1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+1)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_C(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>-0.022548</td>\n",
       "      <td>-0.024313</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.024447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp(t-5)  log_adj_daily_returns_WFC(t-5)  \\\n",
       "1     2019-10-14                        0.001219   \n",
       "2     2019-10-11                        0.011445   \n",
       "3     2019-10-10                        0.010331   \n",
       "4     2019-10-09                        0.006877   \n",
       "5     2019-10-08                       -0.020491   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_BAC(t-5)  \\\n",
       "1                        0.002666                        0.007924   \n",
       "2                        0.016758                        0.016039   \n",
       "3                        0.013931                        0.019880   \n",
       "4                        0.007218                        0.009366   \n",
       "5                       -0.022548                       -0.024313   \n",
       "\n",
       "   log_adj_daily_returns_C(t-5) timestamp(t-4)  \\\n",
       "1                      0.001995     2019-10-15   \n",
       "2                      0.021339     2019-10-14   \n",
       "3                      0.017494     2019-10-11   \n",
       "4                      0.015393     2019-10-10   \n",
       "5                     -0.026014     2019-10-09   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t-4)  log_adj_daily_returns_JPM(t-4)  \\\n",
       "1                        0.016905                        0.029696   \n",
       "2                        0.001219                        0.002666   \n",
       "3                        0.011445                        0.016758   \n",
       "4                        0.010331                        0.013931   \n",
       "5                        0.006877                        0.007218   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t-4)  log_adj_daily_returns_C(t-4)  ...  \\\n",
       "1                        0.020045                      0.013856  ...   \n",
       "2                        0.007924                      0.001995  ...   \n",
       "3                        0.016039                      0.021339  ...   \n",
       "4                        0.019880                      0.017494  ...   \n",
       "5                        0.009366                      0.015393  ...   \n",
       "\n",
       "  timestamp(t+0)  log_adj_daily_returns_WFC(t+0)  \\\n",
       "1     2019-10-21                        0.009758   \n",
       "2     2019-10-18                        0.007230   \n",
       "3     2019-10-17                        0.000403   \n",
       "4     2019-10-16                       -0.010431   \n",
       "5     2019-10-15                        0.016905   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t+0)  log_adj_daily_returns_BAC(t+0)  \\\n",
       "1                        0.024498                        0.021836   \n",
       "2                        0.001743                        0.002970   \n",
       "3                        0.005583                        0.002979   \n",
       "4                       -0.002337                        0.014691   \n",
       "5                        0.029696                        0.020045   \n",
       "\n",
       "   log_adj_daily_returns_C(t+0) timestamp(t+1)  \\\n",
       "1                      0.029250     2019-10-22   \n",
       "2                      0.002009     2019-10-21   \n",
       "3                      0.001438     2019-10-18   \n",
       "4                     -0.024447     2019-10-17   \n",
       "5                      0.013856     2019-10-16   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  log_adj_daily_returns_JPM(t+1)  \\\n",
       "1                        0.003166                        0.009986   \n",
       "2                        0.009758                        0.024498   \n",
       "3                        0.007230                        0.001743   \n",
       "4                        0.000403                        0.005583   \n",
       "5                       -0.010431                       -0.002337   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t+1)  log_adj_daily_returns_C(t+1)  \n",
       "1                        0.005786                      0.003475  \n",
       "2                        0.021836                      0.029250  \n",
       "3                        0.002970                      0.002009  \n",
       "4                        0.002979                      0.001438  \n",
       "5                        0.014691                     -0.024447  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_time_series(data_df, data_df.columns, n_trail=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['log_adj_daily_returns_WFC(t-5)', 'log_adj_daily_returns_WFC(t-4)', 'log_adj_daily_returns_WFC(t-3)', 'log_adj_daily_returns_WFC(t-2)', 'log_adj_daily_returns_WFC(t-1)', 'log_adj_daily_returns_WFC(t+0)', 'log_adj_daily_returns_WFC(t+1)'], ['log_adj_daily_returns_JPM(t-5)', 'log_adj_daily_returns_JPM(t-4)', 'log_adj_daily_returns_JPM(t-3)', 'log_adj_daily_returns_JPM(t-2)', 'log_adj_daily_returns_JPM(t-1)', 'log_adj_daily_returns_JPM(t+0)', 'log_adj_daily_returns_JPM(t+1)'], ['log_adj_daily_returns_BAC(t-5)', 'log_adj_daily_returns_BAC(t-4)', 'log_adj_daily_returns_BAC(t-3)', 'log_adj_daily_returns_BAC(t-2)', 'log_adj_daily_returns_BAC(t-1)', 'log_adj_daily_returns_BAC(t+0)', 'log_adj_daily_returns_BAC(t+1)'], ['log_adj_daily_returns_C(t-5)', 'log_adj_daily_returns_C(t-4)', 'log_adj_daily_returns_C(t-3)', 'log_adj_daily_returns_C(t-2)', 'log_adj_daily_returns_C(t-1)', 'log_adj_daily_returns_C(t+0)', 'log_adj_daily_returns_C(t+1)']]\n"
     ]
    }
   ],
   "source": [
    "column_names_by_ticker = [[name for name in df.columns if 'log_adj_daily_returns_' + t in name] for t in tickers]\n",
    "print(column_names_by_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list(map(lambda cols: df[cols], column_names_by_ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   log_adj_daily_returns_WFC(t-5)  log_adj_daily_returns_WFC(t-4)  \\\n",
      "1                        0.001219                        0.016905   \n",
      "2                        0.011445                        0.001219   \n",
      "3                        0.010331                        0.011445   \n",
      "4                        0.006877                        0.010331   \n",
      "5                       -0.020491                        0.006877   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-3)  log_adj_daily_returns_WFC(t-2)  \\\n",
      "1                       -0.010431                        0.000403   \n",
      "2                        0.016905                       -0.010431   \n",
      "3                        0.001219                        0.016905   \n",
      "4                        0.011445                        0.001219   \n",
      "5                        0.010331                        0.011445   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-1)  log_adj_daily_returns_WFC(t+0)  \\\n",
      "1                        0.007230                        0.009758   \n",
      "2                        0.000403                        0.007230   \n",
      "3                       -0.010431                        0.000403   \n",
      "4                        0.016905                       -0.010431   \n",
      "5                        0.001219                        0.016905   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t+1)  \n",
      "1                        0.003166  \n",
      "2                        0.009758  \n",
      "3                        0.007230  \n",
      "4                        0.000403  \n",
      "5                       -0.010431  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_JPM(t-4)  \\\n",
      "1                        0.002666                        0.029696   \n",
      "2                        0.016758                        0.002666   \n",
      "3                        0.013931                        0.016758   \n",
      "4                        0.007218                        0.013931   \n",
      "5                       -0.022548                        0.007218   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-3)  log_adj_daily_returns_JPM(t-2)  \\\n",
      "1                       -0.002337                        0.005583   \n",
      "2                        0.029696                       -0.002337   \n",
      "3                        0.002666                        0.029696   \n",
      "4                        0.016758                        0.002666   \n",
      "5                        0.013931                        0.016758   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-1)  log_adj_daily_returns_JPM(t+0)  \\\n",
      "1                        0.001743                        0.024498   \n",
      "2                        0.005583                        0.001743   \n",
      "3                       -0.002337                        0.005583   \n",
      "4                        0.029696                       -0.002337   \n",
      "5                        0.002666                        0.029696   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t+1)  \n",
      "1                        0.009986  \n",
      "2                        0.024498  \n",
      "3                        0.001743  \n",
      "4                        0.005583  \n",
      "5                       -0.002337  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_BAC(t-5)  log_adj_daily_returns_BAC(t-4)  \\\n",
      "1                        0.007924                        0.020045   \n",
      "2                        0.016039                        0.007924   \n",
      "3                        0.019880                        0.016039   \n",
      "4                        0.009366                        0.019880   \n",
      "5                       -0.024313                        0.009366   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-3)  log_adj_daily_returns_BAC(t-2)  \\\n",
      "1                        0.014691                        0.002979   \n",
      "2                        0.020045                        0.014691   \n",
      "3                        0.007924                        0.020045   \n",
      "4                        0.016039                        0.007924   \n",
      "5                        0.019880                        0.016039   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-1)  log_adj_daily_returns_BAC(t+0)  \\\n",
      "1                        0.002970                        0.021836   \n",
      "2                        0.002979                        0.002970   \n",
      "3                        0.014691                        0.002979   \n",
      "4                        0.020045                        0.014691   \n",
      "5                        0.007924                        0.020045   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t+1)  \n",
      "1                        0.005786  \n",
      "2                        0.021836  \n",
      "3                        0.002970  \n",
      "4                        0.002979  \n",
      "5                        0.014691  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_C(t-5)  log_adj_daily_returns_C(t-4)  \\\n",
      "1                      0.001995                      0.013856   \n",
      "2                      0.021339                      0.001995   \n",
      "3                      0.017494                      0.021339   \n",
      "4                      0.015393                      0.017494   \n",
      "5                     -0.026014                      0.015393   \n",
      "\n",
      "   log_adj_daily_returns_C(t-3)  log_adj_daily_returns_C(t-2)  \\\n",
      "1                     -0.024447                      0.001438   \n",
      "2                      0.013856                     -0.024447   \n",
      "3                      0.001995                      0.013856   \n",
      "4                      0.021339                      0.001995   \n",
      "5                      0.017494                      0.021339   \n",
      "\n",
      "   log_adj_daily_returns_C(t-1)  log_adj_daily_returns_C(t+0)  \\\n",
      "1                      0.002009                      0.029250   \n",
      "2                      0.001438                      0.002009   \n",
      "3                     -0.024447                      0.001438   \n",
      "4                      0.013856                     -0.024447   \n",
      "5                      0.001995                      0.013856   \n",
      "\n",
      "   log_adj_daily_returns_C(t+1)  \n",
      "1                      0.003475  \n",
      "2                      0.029250  \n",
      "3                      0.002009  \n",
      "4                      0.001438  \n",
      "5                     -0.024447  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking dfs\n",
    "for el in dfs:\n",
    "    print(el.head())\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_by_ticker = list(map(lambda d: d.values, dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 4\n",
      "Shape of each dataset: [(5024, 7), (5024, 7), (5024, 7), (5024, 7)]\n"
     ]
    }
   ],
   "source": [
    "print('Number of datasets: {}'.format(len(datasets_by_ticker)))\n",
    "print('Shape of each dataset: {}'.format(list(map(lambda d: d.shape, datasets_by_ticker))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for each ticker: [200, 100, 50, 300]\n",
      "Shape of each sampled dataset: [(200, 7), (100, 7), (50, 7), (300, 7)]\n"
     ]
    }
   ],
   "source": [
    "# Shuffling and Sampling Datasets\n",
    "shuffled_indices_per_ticker = [np.random.choice(len(datasets_by_ticker[i]),\n",
    "                                                size=dataset_size_by_ticker[i],\n",
    "                                                replace=False)\n",
    "                               for i in range(len(dataset_size_by_ticker))]\n",
    "print('Number of samples for each ticker: {}'.format(list(map(len, shuffled_indices_per_ticker))))\n",
    "sampled_datasets_by_ticker = [datasets_by_ticker[i][shuffled_indices_per_ticker[i]] for i in range(len(datasets_by_ticker))]\n",
    "print('Shape of each sampled dataset: {}'.format(list(map(lambda d: d.shape, sampled_datasets_by_ticker))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (650, 7)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating datasets\n",
    "dataset = np.concatenate(sampled_datasets_by_ticker, axis=0)\n",
    "print('Shape of dataset: {}'.format(dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161 521 569 584 609 256 218  17 513 207 584 503 547 157 253  21 565 589\n",
      " 107 533 490  32 189 399  22 104 197  23 491 255   5  91 435 105 323 198\n",
      " 607 406 383 591 329 255 514 497  30 624 575  41 573  66  36 279 630 261\n",
      " 373 618 574 129 504 531 524  68 363 100 145  95 166 156 525 585 459 162\n",
      " 346 194 173 157 353  55 357 478  96 521 395 131 222  94 514 437 433 104\n",
      " 306  90 602 560 175 347 151 644 152 455  97 634  92 194 231 495 529 557\n",
      " 166 189 286 311  58 290 238 549 430 599 509 171 216  73 601 541 600 106\n",
      " 542 310 466 232 479 279 300 305 635 263 383 389 555  70 250 350 424 121\n",
      " 391 111 495  98 147  18 173 454  64 148 553 584 626 423 555 431 141 362\n",
      "  42 239  79 282 123 592  17 632 321 334  87 562 327 337 569 329 116 158\n",
      " 517 258 381 624 597 151 450 487 546 113 406 542  13 261 138 350 301 379\n",
      " 521  60 410 368 595 123 212 577 485 367 378 505 500 548 112 544 614 446\n",
      " 520 112 375 297 249 596 483 186 616 194 243 534 583 216 240 496 363 572\n",
      " 527 624 278 151 423 649 354 281 635 511 131 583 452 193 234 534 111 569\n",
      " 578 120 508  92  89 451 458 282 605 303  35 306 543 116 241 278 369 321\n",
      " 244 146 540 529 424  62 463 424 597 281 406 339 530 445 625  53 303 246\n",
      "  96 377 286  33 505 431 317  81 516 236 109 175 571 451   0 588  95 111\n",
      " 248 405 180 404 635 207 295 147 396 351 642 362 272 322 110 649 515 642\n",
      " 420 406 345 231 379 437  38 318 171  56 396 591 279 476 354 626  46 143\n",
      " 567 507 505 641 324 129 608 516  37 534 485 534 555 608 210 507  39 168\n",
      " 443 208 420 282 368 274 524  58 424 366 183 142 137 630 293 102 452 243\n",
      " 300  13 220 407  29 482 331 358 288 553 486 109 628 618 486 217 281 244\n",
      " 270 347 300 354 149 470 174 613  54 289 638 223 230 593 345 508 187 250\n",
      " 401 268 558  34 242 443 544 486  95 352 241 342 640 168 144 519 496 291\n",
      "  82 272 510 645 617 620 495  84 580 566 261 273 364 542 498 102 239 611\n",
      " 612 320 456 373 170 103 610 545 576 370 557  32 641 398 582 256 170  71\n",
      " 245 300 402 485 546 347 497 149  28 544 554 219 234 590 155  65 460 226\n",
      " 244   0 143 451 200 471 583 372 280 360 568 424 377 457 499 126  59 122\n",
      " 450 395 391 174  99 599 594 128 345 649 447 507 418  86 290 492 265 499\n",
      " 370 273 511 116 362 630 289 642 124 311  63 242 449 603 220 457 102 438\n",
      " 478 399 426 582 101 495  64 211 347  76  59  43  26 176 228 494 435 107\n",
      " 164 464 543 343 368 420 214 335 209 592 290 382 310 369 499 528 120 611\n",
      "   9 477 218 518 368 634 148  98 438 415 165 303 584 216 432 629 372 447\n",
      " 219  60 543 151 570 280 198  47 244 209  60 619   7  80  61   8 101 462\n",
      " 265 451 441 421 540  99 167 400 587 599 197 624 166 618 317   3  18 500\n",
      " 344 158 464  65 140 399 631 190 239  43 123  80  58 187 508 462 224  18\n",
      "  80  22]\n"
     ]
    }
   ],
   "source": [
    "# Shuffling merged dataset\n",
    "shuffle_indices = np.random.randint(len(dataset), size=len(dataset))\n",
    "assert len(shuffle_indices) == len(dataset)\n",
    "print(shuffle_indices)\n",
    "shuffled_dataset = dataset[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features: (650, 6)\n",
      "Shape of targets: (650,)\n"
     ]
    }
   ],
   "source": [
    "# Spliting Dataset into Features and Labels\n",
    "X, y = shuffled_dataset[:, :-1], shuffled_dataset[:, -1]\n",
    "print('Shape of features: {}'.format(X.shape))\n",
    "print('Shape of targets: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 650 samples, validate on 650 samples\n",
      "Epoch 1/900\n",
      "650/650 [==============================] - 6s 9ms/sample - loss: 7.4908e-04 - val_loss: 0.0010\n",
      "Epoch 2/900\n",
      "650/650 [==============================] - 0s 75us/sample - loss: 0.0010 - val_loss: 7.5246e-04\n",
      "Epoch 3/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.5246e-04 - val_loss: 8.4625e-04\n",
      "Epoch 4/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 8.4625e-04 - val_loss: 9.0363e-04\n",
      "Epoch 5/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 9.0363e-04 - val_loss: 8.3249e-04\n",
      "Epoch 6/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 8.3249e-04 - val_loss: 7.6318e-04\n",
      "Epoch 7/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.6318e-04 - val_loss: 7.5113e-04\n",
      "Epoch 8/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.5113e-04 - val_loss: 7.7838e-04\n",
      "Epoch 9/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.7838e-04 - val_loss: 8.0174e-04\n",
      "Epoch 10/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 8.0174e-04 - val_loss: 7.9987e-04\n",
      "Epoch 11/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.9987e-04 - val_loss: 7.8066e-04\n",
      "Epoch 12/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.8066e-04 - val_loss: 7.6049e-04\n",
      "Epoch 13/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.6049e-04 - val_loss: 7.4984e-04\n",
      "Epoch 14/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4984e-04 - val_loss: 7.5042e-04\n",
      "Epoch 15/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.5042e-04 - val_loss: 7.5765e-04\n",
      "Epoch 16/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.5765e-04 - val_loss: 7.6486e-04\n",
      "Epoch 17/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.6486e-04 - val_loss: 7.6728e-04\n",
      "Epoch 18/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.6728e-04 - val_loss: 7.6414e-04\n",
      "Epoch 19/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.6414e-04 - val_loss: 7.5789e-04\n",
      "Epoch 20/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.5789e-04 - val_loss: 7.5201e-04\n",
      "Epoch 21/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.5201e-04 - val_loss: 7.4908e-04\n",
      "Epoch 22/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4908e-04 - val_loss: 7.4975e-04\n",
      "Epoch 23/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4975e-04 - val_loss: 7.5272e-04\n",
      "Epoch 24/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.5272e-04 - val_loss: 7.5566e-04\n",
      "Epoch 25/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.5566e-04 - val_loss: 7.5667e-04\n",
      "Epoch 26/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.5667e-04 - val_loss: 7.5532e-04\n",
      "Epoch 27/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.5532e-04 - val_loss: 7.5265e-04\n",
      "Epoch 28/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.5265e-04 - val_loss: 7.5018e-04\n",
      "Epoch 29/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.5018e-04 - val_loss: 7.4898e-04\n",
      "Epoch 30/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4898e-04 - val_loss: 7.4923e-04\n",
      "Epoch 31/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4923e-04 - val_loss: 7.5037e-04\n",
      "Epoch 32/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.5037e-04 - val_loss: 7.5155e-04\n",
      "Epoch 33/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.5155e-04 - val_loss: 7.5209e-04\n",
      "Epoch 34/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.5209e-04 - val_loss: 7.5178e-04\n",
      "Epoch 35/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.5178e-04 - val_loss: 7.5084e-04\n",
      "Epoch 36/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.5084e-04 - val_loss: 7.4977e-04\n",
      "Epoch 37/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4977e-04 - val_loss: 7.4905e-04\n",
      "Epoch 38/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4905e-04 - val_loss: 7.4891e-04\n",
      "Epoch 39/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4891e-04 - val_loss: 7.4925e-04\n",
      "Epoch 40/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4925e-04 - val_loss: 7.4979e-04\n",
      "Epoch 41/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4979e-04 - val_loss: 7.5016e-04\n",
      "Epoch 42/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.5016e-04 - val_loss: 7.5017e-04\n",
      "Epoch 43/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.5017e-04 - val_loss: 7.4984e-04\n",
      "Epoch 44/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4984e-04 - val_loss: 7.4937e-04\n",
      "Epoch 45/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.4937e-04 - val_loss: 7.4899e-04\n",
      "Epoch 46/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.4899e-04 - val_loss: 7.4884e-04\n",
      "Epoch 47/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4884e-04 - val_loss: 7.4894e-04\n",
      "Epoch 48/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.4894e-04 - val_loss: 7.4916e-04\n",
      "Epoch 49/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4916e-04 - val_loss: 7.4935e-04\n",
      "Epoch 50/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 7.4935e-04 - val_loss: 7.4939e-04\n",
      "Epoch 51/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4939e-04 - val_loss: 7.4927e-04\n",
      "Epoch 52/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4927e-04 - val_loss: 7.4907e-04\n",
      "Epoch 53/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4907e-04 - val_loss: 7.4888e-04\n",
      "Epoch 54/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.4888e-04 - val_loss: 7.4879e-04\n",
      "Epoch 55/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4879e-04 - val_loss: 7.4882e-04\n",
      "Epoch 56/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.4882e-04 - val_loss: 7.4892e-04\n",
      "Epoch 57/900\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 7.4892e-04 - val_loss: 7.4900e-04\n",
      "Epoch 58/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4900e-04 - val_loss: 7.4902e-04\n",
      "Epoch 59/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4902e-04 - val_loss: 7.4896e-04\n",
      "Epoch 60/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4896e-04 - val_loss: 7.4886e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4886e-04 - val_loss: 7.4877e-04\n",
      "Epoch 62/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4877e-04 - val_loss: 7.4873e-04\n",
      "Epoch 63/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4873e-04 - val_loss: 7.4874e-04\n",
      "Epoch 64/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4874e-04 - val_loss: 7.4878e-04\n",
      "Epoch 65/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4878e-04 - val_loss: 7.4881e-04\n",
      "Epoch 66/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4881e-04 - val_loss: 7.4880e-04\n",
      "Epoch 67/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4880e-04 - val_loss: 7.4876e-04\n",
      "Epoch 68/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4876e-04 - val_loss: 7.4871e-04\n",
      "Epoch 69/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4871e-04 - val_loss: 7.4867e-04\n",
      "Epoch 70/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4867e-04 - val_loss: 7.4865e-04\n",
      "Epoch 71/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4865e-04 - val_loss: 7.4866e-04\n",
      "Epoch 72/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4866e-04 - val_loss: 7.4867e-04\n",
      "Epoch 73/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4867e-04 - val_loss: 7.4867e-04\n",
      "Epoch 74/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4867e-04 - val_loss: 7.4865e-04\n",
      "Epoch 75/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4865e-04 - val_loss: 7.4861e-04\n",
      "Epoch 76/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.4861e-04 - val_loss: 7.4858e-04\n",
      "Epoch 77/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4858e-04 - val_loss: 7.4856e-04\n",
      "Epoch 78/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4856e-04 - val_loss: 7.4855e-04\n",
      "Epoch 79/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4855e-04 - val_loss: 7.4855e-04\n",
      "Epoch 80/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4855e-04 - val_loss: 7.4854e-04\n",
      "Epoch 81/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4854e-04 - val_loss: 7.4853e-04\n",
      "Epoch 82/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4853e-04 - val_loss: 7.4850e-04\n",
      "Epoch 83/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4850e-04 - val_loss: 7.4847e-04\n",
      "Epoch 84/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4847e-04 - val_loss: 7.4845e-04\n",
      "Epoch 85/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4845e-04 - val_loss: 7.4844e-04\n",
      "Epoch 86/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4844e-04 - val_loss: 7.4842e-04\n",
      "Epoch 87/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4842e-04 - val_loss: 7.4841e-04\n",
      "Epoch 88/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4841e-04 - val_loss: 7.4839e-04\n",
      "Epoch 89/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4839e-04 - val_loss: 7.4836e-04\n",
      "Epoch 90/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4836e-04 - val_loss: 7.4833e-04\n",
      "Epoch 91/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4833e-04 - val_loss: 7.4831e-04\n",
      "Epoch 92/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4831e-04 - val_loss: 7.4829e-04\n",
      "Epoch 93/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4829e-04 - val_loss: 7.4827e-04\n",
      "Epoch 94/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4827e-04 - val_loss: 7.4824e-04\n",
      "Epoch 95/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4824e-04 - val_loss: 7.4821e-04\n",
      "Epoch 96/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4821e-04 - val_loss: 7.4818e-04\n",
      "Epoch 97/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.4818e-04 - val_loss: 7.4815e-04\n",
      "Epoch 98/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4815e-04 - val_loss: 7.4812e-04\n",
      "Epoch 99/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4812e-04 - val_loss: 7.4809e-04\n",
      "Epoch 100/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4809e-04 - val_loss: 7.4806e-04\n",
      "Epoch 101/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4806e-04 - val_loss: 7.4802e-04\n",
      "Epoch 102/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.4802e-04 - val_loss: 7.4799e-04\n",
      "Epoch 103/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4799e-04 - val_loss: 7.4795e-04\n",
      "Epoch 104/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4795e-04 - val_loss: 7.4791e-04\n",
      "Epoch 105/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4791e-04 - val_loss: 7.4787e-04\n",
      "Epoch 106/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4787e-04 - val_loss: 7.4782e-04\n",
      "Epoch 107/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4782e-04 - val_loss: 7.4778e-04\n",
      "Epoch 108/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4778e-04 - val_loss: 7.4773e-04\n",
      "Epoch 109/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4773e-04 - val_loss: 7.4768e-04\n",
      "Epoch 110/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4768e-04 - val_loss: 7.4762e-04\n",
      "Epoch 111/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4762e-04 - val_loss: 7.4757e-04\n",
      "Epoch 112/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4757e-04 - val_loss: 7.4751e-04\n",
      "Epoch 113/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4751e-04 - val_loss: 7.4745e-04\n",
      "Epoch 114/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4745e-04 - val_loss: 7.4738e-04\n",
      "Epoch 115/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4738e-04 - val_loss: 7.4731e-04\n",
      "Epoch 116/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4731e-04 - val_loss: 7.4724e-04\n",
      "Epoch 117/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4724e-04 - val_loss: 7.4716e-04\n",
      "Epoch 118/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4716e-04 - val_loss: 7.4708e-04\n",
      "Epoch 119/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4708e-04 - val_loss: 7.4699e-04\n",
      "Epoch 120/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4699e-04 - val_loss: 7.4690e-04\n",
      "Epoch 121/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4690e-04 - val_loss: 7.4680e-04\n",
      "Epoch 122/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4680e-04 - val_loss: 7.4670e-04\n",
      "Epoch 123/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4670e-04 - val_loss: 7.4659e-04\n",
      "Epoch 124/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4659e-04 - val_loss: 7.4647e-04\n",
      "Epoch 125/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4647e-04 - val_loss: 7.4635e-04\n",
      "Epoch 126/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4635e-04 - val_loss: 7.4621e-04\n",
      "Epoch 127/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4621e-04 - val_loss: 7.4607e-04\n",
      "Epoch 128/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4607e-04 - val_loss: 7.4592e-04\n",
      "Epoch 129/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4592e-04 - val_loss: 7.4576e-04\n",
      "Epoch 130/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4576e-04 - val_loss: 7.4559e-04\n",
      "Epoch 131/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4559e-04 - val_loss: 7.4541e-04\n",
      "Epoch 132/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4541e-04 - val_loss: 7.4522e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4522e-04 - val_loss: 7.4501e-04\n",
      "Epoch 134/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4501e-04 - val_loss: 7.4479e-04\n",
      "Epoch 135/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4479e-04 - val_loss: 7.4455e-04\n",
      "Epoch 136/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4455e-04 - val_loss: 7.4430e-04\n",
      "Epoch 137/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4430e-04 - val_loss: 7.4403e-04\n",
      "Epoch 138/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4403e-04 - val_loss: 7.4375e-04\n",
      "Epoch 139/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4375e-04 - val_loss: 7.4344e-04\n",
      "Epoch 140/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.4344e-04 - val_loss: 7.4311e-04\n",
      "Epoch 141/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4311e-04 - val_loss: 7.4277e-04\n",
      "Epoch 142/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4277e-04 - val_loss: 7.4240e-04\n",
      "Epoch 143/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4240e-04 - val_loss: 7.4201e-04\n",
      "Epoch 144/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4201e-04 - val_loss: 7.4160e-04\n",
      "Epoch 145/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4160e-04 - val_loss: 7.4117e-04\n",
      "Epoch 146/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.4117e-04 - val_loss: 7.4072e-04\n",
      "Epoch 147/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.4071e-04 - val_loss: 7.4025e-04\n",
      "Epoch 148/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.4025e-04 - val_loss: 7.3976e-04\n",
      "Epoch 149/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.3976e-04 - val_loss: 7.3927e-04\n",
      "Epoch 150/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3927e-04 - val_loss: 7.3877e-04\n",
      "Epoch 151/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3877e-04 - val_loss: 7.3828e-04\n",
      "Epoch 152/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3828e-04 - val_loss: 7.3780e-04\n",
      "Epoch 153/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3780e-04 - val_loss: 7.3734e-04\n",
      "Epoch 154/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3734e-04 - val_loss: 7.3692e-04\n",
      "Epoch 155/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3692e-04 - val_loss: 7.3654e-04\n",
      "Epoch 156/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3654e-04 - val_loss: 7.3623e-04\n",
      "Epoch 157/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3623e-04 - val_loss: 7.3598e-04\n",
      "Epoch 158/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3598e-04 - val_loss: 7.3580e-04\n",
      "Epoch 159/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3580e-04 - val_loss: 7.3569e-04\n",
      "Epoch 160/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3569e-04 - val_loss: 7.3566e-04\n",
      "Epoch 161/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.3566e-04 - val_loss: 7.3578e-04\n",
      "Epoch 162/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3578e-04 - val_loss: 7.3721e-04\n",
      "Epoch 163/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3721e-04 - val_loss: 7.4729e-04\n",
      "Epoch 164/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.4729e-04 - val_loss: 7.5673e-04\n",
      "Epoch 165/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.5673e-04 - val_loss: 7.3667e-04\n",
      "Epoch 166/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3667e-04 - val_loss: 7.4711e-04\n",
      "Epoch 167/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4711e-04 - val_loss: 7.3761e-04\n",
      "Epoch 168/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3761e-04 - val_loss: 7.4314e-04\n",
      "Epoch 169/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.4314e-04 - val_loss: 7.3564e-04\n",
      "Epoch 170/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3564e-04 - val_loss: 7.4189e-04\n",
      "Epoch 171/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.4189e-04 - val_loss: 7.3525e-04\n",
      "Epoch 172/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3525e-04 - val_loss: 7.3887e-04\n",
      "Epoch 173/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3887e-04 - val_loss: 7.3781e-04\n",
      "Epoch 174/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3781e-04 - val_loss: 7.3544e-04\n",
      "Epoch 175/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.3544e-04 - val_loss: 7.3841e-04\n",
      "Epoch 176/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3841e-04 - val_loss: 7.3638e-04\n",
      "Epoch 177/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3638e-04 - val_loss: 7.3564e-04\n",
      "Epoch 178/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3564e-04 - val_loss: 7.3743e-04\n",
      "Epoch 179/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3743e-04 - val_loss: 7.3582e-04\n",
      "Epoch 180/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3582e-04 - val_loss: 7.3531e-04\n",
      "Epoch 181/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3531e-04 - val_loss: 7.3648e-04\n",
      "Epoch 182/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3648e-04 - val_loss: 7.3524e-04\n",
      "Epoch 183/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.3524e-04 - val_loss: 7.3474e-04\n",
      "Epoch 184/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3474e-04 - val_loss: 7.3553e-04\n",
      "Epoch 185/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.3553e-04 - val_loss: 7.3450e-04\n",
      "Epoch 186/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3450e-04 - val_loss: 7.3412e-04\n",
      "Epoch 187/900\n",
      "650/650 [==============================] - 0s 96us/sample - loss: 7.3412e-04 - val_loss: 7.3463e-04\n",
      "Epoch 188/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3463e-04 - val_loss: 7.3369e-04\n",
      "Epoch 189/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3369e-04 - val_loss: 7.3360e-04\n",
      "Epoch 190/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3360e-04 - val_loss: 7.3383e-04\n",
      "Epoch 191/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3383e-04 - val_loss: 7.3301e-04\n",
      "Epoch 192/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3301e-04 - val_loss: 7.3326e-04\n",
      "Epoch 193/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3326e-04 - val_loss: 7.3309e-04\n",
      "Epoch 194/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 7.3309e-04 - val_loss: 7.3264e-04\n",
      "Epoch 195/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.3264e-04 - val_loss: 7.3297e-04\n",
      "Epoch 196/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.3297e-04 - val_loss: 7.3248e-04\n",
      "Epoch 197/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3248e-04 - val_loss: 7.3252e-04\n",
      "Epoch 198/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3252e-04 - val_loss: 7.3246e-04\n",
      "Epoch 199/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.3246e-04 - val_loss: 7.3210e-04\n",
      "Epoch 200/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3210e-04 - val_loss: 7.3224e-04\n",
      "Epoch 201/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3224e-04 - val_loss: 7.3186e-04\n",
      "Epoch 202/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.3186e-04 - val_loss: 7.3182e-04\n",
      "Epoch 203/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.3182e-04 - val_loss: 7.3168e-04\n",
      "Epoch 204/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3168e-04 - val_loss: 7.3140e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3140e-04 - val_loss: 7.3139e-04\n",
      "Epoch 206/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3139e-04 - val_loss: 7.3110e-04\n",
      "Epoch 207/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3110e-04 - val_loss: 7.3099e-04\n",
      "Epoch 208/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.3099e-04 - val_loss: 7.3087e-04\n",
      "Epoch 209/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.3087e-04 - val_loss: 7.3062e-04\n",
      "Epoch 210/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3062e-04 - val_loss: 7.3056e-04\n",
      "Epoch 211/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.3056e-04 - val_loss: 7.3035e-04\n",
      "Epoch 212/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.3035e-04 - val_loss: 7.3019e-04\n",
      "Epoch 213/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.3019e-04 - val_loss: 7.3007e-04\n",
      "Epoch 214/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.3007e-04 - val_loss: 7.2985e-04\n",
      "Epoch 215/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.2985e-04 - val_loss: 7.2972e-04\n",
      "Epoch 216/900\n",
      "650/650 [==============================] - 0s 93us/sample - loss: 7.2972e-04 - val_loss: 7.2954e-04\n",
      "Epoch 217/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2954e-04 - val_loss: 7.2933e-04\n",
      "Epoch 218/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2933e-04 - val_loss: 7.2919e-04\n",
      "Epoch 219/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.2919e-04 - val_loss: 7.2897e-04\n",
      "Epoch 220/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2897e-04 - val_loss: 7.2878e-04\n",
      "Epoch 221/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2878e-04 - val_loss: 7.2859e-04\n",
      "Epoch 222/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2859e-04 - val_loss: 7.2836e-04\n",
      "Epoch 223/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2836e-04 - val_loss: 7.2818e-04\n",
      "Epoch 224/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2818e-04 - val_loss: 7.2795e-04\n",
      "Epoch 225/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2795e-04 - val_loss: 7.2773e-04\n",
      "Epoch 226/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.2773e-04 - val_loss: 7.2752e-04\n",
      "Epoch 227/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2752e-04 - val_loss: 7.2728e-04\n",
      "Epoch 228/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2728e-04 - val_loss: 7.2706e-04\n",
      "Epoch 229/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.2706e-04 - val_loss: 7.2682e-04\n",
      "Epoch 230/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.2682e-04 - val_loss: 7.2657e-04\n",
      "Epoch 231/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.2657e-04 - val_loss: 7.2632e-04\n",
      "Epoch 232/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.2632e-04 - val_loss: 7.2605e-04\n",
      "Epoch 233/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2605e-04 - val_loss: 7.2580e-04\n",
      "Epoch 234/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.2580e-04 - val_loss: 7.2552e-04\n",
      "Epoch 235/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2552e-04 - val_loss: 7.2524e-04\n",
      "Epoch 236/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2524e-04 - val_loss: 7.2496e-04\n",
      "Epoch 237/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2496e-04 - val_loss: 7.2466e-04\n",
      "Epoch 238/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2466e-04 - val_loss: 7.2437e-04\n",
      "Epoch 239/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.2437e-04 - val_loss: 7.2406e-04\n",
      "Epoch 240/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2405e-04 - val_loss: 7.2374e-04\n",
      "Epoch 241/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2374e-04 - val_loss: 7.2342e-04\n",
      "Epoch 242/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2342e-04 - val_loss: 7.2309e-04\n",
      "Epoch 243/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2309e-04 - val_loss: 7.2276e-04\n",
      "Epoch 244/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 7.2276e-04 - val_loss: 7.2241e-04\n",
      "Epoch 245/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2241e-04 - val_loss: 7.2206e-04\n",
      "Epoch 246/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2206e-04 - val_loss: 7.2171e-04\n",
      "Epoch 247/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.2171e-04 - val_loss: 7.2134e-04\n",
      "Epoch 248/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.2134e-04 - val_loss: 7.2098e-04\n",
      "Epoch 249/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2098e-04 - val_loss: 7.2060e-04\n",
      "Epoch 250/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2060e-04 - val_loss: 7.2023e-04\n",
      "Epoch 251/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.2023e-04 - val_loss: 7.1985e-04\n",
      "Epoch 252/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1985e-04 - val_loss: 7.1948e-04\n",
      "Epoch 253/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1948e-04 - val_loss: 7.1911e-04\n",
      "Epoch 254/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1911e-04 - val_loss: 7.1874e-04\n",
      "Epoch 255/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1874e-04 - val_loss: 7.1837e-04\n",
      "Epoch 256/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1837e-04 - val_loss: 7.1802e-04\n",
      "Epoch 257/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.1802e-04 - val_loss: 7.1768e-04\n",
      "Epoch 258/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1768e-04 - val_loss: 7.1735e-04\n",
      "Epoch 259/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.1735e-04 - val_loss: 7.1704e-04\n",
      "Epoch 260/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1704e-04 - val_loss: 7.1675e-04\n",
      "Epoch 261/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 7.1675e-04 - val_loss: 7.1648e-04\n",
      "Epoch 262/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1648e-04 - val_loss: 7.1624e-04\n",
      "Epoch 263/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1624e-04 - val_loss: 7.1603e-04\n",
      "Epoch 264/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.1603e-04 - val_loss: 7.1585e-04\n",
      "Epoch 265/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1585e-04 - val_loss: 7.1570e-04\n",
      "Epoch 266/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1570e-04 - val_loss: 7.1557e-04\n",
      "Epoch 267/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1557e-04 - val_loss: 7.1548e-04\n",
      "Epoch 268/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1548e-04 - val_loss: 7.1542e-04\n",
      "Epoch 269/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1542e-04 - val_loss: 7.1539e-04\n",
      "Epoch 270/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1539e-04 - val_loss: 7.1537e-04\n",
      "Epoch 271/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1537e-04 - val_loss: 7.1538e-04\n",
      "Epoch 272/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1538e-04 - val_loss: 7.1540e-04\n",
      "Epoch 273/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1540e-04 - val_loss: 7.1542e-04\n",
      "Epoch 274/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1542e-04 - val_loss: 7.1546e-04\n",
      "Epoch 275/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1546e-04 - val_loss: 7.1549e-04\n",
      "Epoch 276/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1549e-04 - val_loss: 7.1551e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1551e-04 - val_loss: 7.1553e-04\n",
      "Epoch 278/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1553e-04 - val_loss: 7.1555e-04\n",
      "Epoch 279/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1555e-04 - val_loss: 7.1555e-04\n",
      "Epoch 280/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1555e-04 - val_loss: 7.1555e-04\n",
      "Epoch 281/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1555e-04 - val_loss: 7.1554e-04\n",
      "Epoch 282/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1554e-04 - val_loss: 7.1552e-04\n",
      "Epoch 283/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1552e-04 - val_loss: 7.1550e-04\n",
      "Epoch 284/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1550e-04 - val_loss: 7.1547e-04\n",
      "Epoch 285/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1547e-04 - val_loss: 7.1545e-04\n",
      "Epoch 286/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1545e-04 - val_loss: 7.1542e-04\n",
      "Epoch 287/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1542e-04 - val_loss: 7.1540e-04\n",
      "Epoch 288/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1540e-04 - val_loss: 7.1538e-04\n",
      "Epoch 289/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1538e-04 - val_loss: 7.1536e-04\n",
      "Epoch 290/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1536e-04 - val_loss: 7.1534e-04\n",
      "Epoch 291/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1534e-04 - val_loss: 7.1533e-04\n",
      "Epoch 292/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1533e-04 - val_loss: 7.1532e-04\n",
      "Epoch 293/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1532e-04 - val_loss: 7.1531e-04\n",
      "Epoch 294/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1531e-04 - val_loss: 7.1531e-04\n",
      "Epoch 295/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1531e-04 - val_loss: 7.1531e-04\n",
      "Epoch 296/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1531e-04 - val_loss: 7.1530e-04\n",
      "Epoch 297/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 298/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 299/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 300/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 301/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 302/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 303/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 304/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 305/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1530e-04 - val_loss: 7.1530e-04\n",
      "Epoch 306/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1530e-04 - val_loss: 7.1529e-04\n",
      "Epoch 307/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1529e-04 - val_loss: 7.1529e-04\n",
      "Epoch 308/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1529e-04 - val_loss: 7.1529e-04\n",
      "Epoch 309/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1529e-04 - val_loss: 7.1528e-04\n",
      "Epoch 310/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1528e-04 - val_loss: 7.1528e-04\n",
      "Epoch 311/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1528e-04 - val_loss: 7.1528e-04\n",
      "Epoch 312/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1528e-04 - val_loss: 7.1527e-04\n",
      "Epoch 313/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 7.1527e-04 - val_loss: 7.1527e-04\n",
      "Epoch 314/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1527e-04 - val_loss: 7.1526e-04\n",
      "Epoch 315/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1526e-04 - val_loss: 7.1526e-04\n",
      "Epoch 316/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1526e-04 - val_loss: 7.1526e-04\n",
      "Epoch 317/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1526e-04 - val_loss: 7.1525e-04\n",
      "Epoch 318/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 7.1525e-04 - val_loss: 7.1525e-04\n",
      "Epoch 319/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1525e-04 - val_loss: 7.1525e-04\n",
      "Epoch 320/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1525e-04 - val_loss: 7.1525e-04\n",
      "Epoch 321/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 7.1525e-04 - val_loss: 7.1524e-04\n",
      "Epoch 322/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1524e-04 - val_loss: 7.1524e-04\n",
      "Epoch 323/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 7.1524e-04 - val_loss: 7.1524e-04\n",
      "Epoch 324/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1524e-04 - val_loss: 7.1524e-04\n",
      "Epoch 325/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 7.1524e-04 - val_loss: 7.1523e-04\n",
      "Epoch 326/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 7.1523e-04 - val_loss: 7.1523e-04\n",
      "Epoch 327/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1523e-04 - val_loss: 7.1523e-04\n",
      "Epoch 328/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1523e-04 - val_loss: 7.1523e-04\n",
      "Epoch 329/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.1523e-04 - val_loss: 7.1522e-04\n",
      "Epoch 330/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 331/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 332/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 333/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1522e-04 - val_loss: 7.1522e-04\n",
      "Epoch 334/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 7.1522e-04 - val_loss: 7.1521e-04\n",
      "Epoch 335/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 7.1521e-04 - val_loss: 7.1521e-04\n",
      "Epoch 336/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 7.1521e-04 - val_loss: 7.1521e-04\n",
      "Epoch 337/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 7.1521e-04 - val_loss: 7.1521e-04\n",
      "Epoch 338/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 7.1521e-04 - val_loss: 7.1520e-04\n",
      "Epoch 339/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1520e-04 - val_loss: 7.1520e-04\n",
      "Epoch 340/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 7.1520e-04 - val_loss: 7.1520e-04\n",
      "Epoch 341/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1520e-04 - val_loss: 7.1520e-04\n",
      "Epoch 342/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 7.1520e-04 - val_loss: 7.1519e-04\n",
      "Epoch 343/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1519e-04 - val_loss: 7.1519e-04\n",
      "Epoch 344/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1519e-04 - val_loss: 7.1519e-04\n",
      "Epoch 345/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1519e-04 - val_loss: 7.1519e-04\n",
      "Epoch 346/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 7.1519e-04 - val_loss: 7.1518e-04\n",
      "Epoch 347/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 7.1518e-04 - val_loss: 7.1518e-04\n",
      "Epoch 348/900\n",
      "650/650 [==============================] - 0s 94us/sample - loss: 7.1518e-04 - val_loss: 7.1518e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 7.1518e-04 - val_loss: 7.1518e-04\n",
      "Epoch 350/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1518e-04 - val_loss: 7.1517e-04\n",
      "Epoch 351/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1517e-04 - val_loss: 7.1517e-04\n",
      "Epoch 352/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1517e-04 - val_loss: 7.1517e-04\n",
      "Epoch 353/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 7.1517e-04 - val_loss: 7.1517e-04\n",
      "Epoch 354/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1517e-04 - val_loss: 7.1516e-04\n",
      "Epoch 355/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1516e-04 - val_loss: 7.1516e-04\n",
      "Epoch 356/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 7.1516e-04 - val_loss: 7.1516e-04\n",
      "Epoch 357/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1516e-04 - val_loss: 7.1516e-04\n",
      "Epoch 358/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 7.1516e-04 - val_loss: 7.1515e-04\n",
      "Epoch 359/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1515e-04 - val_loss: 7.1515e-04\n",
      "Epoch 360/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1515e-04 - val_loss: 7.1515e-04\n",
      "Epoch 361/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1515e-04 - val_loss: 7.1515e-04\n",
      "Epoch 362/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1515e-04 - val_loss: 7.1514e-04\n",
      "Epoch 363/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1514e-04 - val_loss: 7.1514e-04\n",
      "Epoch 364/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1514e-04 - val_loss: 7.1514e-04\n",
      "Epoch 365/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1514e-04 - val_loss: 7.1514e-04\n",
      "Epoch 366/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1514e-04 - val_loss: 7.1513e-04\n",
      "Epoch 367/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1513e-04 - val_loss: 7.1513e-04\n",
      "Epoch 368/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1513e-04 - val_loss: 7.1513e-04\n",
      "Epoch 369/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1513e-04 - val_loss: 7.1513e-04\n",
      "Epoch 370/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1513e-04 - val_loss: 7.1512e-04\n",
      "Epoch 371/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1512e-04 - val_loss: 7.1512e-04\n",
      "Epoch 372/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1512e-04 - val_loss: 7.1512e-04\n",
      "Epoch 373/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1512e-04 - val_loss: 7.1512e-04\n",
      "Epoch 374/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1512e-04 - val_loss: 7.1511e-04\n",
      "Epoch 375/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1511e-04\n",
      "Epoch 376/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1511e-04\n",
      "Epoch 377/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1511e-04\n",
      "Epoch 378/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1511e-04 - val_loss: 7.1510e-04\n",
      "Epoch 379/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 380/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 381/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 382/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1510e-04 - val_loss: 7.1510e-04\n",
      "Epoch 383/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 384/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 385/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 386/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1509e-04 - val_loss: 7.1509e-04\n",
      "Epoch 387/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 7.1509e-04 - val_loss: 7.1508e-04\n",
      "Epoch 388/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 7.1508e-04 - val_loss: 7.1508e-04\n",
      "Epoch 389/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1508e-04 - val_loss: 7.1508e-04\n",
      "Epoch 390/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 7.1508e-04 - val_loss: 7.1508e-04\n",
      "Epoch 391/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1508e-04 - val_loss: 7.1507e-04\n",
      "Epoch 392/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1507e-04 - val_loss: 7.1507e-04\n",
      "Epoch 393/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1507e-04 - val_loss: 7.1507e-04\n",
      "Epoch 394/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1507e-04 - val_loss: 7.1507e-04\n",
      "Epoch 395/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 7.1507e-04 - val_loss: 7.1506e-04\n",
      "Epoch 396/900\n",
      "650/650 [==============================] - 0s 134us/sample - loss: 7.1506e-04 - val_loss: 7.1506e-04\n",
      "Epoch 397/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1506e-04 - val_loss: 7.1506e-04\n",
      "Epoch 398/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1506e-04 - val_loss: 7.1506e-04\n",
      "Epoch 399/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1506e-04 - val_loss: 7.1505e-04\n",
      "Epoch 400/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1505e-04 - val_loss: 7.1505e-04\n",
      "Epoch 401/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1505e-04 - val_loss: 7.1505e-04\n",
      "Epoch 402/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1505e-04 - val_loss: 7.1505e-04\n",
      "Epoch 403/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1505e-04 - val_loss: 7.1504e-04\n",
      "Epoch 404/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1504e-04 - val_loss: 7.1504e-04\n",
      "Epoch 405/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1504e-04 - val_loss: 7.1504e-04\n",
      "Epoch 406/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1504e-04 - val_loss: 7.1504e-04\n",
      "Epoch 407/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1504e-04 - val_loss: 7.1503e-04\n",
      "Epoch 408/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1503e-04 - val_loss: 7.1503e-04\n",
      "Epoch 409/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1503e-04 - val_loss: 7.1503e-04\n",
      "Epoch 410/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1503e-04 - val_loss: 7.1503e-04\n",
      "Epoch 411/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1503e-04 - val_loss: 7.1502e-04\n",
      "Epoch 412/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1502e-04 - val_loss: 7.1502e-04\n",
      "Epoch 413/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1502e-04 - val_loss: 7.1502e-04\n",
      "Epoch 414/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1502e-04 - val_loss: 7.1501e-04\n",
      "Epoch 415/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1502e-04 - val_loss: 7.1501e-04\n",
      "Epoch 416/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1501e-04 - val_loss: 7.1501e-04\n",
      "Epoch 417/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1501e-04 - val_loss: 7.1501e-04\n",
      "Epoch 418/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1501e-04 - val_loss: 7.1500e-04\n",
      "Epoch 419/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1500e-04 - val_loss: 7.1500e-04\n",
      "Epoch 420/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1500e-04 - val_loss: 7.1500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1500e-04 - val_loss: 7.1500e-04\n",
      "Epoch 422/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1500e-04 - val_loss: 7.1499e-04\n",
      "Epoch 423/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1499e-04 - val_loss: 7.1499e-04\n",
      "Epoch 424/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1499e-04 - val_loss: 7.1499e-04\n",
      "Epoch 425/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1499e-04 - val_loss: 7.1499e-04\n",
      "Epoch 426/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1499e-04 - val_loss: 7.1498e-04\n",
      "Epoch 427/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1498e-04 - val_loss: 7.1498e-04\n",
      "Epoch 428/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1498e-04 - val_loss: 7.1498e-04\n",
      "Epoch 429/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1498e-04 - val_loss: 7.1498e-04\n",
      "Epoch 430/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1498e-04 - val_loss: 7.1497e-04\n",
      "Epoch 431/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1497e-04 - val_loss: 7.1497e-04\n",
      "Epoch 432/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1497e-04 - val_loss: 7.1497e-04\n",
      "Epoch 433/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1497e-04 - val_loss: 7.1497e-04\n",
      "Epoch 434/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1497e-04 - val_loss: 7.1496e-04\n",
      "Epoch 435/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1496e-04 - val_loss: 7.1496e-04\n",
      "Epoch 436/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1496e-04 - val_loss: 7.1496e-04\n",
      "Epoch 437/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1496e-04 - val_loss: 7.1496e-04\n",
      "Epoch 438/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1496e-04 - val_loss: 7.1495e-04\n",
      "Epoch 439/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1495e-04 - val_loss: 7.1495e-04\n",
      "Epoch 440/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1495e-04 - val_loss: 7.1495e-04\n",
      "Epoch 441/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1495e-04 - val_loss: 7.1495e-04\n",
      "Epoch 442/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1495e-04 - val_loss: 7.1494e-04\n",
      "Epoch 443/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1494e-04 - val_loss: 7.1494e-04\n",
      "Epoch 444/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1494e-04 - val_loss: 7.1494e-04\n",
      "Epoch 445/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1494e-04 - val_loss: 7.1494e-04\n",
      "Epoch 446/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1494e-04 - val_loss: 7.1493e-04\n",
      "Epoch 447/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1493e-04 - val_loss: 7.1493e-04\n",
      "Epoch 448/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1493e-04 - val_loss: 7.1493e-04\n",
      "Epoch 449/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1493e-04 - val_loss: 7.1492e-04\n",
      "Epoch 450/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1492e-04 - val_loss: 7.1492e-04\n",
      "Epoch 451/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1492e-04 - val_loss: 7.1492e-04\n",
      "Epoch 452/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1492e-04 - val_loss: 7.1492e-04\n",
      "Epoch 453/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1492e-04 - val_loss: 7.1491e-04\n",
      "Epoch 454/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1491e-04 - val_loss: 7.1491e-04\n",
      "Epoch 455/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1491e-04 - val_loss: 7.1491e-04\n",
      "Epoch 456/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1491e-04 - val_loss: 7.1491e-04\n",
      "Epoch 457/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1491e-04 - val_loss: 7.1490e-04\n",
      "Epoch 458/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1490e-04 - val_loss: 7.1490e-04\n",
      "Epoch 459/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1490e-04 - val_loss: 7.1490e-04\n",
      "Epoch 460/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1490e-04 - val_loss: 7.1490e-04\n",
      "Epoch 461/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1490e-04 - val_loss: 7.1489e-04\n",
      "Epoch 462/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1489e-04 - val_loss: 7.1489e-04\n",
      "Epoch 463/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1489e-04 - val_loss: 7.1489e-04\n",
      "Epoch 464/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1489e-04 - val_loss: 7.1488e-04\n",
      "Epoch 465/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1488e-04 - val_loss: 7.1488e-04\n",
      "Epoch 466/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1488e-04 - val_loss: 7.1488e-04\n",
      "Epoch 467/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1488e-04 - val_loss: 7.1488e-04\n",
      "Epoch 468/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1488e-04 - val_loss: 7.1487e-04\n",
      "Epoch 469/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1487e-04 - val_loss: 7.1487e-04\n",
      "Epoch 470/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1487e-04 - val_loss: 7.1487e-04\n",
      "Epoch 471/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1487e-04 - val_loss: 7.1487e-04\n",
      "Epoch 472/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1487e-04 - val_loss: 7.1486e-04\n",
      "Epoch 473/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1486e-04 - val_loss: 7.1486e-04\n",
      "Epoch 474/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1486e-04 - val_loss: 7.1486e-04\n",
      "Epoch 475/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1486e-04 - val_loss: 7.1485e-04\n",
      "Epoch 476/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1485e-04 - val_loss: 7.1485e-04\n",
      "Epoch 477/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1485e-04 - val_loss: 7.1485e-04\n",
      "Epoch 478/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1485e-04 - val_loss: 7.1485e-04\n",
      "Epoch 479/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1485e-04 - val_loss: 7.1484e-04\n",
      "Epoch 480/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1484e-04 - val_loss: 7.1484e-04\n",
      "Epoch 481/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1484e-04 - val_loss: 7.1484e-04\n",
      "Epoch 482/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1484e-04 - val_loss: 7.1484e-04\n",
      "Epoch 483/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1484e-04 - val_loss: 7.1483e-04\n",
      "Epoch 484/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1483e-04 - val_loss: 7.1483e-04\n",
      "Epoch 485/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1483e-04 - val_loss: 7.1483e-04\n",
      "Epoch 486/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1483e-04 - val_loss: 7.1482e-04\n",
      "Epoch 487/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1482e-04 - val_loss: 7.1482e-04\n",
      "Epoch 488/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1482e-04 - val_loss: 7.1482e-04\n",
      "Epoch 489/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1482e-04 - val_loss: 7.1482e-04\n",
      "Epoch 490/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1482e-04 - val_loss: 7.1481e-04\n",
      "Epoch 491/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1481e-04 - val_loss: 7.1481e-04\n",
      "Epoch 492/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1481e-04 - val_loss: 7.1481e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1481e-04 - val_loss: 7.1480e-04\n",
      "Epoch 494/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1480e-04 - val_loss: 7.1480e-04\n",
      "Epoch 495/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1480e-04 - val_loss: 7.1480e-04\n",
      "Epoch 496/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1480e-04 - val_loss: 7.1480e-04\n",
      "Epoch 497/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1480e-04 - val_loss: 7.1479e-04\n",
      "Epoch 498/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1479e-04 - val_loss: 7.1479e-04\n",
      "Epoch 499/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1479e-04 - val_loss: 7.1479e-04\n",
      "Epoch 500/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1479e-04 - val_loss: 7.1478e-04\n",
      "Epoch 501/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1478e-04 - val_loss: 7.1478e-04\n",
      "Epoch 502/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1478e-04 - val_loss: 7.1478e-04\n",
      "Epoch 503/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1478e-04 - val_loss: 7.1478e-04\n",
      "Epoch 504/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1478e-04 - val_loss: 7.1477e-04\n",
      "Epoch 505/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1477e-04 - val_loss: 7.1477e-04\n",
      "Epoch 506/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1477e-04 - val_loss: 7.1477e-04\n",
      "Epoch 507/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1477e-04 - val_loss: 7.1476e-04\n",
      "Epoch 508/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1476e-04 - val_loss: 7.1476e-04\n",
      "Epoch 509/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1476e-04 - val_loss: 7.1476e-04\n",
      "Epoch 510/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1476e-04 - val_loss: 7.1476e-04\n",
      "Epoch 511/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1476e-04 - val_loss: 7.1475e-04\n",
      "Epoch 512/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1475e-04 - val_loss: 7.1475e-04\n",
      "Epoch 513/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1475e-04 - val_loss: 7.1475e-04\n",
      "Epoch 514/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1475e-04 - val_loss: 7.1474e-04\n",
      "Epoch 515/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1474e-04 - val_loss: 7.1474e-04\n",
      "Epoch 516/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1474e-04 - val_loss: 7.1474e-04\n",
      "Epoch 517/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1474e-04 - val_loss: 7.1474e-04\n",
      "Epoch 518/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1474e-04 - val_loss: 7.1473e-04\n",
      "Epoch 519/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1473e-04 - val_loss: 7.1473e-04\n",
      "Epoch 520/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1473e-04 - val_loss: 7.1473e-04\n",
      "Epoch 521/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1473e-04 - val_loss: 7.1472e-04\n",
      "Epoch 522/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1472e-04 - val_loss: 7.1472e-04\n",
      "Epoch 523/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1472e-04 - val_loss: 7.1472e-04\n",
      "Epoch 524/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1472e-04 - val_loss: 7.1471e-04\n",
      "Epoch 525/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1471e-04 - val_loss: 7.1471e-04\n",
      "Epoch 526/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1471e-04 - val_loss: 7.1471e-04\n",
      "Epoch 527/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1471e-04 - val_loss: 7.1471e-04\n",
      "Epoch 528/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1471e-04 - val_loss: 7.1470e-04\n",
      "Epoch 529/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1470e-04 - val_loss: 7.1470e-04\n",
      "Epoch 530/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1470e-04 - val_loss: 7.1470e-04\n",
      "Epoch 531/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1470e-04 - val_loss: 7.1469e-04\n",
      "Epoch 532/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1469e-04 - val_loss: 7.1469e-04\n",
      "Epoch 533/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1469e-04 - val_loss: 7.1469e-04\n",
      "Epoch 534/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1469e-04 - val_loss: 7.1468e-04\n",
      "Epoch 535/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1468e-04 - val_loss: 7.1468e-04\n",
      "Epoch 536/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1468e-04 - val_loss: 7.1468e-04\n",
      "Epoch 537/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1468e-04 - val_loss: 7.1467e-04\n",
      "Epoch 538/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1467e-04 - val_loss: 7.1467e-04\n",
      "Epoch 539/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1467e-04 - val_loss: 7.1467e-04\n",
      "Epoch 540/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1467e-04 - val_loss: 7.1467e-04\n",
      "Epoch 541/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1467e-04 - val_loss: 7.1466e-04\n",
      "Epoch 542/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1466e-04 - val_loss: 7.1466e-04\n",
      "Epoch 543/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1466e-04 - val_loss: 7.1466e-04\n",
      "Epoch 544/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1466e-04 - val_loss: 7.1465e-04\n",
      "Epoch 545/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1465e-04 - val_loss: 7.1465e-04\n",
      "Epoch 546/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1465e-04 - val_loss: 7.1465e-04\n",
      "Epoch 547/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1465e-04 - val_loss: 7.1464e-04\n",
      "Epoch 548/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1464e-04 - val_loss: 7.1464e-04\n",
      "Epoch 549/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1464e-04 - val_loss: 7.1464e-04\n",
      "Epoch 550/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1464e-04 - val_loss: 7.1463e-04\n",
      "Epoch 551/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1463e-04 - val_loss: 7.1463e-04\n",
      "Epoch 552/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1463e-04 - val_loss: 7.1463e-04\n",
      "Epoch 553/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1463e-04 - val_loss: 7.1462e-04\n",
      "Epoch 554/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1462e-04 - val_loss: 7.1462e-04\n",
      "Epoch 555/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1462e-04 - val_loss: 7.1462e-04\n",
      "Epoch 556/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1462e-04 - val_loss: 7.1461e-04\n",
      "Epoch 557/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1461e-04 - val_loss: 7.1461e-04\n",
      "Epoch 558/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 7.1461e-04 - val_loss: 7.1461e-04\n",
      "Epoch 559/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 7.1461e-04 - val_loss: 7.1460e-04\n",
      "Epoch 560/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 7.1460e-04 - val_loss: 7.1460e-04\n",
      "Epoch 561/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 7.1460e-04 - val_loss: 7.1460e-04\n",
      "Epoch 562/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 7.1460e-04 - val_loss: 7.1459e-04\n",
      "Epoch 563/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 7.1459e-04 - val_loss: 7.1459e-04\n",
      "Epoch 564/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1459e-04 - val_loss: 7.1459e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1459e-04 - val_loss: 7.1458e-04\n",
      "Epoch 566/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1458e-04 - val_loss: 7.1458e-04\n",
      "Epoch 567/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1458e-04 - val_loss: 7.1458e-04\n",
      "Epoch 568/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1458e-04 - val_loss: 7.1457e-04\n",
      "Epoch 569/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1457e-04 - val_loss: 7.1457e-04\n",
      "Epoch 570/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1457e-04 - val_loss: 7.1457e-04\n",
      "Epoch 571/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1457e-04 - val_loss: 7.1456e-04\n",
      "Epoch 572/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1456e-04 - val_loss: 7.1456e-04\n",
      "Epoch 573/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1456e-04 - val_loss: 7.1456e-04\n",
      "Epoch 574/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1456e-04 - val_loss: 7.1455e-04\n",
      "Epoch 575/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1455e-04 - val_loss: 7.1455e-04\n",
      "Epoch 576/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1455e-04 - val_loss: 7.1455e-04\n",
      "Epoch 577/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1455e-04 - val_loss: 7.1454e-04\n",
      "Epoch 578/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1454e-04 - val_loss: 7.1454e-04\n",
      "Epoch 579/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1454e-04 - val_loss: 7.1454e-04\n",
      "Epoch 580/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1454e-04 - val_loss: 7.1453e-04\n",
      "Epoch 581/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1453e-04 - val_loss: 7.1453e-04\n",
      "Epoch 582/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1453e-04 - val_loss: 7.1453e-04\n",
      "Epoch 583/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1453e-04 - val_loss: 7.1452e-04\n",
      "Epoch 584/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1452e-04 - val_loss: 7.1452e-04\n",
      "Epoch 585/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1452e-04 - val_loss: 7.1451e-04\n",
      "Epoch 586/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1451e-04 - val_loss: 7.1451e-04\n",
      "Epoch 587/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1451e-04 - val_loss: 7.1451e-04\n",
      "Epoch 588/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 7.1451e-04 - val_loss: 7.1450e-04\n",
      "Epoch 589/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 7.1450e-04 - val_loss: 7.1450e-04\n",
      "Epoch 590/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1450e-04 - val_loss: 7.1450e-04\n",
      "Epoch 591/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 7.1450e-04 - val_loss: 7.1449e-04\n",
      "Epoch 592/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1449e-04 - val_loss: 7.1449e-04\n",
      "Epoch 593/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1449e-04 - val_loss: 7.1449e-04\n",
      "Epoch 594/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1449e-04 - val_loss: 7.1448e-04\n",
      "Epoch 595/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1448e-04 - val_loss: 7.1448e-04\n",
      "Epoch 596/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1448e-04 - val_loss: 7.1447e-04\n",
      "Epoch 597/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1447e-04 - val_loss: 7.1447e-04\n",
      "Epoch 598/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1447e-04 - val_loss: 7.1447e-04\n",
      "Epoch 599/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1447e-04 - val_loss: 7.1446e-04\n",
      "Epoch 600/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1446e-04 - val_loss: 7.1446e-04\n",
      "Epoch 601/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1446e-04 - val_loss: 7.1446e-04\n",
      "Epoch 602/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1446e-04 - val_loss: 7.1445e-04\n",
      "Epoch 603/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1445e-04 - val_loss: 7.1445e-04\n",
      "Epoch 604/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1445e-04 - val_loss: 7.1444e-04\n",
      "Epoch 605/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 7.1444e-04 - val_loss: 7.1444e-04\n",
      "Epoch 606/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1444e-04 - val_loss: 7.1444e-04\n",
      "Epoch 607/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1444e-04 - val_loss: 7.1443e-04\n",
      "Epoch 608/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1443e-04 - val_loss: 7.1443e-04\n",
      "Epoch 609/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1443e-04 - val_loss: 7.1443e-04\n",
      "Epoch 610/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1443e-04 - val_loss: 7.1442e-04\n",
      "Epoch 611/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1442e-04 - val_loss: 7.1442e-04\n",
      "Epoch 612/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1442e-04 - val_loss: 7.1441e-04\n",
      "Epoch 613/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1441e-04 - val_loss: 7.1441e-04\n",
      "Epoch 614/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1441e-04 - val_loss: 7.1441e-04\n",
      "Epoch 615/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1441e-04 - val_loss: 7.1440e-04\n",
      "Epoch 616/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1440e-04 - val_loss: 7.1440e-04\n",
      "Epoch 617/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.1440e-04 - val_loss: 7.1439e-04\n",
      "Epoch 618/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1439e-04 - val_loss: 7.1439e-04\n",
      "Epoch 619/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1439e-04 - val_loss: 7.1439e-04\n",
      "Epoch 620/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1439e-04 - val_loss: 7.1438e-04\n",
      "Epoch 621/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1438e-04 - val_loss: 7.1438e-04\n",
      "Epoch 622/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1438e-04 - val_loss: 7.1437e-04\n",
      "Epoch 623/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1437e-04 - val_loss: 7.1437e-04\n",
      "Epoch 624/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1437e-04 - val_loss: 7.1436e-04\n",
      "Epoch 625/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1436e-04 - val_loss: 7.1436e-04\n",
      "Epoch 626/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1436e-04 - val_loss: 7.1436e-04\n",
      "Epoch 627/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1436e-04 - val_loss: 7.1435e-04\n",
      "Epoch 628/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1435e-04 - val_loss: 7.1435e-04\n",
      "Epoch 629/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1435e-04 - val_loss: 7.1434e-04\n",
      "Epoch 630/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1434e-04 - val_loss: 7.1434e-04\n",
      "Epoch 631/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1434e-04 - val_loss: 7.1434e-04\n",
      "Epoch 632/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1434e-04 - val_loss: 7.1433e-04\n",
      "Epoch 633/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1433e-04 - val_loss: 7.1433e-04\n",
      "Epoch 634/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1433e-04 - val_loss: 7.1432e-04\n",
      "Epoch 635/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1432e-04 - val_loss: 7.1432e-04\n",
      "Epoch 636/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1432e-04 - val_loss: 7.1431e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 637/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1431e-04 - val_loss: 7.1431e-04\n",
      "Epoch 638/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1431e-04 - val_loss: 7.1431e-04\n",
      "Epoch 639/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1431e-04 - val_loss: 7.1430e-04\n",
      "Epoch 640/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1430e-04 - val_loss: 7.1430e-04\n",
      "Epoch 641/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1430e-04 - val_loss: 7.1429e-04\n",
      "Epoch 642/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1429e-04 - val_loss: 7.1429e-04\n",
      "Epoch 643/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1429e-04 - val_loss: 7.1428e-04\n",
      "Epoch 644/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1428e-04 - val_loss: 7.1428e-04\n",
      "Epoch 645/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1428e-04 - val_loss: 7.1427e-04\n",
      "Epoch 646/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1427e-04 - val_loss: 7.1427e-04\n",
      "Epoch 647/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1427e-04 - val_loss: 7.1426e-04\n",
      "Epoch 648/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1426e-04 - val_loss: 7.1426e-04\n",
      "Epoch 649/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1426e-04 - val_loss: 7.1426e-04\n",
      "Epoch 650/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1426e-04 - val_loss: 7.1425e-04\n",
      "Epoch 651/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1425e-04 - val_loss: 7.1425e-04\n",
      "Epoch 652/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1425e-04 - val_loss: 7.1424e-04\n",
      "Epoch 653/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1424e-04 - val_loss: 7.1424e-04\n",
      "Epoch 654/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1424e-04 - val_loss: 7.1423e-04\n",
      "Epoch 655/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 7.1423e-04 - val_loss: 7.1423e-04\n",
      "Epoch 656/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1423e-04 - val_loss: 7.1422e-04\n",
      "Epoch 657/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 7.1422e-04 - val_loss: 7.1422e-04\n",
      "Epoch 658/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1422e-04 - val_loss: 7.1421e-04\n",
      "Epoch 659/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1421e-04 - val_loss: 7.1421e-04\n",
      "Epoch 660/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1421e-04 - val_loss: 7.1420e-04\n",
      "Epoch 661/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1420e-04 - val_loss: 7.1420e-04\n",
      "Epoch 662/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.1420e-04 - val_loss: 7.1419e-04\n",
      "Epoch 663/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1419e-04 - val_loss: 7.1419e-04\n",
      "Epoch 664/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1419e-04 - val_loss: 7.1418e-04\n",
      "Epoch 665/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1418e-04 - val_loss: 7.1418e-04\n",
      "Epoch 666/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1418e-04 - val_loss: 7.1417e-04\n",
      "Epoch 667/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1417e-04 - val_loss: 7.1417e-04\n",
      "Epoch 668/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1417e-04 - val_loss: 7.1416e-04\n",
      "Epoch 669/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1416e-04 - val_loss: 7.1416e-04\n",
      "Epoch 670/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1416e-04 - val_loss: 7.1415e-04\n",
      "Epoch 671/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1415e-04 - val_loss: 7.1415e-04\n",
      "Epoch 672/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1415e-04 - val_loss: 7.1414e-04\n",
      "Epoch 673/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1414e-04 - val_loss: 7.1414e-04\n",
      "Epoch 674/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1414e-04 - val_loss: 7.1413e-04\n",
      "Epoch 675/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1413e-04 - val_loss: 7.1413e-04\n",
      "Epoch 676/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1413e-04 - val_loss: 7.1412e-04\n",
      "Epoch 677/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1412e-04 - val_loss: 7.1412e-04\n",
      "Epoch 678/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1412e-04 - val_loss: 7.1411e-04\n",
      "Epoch 679/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1411e-04 - val_loss: 7.1411e-04\n",
      "Epoch 680/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1411e-04 - val_loss: 7.1410e-04\n",
      "Epoch 681/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1410e-04 - val_loss: 7.1409e-04\n",
      "Epoch 682/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1409e-04 - val_loss: 7.1409e-04\n",
      "Epoch 683/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1409e-04 - val_loss: 7.1408e-04\n",
      "Epoch 684/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1408e-04 - val_loss: 7.1408e-04\n",
      "Epoch 685/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1408e-04 - val_loss: 7.1407e-04\n",
      "Epoch 686/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1407e-04 - val_loss: 7.1407e-04\n",
      "Epoch 687/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1407e-04 - val_loss: 7.1406e-04\n",
      "Epoch 688/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1406e-04 - val_loss: 7.1405e-04\n",
      "Epoch 689/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1405e-04 - val_loss: 7.1405e-04\n",
      "Epoch 690/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1405e-04 - val_loss: 7.1404e-04\n",
      "Epoch 691/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1404e-04 - val_loss: 7.1404e-04\n",
      "Epoch 692/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1404e-04 - val_loss: 7.1403e-04\n",
      "Epoch 693/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1403e-04 - val_loss: 7.1403e-04\n",
      "Epoch 694/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1403e-04 - val_loss: 7.1402e-04\n",
      "Epoch 695/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1402e-04 - val_loss: 7.1401e-04\n",
      "Epoch 696/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1401e-04 - val_loss: 7.1401e-04\n",
      "Epoch 697/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1401e-04 - val_loss: 7.1400e-04\n",
      "Epoch 698/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1400e-04 - val_loss: 7.1400e-04\n",
      "Epoch 699/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1400e-04 - val_loss: 7.1399e-04\n",
      "Epoch 700/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1399e-04 - val_loss: 7.1398e-04\n",
      "Epoch 701/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1398e-04 - val_loss: 7.1398e-04\n",
      "Epoch 702/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1398e-04 - val_loss: 7.1397e-04\n",
      "Epoch 703/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1397e-04 - val_loss: 7.1396e-04\n",
      "Epoch 704/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1396e-04 - val_loss: 7.1396e-04\n",
      "Epoch 705/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1396e-04 - val_loss: 7.1395e-04\n",
      "Epoch 706/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1395e-04 - val_loss: 7.1395e-04\n",
      "Epoch 707/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1395e-04 - val_loss: 7.1394e-04\n",
      "Epoch 708/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1394e-04 - val_loss: 7.1393e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1393e-04 - val_loss: 7.1393e-04\n",
      "Epoch 710/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1393e-04 - val_loss: 7.1392e-04\n",
      "Epoch 711/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1392e-04 - val_loss: 7.1391e-04\n",
      "Epoch 712/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1391e-04 - val_loss: 7.1391e-04\n",
      "Epoch 713/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1391e-04 - val_loss: 7.1390e-04\n",
      "Epoch 714/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1390e-04 - val_loss: 7.1389e-04\n",
      "Epoch 715/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1389e-04 - val_loss: 7.1388e-04\n",
      "Epoch 716/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1388e-04 - val_loss: 7.1388e-04\n",
      "Epoch 717/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1388e-04 - val_loss: 7.1387e-04\n",
      "Epoch 718/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1387e-04 - val_loss: 7.1386e-04\n",
      "Epoch 719/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1386e-04 - val_loss: 7.1386e-04\n",
      "Epoch 720/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1386e-04 - val_loss: 7.1385e-04\n",
      "Epoch 721/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1385e-04 - val_loss: 7.1384e-04\n",
      "Epoch 722/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1384e-04 - val_loss: 7.1383e-04\n",
      "Epoch 723/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1383e-04 - val_loss: 7.1383e-04\n",
      "Epoch 724/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.1383e-04 - val_loss: 7.1382e-04\n",
      "Epoch 725/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1382e-04 - val_loss: 7.1381e-04\n",
      "Epoch 726/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1381e-04 - val_loss: 7.1381e-04\n",
      "Epoch 727/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1381e-04 - val_loss: 7.1380e-04\n",
      "Epoch 728/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1380e-04 - val_loss: 7.1379e-04\n",
      "Epoch 729/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1379e-04 - val_loss: 7.1378e-04\n",
      "Epoch 730/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1378e-04 - val_loss: 7.1377e-04\n",
      "Epoch 731/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1377e-04 - val_loss: 7.1377e-04\n",
      "Epoch 732/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1377e-04 - val_loss: 7.1376e-04\n",
      "Epoch 733/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1376e-04 - val_loss: 7.1375e-04\n",
      "Epoch 734/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1375e-04 - val_loss: 7.1374e-04\n",
      "Epoch 735/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1374e-04 - val_loss: 7.1373e-04\n",
      "Epoch 736/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1373e-04 - val_loss: 7.1373e-04\n",
      "Epoch 737/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1373e-04 - val_loss: 7.1372e-04\n",
      "Epoch 738/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1372e-04 - val_loss: 7.1371e-04\n",
      "Epoch 739/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1371e-04 - val_loss: 7.1370e-04\n",
      "Epoch 740/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1370e-04 - val_loss: 7.1369e-04\n",
      "Epoch 741/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1369e-04 - val_loss: 7.1368e-04\n",
      "Epoch 742/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 7.1368e-04 - val_loss: 7.1367e-04\n",
      "Epoch 743/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1367e-04 - val_loss: 7.1367e-04\n",
      "Epoch 744/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1367e-04 - val_loss: 7.1366e-04\n",
      "Epoch 745/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1366e-04 - val_loss: 7.1365e-04\n",
      "Epoch 746/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 7.1365e-04 - val_loss: 7.1364e-04\n",
      "Epoch 747/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1364e-04 - val_loss: 7.1363e-04\n",
      "Epoch 748/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1363e-04 - val_loss: 7.1362e-04\n",
      "Epoch 749/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1362e-04 - val_loss: 7.1361e-04\n",
      "Epoch 750/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1361e-04 - val_loss: 7.1360e-04\n",
      "Epoch 751/900\n",
      "650/650 [==============================] - 0s 133us/sample - loss: 7.1360e-04 - val_loss: 7.1359e-04\n",
      "Epoch 752/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1359e-04 - val_loss: 7.1358e-04\n",
      "Epoch 753/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1358e-04 - val_loss: 7.1357e-04\n",
      "Epoch 754/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1357e-04 - val_loss: 7.1356e-04\n",
      "Epoch 755/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1356e-04 - val_loss: 7.1355e-04\n",
      "Epoch 756/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1355e-04 - val_loss: 7.1354e-04\n",
      "Epoch 757/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1354e-04 - val_loss: 7.1353e-04\n",
      "Epoch 758/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.1353e-04 - val_loss: 7.1352e-04\n",
      "Epoch 759/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1352e-04 - val_loss: 7.1351e-04\n",
      "Epoch 760/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1351e-04 - val_loss: 7.1350e-04\n",
      "Epoch 761/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1350e-04 - val_loss: 7.1349e-04\n",
      "Epoch 762/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1349e-04 - val_loss: 7.1348e-04\n",
      "Epoch 763/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1348e-04 - val_loss: 7.1347e-04\n",
      "Epoch 764/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1347e-04 - val_loss: 7.1346e-04\n",
      "Epoch 765/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1346e-04 - val_loss: 7.1345e-04\n",
      "Epoch 766/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1345e-04 - val_loss: 7.1343e-04\n",
      "Epoch 767/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1343e-04 - val_loss: 7.1342e-04\n",
      "Epoch 768/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1342e-04 - val_loss: 7.1341e-04\n",
      "Epoch 769/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1341e-04 - val_loss: 7.1340e-04\n",
      "Epoch 770/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 7.1340e-04 - val_loss: 7.1339e-04\n",
      "Epoch 771/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1339e-04 - val_loss: 7.1337e-04\n",
      "Epoch 772/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1337e-04 - val_loss: 7.1336e-04\n",
      "Epoch 773/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1336e-04 - val_loss: 7.1335e-04\n",
      "Epoch 774/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1335e-04 - val_loss: 7.1334e-04\n",
      "Epoch 775/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1334e-04 - val_loss: 7.1332e-04\n",
      "Epoch 776/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1332e-04 - val_loss: 7.1331e-04\n",
      "Epoch 777/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1331e-04 - val_loss: 7.1330e-04\n",
      "Epoch 778/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1330e-04 - val_loss: 7.1328e-04\n",
      "Epoch 779/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1328e-04 - val_loss: 7.1327e-04\n",
      "Epoch 780/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1327e-04 - val_loss: 7.1326e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1326e-04 - val_loss: 7.1324e-04\n",
      "Epoch 782/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1324e-04 - val_loss: 7.1323e-04\n",
      "Epoch 783/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1323e-04 - val_loss: 7.1321e-04\n",
      "Epoch 784/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1321e-04 - val_loss: 7.1320e-04\n",
      "Epoch 785/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1320e-04 - val_loss: 7.1318e-04\n",
      "Epoch 786/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.1318e-04 - val_loss: 7.1317e-04\n",
      "Epoch 787/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1317e-04 - val_loss: 7.1315e-04\n",
      "Epoch 788/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1315e-04 - val_loss: 7.1313e-04\n",
      "Epoch 789/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1313e-04 - val_loss: 7.1312e-04\n",
      "Epoch 790/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1312e-04 - val_loss: 7.1310e-04\n",
      "Epoch 791/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1310e-04 - val_loss: 7.1308e-04\n",
      "Epoch 792/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.1308e-04 - val_loss: 7.1307e-04\n",
      "Epoch 793/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1307e-04 - val_loss: 7.1305e-04\n",
      "Epoch 794/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.1305e-04 - val_loss: 7.1303e-04\n",
      "Epoch 795/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 7.1303e-04 - val_loss: 7.1301e-04\n",
      "Epoch 796/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1301e-04 - val_loss: 7.1299e-04\n",
      "Epoch 797/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1299e-04 - val_loss: 7.1297e-04\n",
      "Epoch 798/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1297e-04 - val_loss: 7.1295e-04\n",
      "Epoch 799/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1295e-04 - val_loss: 7.1293e-04\n",
      "Epoch 800/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1293e-04 - val_loss: 7.1291e-04\n",
      "Epoch 801/900\n",
      "650/650 [==============================] - 0s 134us/sample - loss: 7.1291e-04 - val_loss: 7.1289e-04\n",
      "Epoch 802/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1289e-04 - val_loss: 7.1287e-04\n",
      "Epoch 803/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 7.1287e-04 - val_loss: 7.1285e-04\n",
      "Epoch 804/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1285e-04 - val_loss: 7.1282e-04\n",
      "Epoch 805/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1282e-04 - val_loss: 7.1280e-04\n",
      "Epoch 806/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1280e-04 - val_loss: 7.1278e-04\n",
      "Epoch 807/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1278e-04 - val_loss: 7.1275e-04\n",
      "Epoch 808/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1275e-04 - val_loss: 7.1273e-04\n",
      "Epoch 809/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1273e-04 - val_loss: 7.1270e-04\n",
      "Epoch 810/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1270e-04 - val_loss: 7.1267e-04\n",
      "Epoch 811/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.1267e-04 - val_loss: 7.1264e-04\n",
      "Epoch 812/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 7.1264e-04 - val_loss: 7.1262e-04\n",
      "Epoch 813/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1262e-04 - val_loss: 7.1259e-04\n",
      "Epoch 814/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1259e-04 - val_loss: 7.1255e-04\n",
      "Epoch 815/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1255e-04 - val_loss: 7.1252e-04\n",
      "Epoch 816/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1252e-04 - val_loss: 7.1249e-04\n",
      "Epoch 817/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1249e-04 - val_loss: 7.1245e-04\n",
      "Epoch 818/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1245e-04 - val_loss: 7.1242e-04\n",
      "Epoch 819/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1242e-04 - val_loss: 7.1238e-04\n",
      "Epoch 820/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1238e-04 - val_loss: 7.1234e-04\n",
      "Epoch 821/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1234e-04 - val_loss: 7.1230e-04\n",
      "Epoch 822/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1230e-04 - val_loss: 7.1226e-04\n",
      "Epoch 823/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1226e-04 - val_loss: 7.1221e-04\n",
      "Epoch 824/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1221e-04 - val_loss: 7.1217e-04\n",
      "Epoch 825/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1217e-04 - val_loss: 7.1212e-04\n",
      "Epoch 826/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1212e-04 - val_loss: 7.1206e-04\n",
      "Epoch 827/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 7.1206e-04 - val_loss: 7.1201e-04\n",
      "Epoch 828/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.1201e-04 - val_loss: 7.1195e-04\n",
      "Epoch 829/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1195e-04 - val_loss: 7.1189e-04\n",
      "Epoch 830/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1189e-04 - val_loss: 7.1182e-04\n",
      "Epoch 831/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 7.1182e-04 - val_loss: 7.1175e-04\n",
      "Epoch 832/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1175e-04 - val_loss: 7.1167e-04\n",
      "Epoch 833/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1167e-04 - val_loss: 7.1159e-04\n",
      "Epoch 834/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1159e-04 - val_loss: 7.1150e-04\n",
      "Epoch 835/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1150e-04 - val_loss: 7.1141e-04\n",
      "Epoch 836/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.1141e-04 - val_loss: 7.1130e-04\n",
      "Epoch 837/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.1130e-04 - val_loss: 7.1119e-04\n",
      "Epoch 838/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1119e-04 - val_loss: 7.1107e-04\n",
      "Epoch 839/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1107e-04 - val_loss: 7.1093e-04\n",
      "Epoch 840/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1093e-04 - val_loss: 7.1077e-04\n",
      "Epoch 841/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1077e-04 - val_loss: 7.1060e-04\n",
      "Epoch 842/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.1060e-04 - val_loss: 7.1041e-04\n",
      "Epoch 843/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.1041e-04 - val_loss: 7.1019e-04\n",
      "Epoch 844/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.1019e-04 - val_loss: 7.0994e-04\n",
      "Epoch 845/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.0994e-04 - val_loss: 7.0965e-04\n",
      "Epoch 846/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 7.0965e-04 - val_loss: 7.0931e-04\n",
      "Epoch 847/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.0931e-04 - val_loss: 7.0892e-04\n",
      "Epoch 848/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.0892e-04 - val_loss: 7.0844e-04\n",
      "Epoch 849/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.0844e-04 - val_loss: 7.0787e-04\n",
      "Epoch 850/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.0787e-04 - val_loss: 7.0718e-04\n",
      "Epoch 851/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.0718e-04 - val_loss: 7.0632e-04\n",
      "Epoch 852/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.0632e-04 - val_loss: 7.0525e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.0525e-04 - val_loss: 7.0390e-04\n",
      "Epoch 854/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.0390e-04 - val_loss: 7.0216e-04\n",
      "Epoch 855/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.0216e-04 - val_loss: 6.9994e-04\n",
      "Epoch 856/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 6.9994e-04 - val_loss: 6.9707e-04\n",
      "Epoch 857/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 6.9707e-04 - val_loss: 6.9344e-04\n",
      "Epoch 858/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 6.9344e-04 - val_loss: 6.8894e-04\n",
      "Epoch 859/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 6.8894e-04 - val_loss: 6.8372e-04\n",
      "Epoch 860/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 6.8372e-04 - val_loss: 6.7852e-04\n",
      "Epoch 861/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 6.7852e-04 - val_loss: 6.7554e-04\n",
      "Epoch 862/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 6.7554e-04 - val_loss: 6.8865e-04\n",
      "Epoch 863/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 6.8865e-04 - val_loss: 0.0011\n",
      "Epoch 864/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 865/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 866/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 867/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.0010 - val_loss: 8.3454e-04\n",
      "Epoch 868/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 8.3454e-04 - val_loss: 7.7928e-04\n",
      "Epoch 869/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.7928e-04 - val_loss: 7.6302e-04\n",
      "Epoch 870/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.6302e-04 - val_loss: 7.5708e-04\n",
      "Epoch 871/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.5708e-04 - val_loss: 7.4853e-04\n",
      "Epoch 872/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4853e-04 - val_loss: 7.4984e-04\n",
      "Epoch 873/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4984e-04 - val_loss: 7.5138e-04\n",
      "Epoch 874/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.5138e-04 - val_loss: 7.4593e-04\n",
      "Epoch 875/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4593e-04 - val_loss: 7.4912e-04\n",
      "Epoch 876/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.4912e-04 - val_loss: 7.4807e-04\n",
      "Epoch 877/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.4807e-04 - val_loss: 7.4602e-04\n",
      "Epoch 878/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.4602e-04 - val_loss: 7.4916e-04\n",
      "Epoch 879/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 7.4916e-04 - val_loss: 7.4504e-04\n",
      "Epoch 880/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4504e-04 - val_loss: 7.4746e-04\n",
      "Epoch 881/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.4746e-04 - val_loss: 7.4512e-04\n",
      "Epoch 882/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.4512e-04 - val_loss: 7.4528e-04\n",
      "Epoch 883/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.4528e-04 - val_loss: 7.4474e-04\n",
      "Epoch 884/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.4474e-04 - val_loss: 7.4335e-04\n",
      "Epoch 885/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 7.4335e-04 - val_loss: 7.4365e-04\n",
      "Epoch 886/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.4365e-04 - val_loss: 7.4167e-04\n",
      "Epoch 887/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.4167e-04 - val_loss: 7.4203e-04\n",
      "Epoch 888/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.4203e-04 - val_loss: 7.4015e-04\n",
      "Epoch 889/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 7.4015e-04 - val_loss: 7.3993e-04\n",
      "Epoch 890/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 7.3993e-04 - val_loss: 7.3870e-04\n",
      "Epoch 891/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.3870e-04 - val_loss: 7.3733e-04\n",
      "Epoch 892/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.3733e-04 - val_loss: 7.3738e-04\n",
      "Epoch 893/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.3738e-04 - val_loss: 7.3485e-04\n",
      "Epoch 894/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 7.3485e-04 - val_loss: 7.3503e-04\n",
      "Epoch 895/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 7.3503e-04 - val_loss: 7.3432e-04\n",
      "Epoch 896/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 7.3432e-04 - val_loss: 7.3202e-04\n",
      "Epoch 897/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 7.3202e-04 - val_loss: 7.3146e-04\n",
      "Epoch 898/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 7.3146e-04 - val_loss: 7.3247e-04\n",
      "Epoch 899/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 7.3247e-04 - val_loss: 7.3442e-04\n",
      "Epoch 900/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 7.3442e-04 - val_loss: 7.3996e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_5)\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=900, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), tight_layout=True)\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.set_title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sampling a 1: 0.4553846153846154\n",
      "Probability of sampling a 0: 0.5446153846153846\n"
     ]
    }
   ],
   "source": [
    "# Mapping labels to categorical labels\n",
    "def to_categorical(el):\n",
    "    if el > 0:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = 0\n",
    "    return c\n",
    "\n",
    "y_cls = np.array(list(map(to_categorical, y)))\n",
    "print('Probability of sampling a 1: {}'.format(y_cls.sum()/len(y_cls)))\n",
    "print('Probability of sampling a 0: {}'.format((len(y_cls) - y_cls.sum())/len(y_cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "log_adj_daily_returns (Input [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_ExpandDims (Tens [(None, 6, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 6, 500)            1004000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6, 500)            2002000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 300)            961200    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 160)            295040    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                42200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 4,304,491\n",
      "Trainable params: 4,304,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 650 samples, validate on 650 samples\n",
      "Epoch 1/900\n",
      "650/650 [==============================] - 6s 10ms/sample - loss: 0.6931 - binary_accuracy: 0.5077 - precision: 0.4615 - recall: 0.4865 - val_loss: 0.6922 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/900\n",
      "650/650 [==============================] - 0s 97us/sample - loss: 0.6922 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6913 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6913 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6904 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6904 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6895 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6895 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6898 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 0.6898 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6900 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/900\n",
      "650/650 [==============================] - 0s 104us/sample - loss: 0.6900 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6896 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6896 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6894 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6894 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6894 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6894 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6893 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6893 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 51/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 52/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 53/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 54/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 55/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 56/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 57/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 58/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 60/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 61/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 62/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 63/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 64/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 65/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 66/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 67/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 68/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 69/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 70/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 71/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 72/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 73/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 74/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 75/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 76/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 77/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 78/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 79/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 80/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 81/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 82/900\n",
      "650/650 [==============================] - 0s 106us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 83/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 84/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 85/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 86/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 87/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 88/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6892 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 89/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6892 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 90/900\n",
      "650/650 [==============================] - 0s 129us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 92/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 93/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 94/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 95/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 96/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 97/900\n",
      "650/650 [==============================] - 0s 98us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 98/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 99/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 100/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 101/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 102/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 103/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 104/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 105/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 106/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 107/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 108/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 109/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 110/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 111/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 112/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 113/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 114/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 115/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 116/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 117/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 118/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 119/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 120/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 121/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 122/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6891 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6891 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 124/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 125/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 126/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5446 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 127/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6890 - binary_accuracy: 0.5446 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6890 - val_binary_accuracy: 0.5477 - val_precision: 1.0000 - val_recall: 0.0068\n",
      "Epoch 128/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6890 - binary_accuracy: 0.5477 - precision: 1.0000 - recall: 0.0068 - val_loss: 0.6890 - val_binary_accuracy: 0.5477 - val_precision: 1.0000 - val_recall: 0.0068\n",
      "Epoch 129/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6890 - binary_accuracy: 0.5477 - precision: 1.0000 - recall: 0.0068 - val_loss: 0.6890 - val_binary_accuracy: 0.5462 - val_precision: 0.6667 - val_recall: 0.0068\n",
      "Epoch 130/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6890 - binary_accuracy: 0.5462 - precision: 0.6667 - recall: 0.0068 - val_loss: 0.6889 - val_binary_accuracy: 0.5462 - val_precision: 0.6667 - val_recall: 0.0068\n",
      "Epoch 131/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6889 - binary_accuracy: 0.5462 - precision: 0.6667 - recall: 0.0068 - val_loss: 0.6889 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0101\n",
      "Epoch 132/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6889 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0101 - val_loss: 0.6889 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0101\n",
      "Epoch 133/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6889 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0101 - val_loss: 0.6889 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0101\n",
      "Epoch 134/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6889 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0101 - val_loss: 0.6888 - val_binary_accuracy: 0.5462 - val_precision: 0.5714 - val_recall: 0.0135\n",
      "Epoch 135/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6888 - binary_accuracy: 0.5462 - precision: 0.5714 - recall: 0.0135 - val_loss: 0.6888 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 136/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6888 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6888 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 137/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6888 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6887 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 138/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6887 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6887 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 139/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6887 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6886 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 140/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6886 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6886 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 141/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6886 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6885 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 142/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6885 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6884 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n",
      "Epoch 143/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6884 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6883 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 144/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6883 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6882 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 145/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6882 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6881 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 146/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6881 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6879 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 147/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6879 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6877 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 148/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.6877 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6875 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0169\n",
      "Epoch 149/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6875 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0169 - val_loss: 0.6872 - val_binary_accuracy: 0.5431 - val_precision: 0.4545 - val_recall: 0.0169\n",
      "Epoch 150/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6872 - binary_accuracy: 0.5431 - precision: 0.4545 - recall: 0.0169 - val_loss: 0.6869 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0236\n",
      "Epoch 151/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6869 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0236 - val_loss: 0.6866 - val_binary_accuracy: 0.5492 - val_precision: 0.5789 - val_recall: 0.0372\n",
      "Epoch 152/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6866 - binary_accuracy: 0.5492 - precision: 0.5789 - recall: 0.0372 - val_loss: 0.6867 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0270\n",
      "Epoch 153/900\n",
      "650/650 [==============================] - 0s 126us/sample - loss: 0.6867 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0270 - val_loss: 0.6873 - val_binary_accuracy: 0.5292 - val_precision: 0.4324 - val_recall: 0.1081\n",
      "Epoch 154/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6873 - binary_accuracy: 0.5292 - precision: 0.4324 - recall: 0.1081 - val_loss: 0.6870 - val_binary_accuracy: 0.5538 - val_precision: 0.6154 - val_recall: 0.0541\n",
      "Epoch 155/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6870 - binary_accuracy: 0.5538 - precision: 0.6154 - recall: 0.0541 - val_loss: 0.6870 - val_binary_accuracy: 0.5508 - val_precision: 0.6000 - val_recall: 0.0405\n",
      "Epoch 156/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6870 - binary_accuracy: 0.5508 - precision: 0.6000 - recall: 0.0405 - val_loss: 0.6864 - val_binary_accuracy: 0.5600 - val_precision: 0.6667 - val_recall: 0.0676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6864 - binary_accuracy: 0.5600 - precision: 0.6667 - recall: 0.0676 - val_loss: 0.6863 - val_binary_accuracy: 0.5646 - val_precision: 0.7241 - val_recall: 0.0709\n",
      "Epoch 158/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6863 - binary_accuracy: 0.5646 - precision: 0.7241 - recall: 0.0709 - val_loss: 0.6862 - val_binary_accuracy: 0.5492 - val_precision: 0.5789 - val_recall: 0.0372\n",
      "Epoch 159/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6862 - binary_accuracy: 0.5492 - precision: 0.5789 - recall: 0.0372 - val_loss: 0.6861 - val_binary_accuracy: 0.5462 - val_precision: 0.5455 - val_recall: 0.0203\n",
      "Epoch 160/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6861 - binary_accuracy: 0.5462 - precision: 0.5455 - recall: 0.0203 - val_loss: 0.6861 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 161/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6861 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6861 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 162/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6861 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6861 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 163/900\n",
      "650/650 [==============================] - 0s 91us/sample - loss: 0.6861 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6860 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 164/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6860 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6859 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 165/900\n",
      "650/650 [==============================] - 0s 127us/sample - loss: 0.6859 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6859 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 166/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6859 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6857 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 167/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6857 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6856 - val_binary_accuracy: 0.5462 - val_precision: 0.5714 - val_recall: 0.0135\n",
      "Epoch 168/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6856 - binary_accuracy: 0.5462 - precision: 0.5714 - recall: 0.0135 - val_loss: 0.6855 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 169/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6855 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6853 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 170/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6853 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6851 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 171/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6851 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6850 - val_binary_accuracy: 0.5431 - val_precision: 0.4444 - val_recall: 0.0135\n",
      "Epoch 172/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6850 - binary_accuracy: 0.5431 - precision: 0.4444 - recall: 0.0135 - val_loss: 0.6849 - val_binary_accuracy: 0.5446 - val_precision: 0.5000 - val_recall: 0.0135\n",
      "Epoch 173/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6849 - binary_accuracy: 0.5446 - precision: 0.5000 - recall: 0.0135 - val_loss: 0.6847 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 174/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6847 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6844 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 175/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6844 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6842 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 176/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6842 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6840 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 177/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6840 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6838 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 178/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6838 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6836 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 179/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6836 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6833 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 180/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6833 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6831 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 181/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6831 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6829 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 182/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6829 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6827 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 183/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6827 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6827 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 184/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6827 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6824 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 185/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6824 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6822 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 186/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6822 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6820 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 187/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6820 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6818 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 188/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6818 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 189/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6816 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6814 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 190/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6814 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6824 - val_binary_accuracy: 0.5477 - val_precision: 0.6250 - val_recall: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6824 - binary_accuracy: 0.5477 - precision: 0.6250 - recall: 0.0169 - val_loss: 0.6875 - val_binary_accuracy: 0.5738 - val_precision: 0.7568 - val_recall: 0.0946\n",
      "Epoch 192/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6875 - binary_accuracy: 0.5738 - precision: 0.7568 - recall: 0.0946 - val_loss: 0.6830 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 193/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6830 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6889 - val_binary_accuracy: 0.5508 - val_precision: 0.8333 - val_recall: 0.0169\n",
      "Epoch 194/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6889 - binary_accuracy: 0.5508 - precision: 0.8333 - recall: 0.0169 - val_loss: 0.6814 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 195/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6814 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6845 - val_binary_accuracy: 0.5631 - val_precision: 0.7500 - val_recall: 0.0608\n",
      "Epoch 196/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6845 - binary_accuracy: 0.5631 - precision: 0.7500 - recall: 0.0608 - val_loss: 0.6830 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 197/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6830 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6815 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 198/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6815 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6823 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 199/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6823 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6833 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 200/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6833 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6828 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 201/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6828 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6819 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 202/900\n",
      "650/650 [==============================] - 0s 108us/sample - loss: 0.6819 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6818 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 203/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6818 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6824 - val_binary_accuracy: 0.5477 - val_precision: 0.6667 - val_recall: 0.0135\n",
      "Epoch 204/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6824 - binary_accuracy: 0.5477 - precision: 0.6667 - recall: 0.0135 - val_loss: 0.6821 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 205/900\n",
      "650/650 [==============================] - 0s 124us/sample - loss: 0.6821 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 206/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6817 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 207/900\n",
      "650/650 [==============================] - 0s 111us/sample - loss: 0.6816 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 208/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 209/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6816 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6814 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 210/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6814 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6810 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 211/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6810 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6811 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 212/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6811 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6811 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 213/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6811 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6808 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 214/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6808 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6810 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 215/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6810 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6810 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 216/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6810 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6807 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 217/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6807 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6807 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 218/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6807 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6807 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 219/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6807 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6806 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 220/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6806 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 221/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6805 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 222/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6805 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 223/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6805 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6805 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 224/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6805 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 226/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 227/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 228/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6804 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6803 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 229/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6803 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6803 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 230/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6803 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6803 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 231/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6803 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 232/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 233/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 234/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 235/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 236/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6801 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 237/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6801 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 238/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6801 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6801 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 239/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6801 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 240/900\n",
      "650/650 [==============================] - 0s 93us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 241/900\n",
      "650/650 [==============================] - 0s 110us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 242/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 243/900\n",
      "650/650 [==============================] - 0s 130us/sample - loss: 0.6800 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6799 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 244/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6799 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6799 - val_binary_accuracy: 0.5462 - val_precision: 0.5556 - val_recall: 0.0169\n",
      "Epoch 245/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6799 - binary_accuracy: 0.5462 - precision: 0.5556 - recall: 0.0169 - val_loss: 0.6799 - val_binary_accuracy: 0.5477 - val_precision: 0.6000 - val_recall: 0.0203\n",
      "Epoch 246/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6799 - binary_accuracy: 0.5477 - precision: 0.6000 - recall: 0.0203 - val_loss: 0.6798 - val_binary_accuracy: 0.5492 - val_precision: 0.6364 - val_recall: 0.0236\n",
      "Epoch 247/900\n",
      "650/650 [==============================] - 0s 92us/sample - loss: 0.6798 - binary_accuracy: 0.5492 - precision: 0.6364 - recall: 0.0236 - val_loss: 0.6798 - val_binary_accuracy: 0.5492 - val_precision: 0.6364 - val_recall: 0.0236\n",
      "Epoch 248/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6798 - binary_accuracy: 0.5492 - precision: 0.6364 - recall: 0.0236 - val_loss: 0.6797 - val_binary_accuracy: 0.5508 - val_precision: 0.6667 - val_recall: 0.0270\n",
      "Epoch 249/900\n",
      "650/650 [==============================] - 0s 132us/sample - loss: 0.6797 - binary_accuracy: 0.5508 - precision: 0.6667 - recall: 0.0270 - val_loss: 0.6796 - val_binary_accuracy: 0.5508 - val_precision: 0.6667 - val_recall: 0.0270\n",
      "Epoch 250/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6796 - binary_accuracy: 0.5508 - precision: 0.6667 - recall: 0.0270 - val_loss: 0.6795 - val_binary_accuracy: 0.5554 - val_precision: 0.7333 - val_recall: 0.0372\n",
      "Epoch 251/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6795 - binary_accuracy: 0.5554 - precision: 0.7333 - recall: 0.0372 - val_loss: 0.6794 - val_binary_accuracy: 0.5585 - val_precision: 0.7647 - val_recall: 0.0439\n",
      "Epoch 252/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6794 - binary_accuracy: 0.5585 - precision: 0.7647 - recall: 0.0439 - val_loss: 0.6793 - val_binary_accuracy: 0.5569 - val_precision: 0.7222 - val_recall: 0.0439\n",
      "Epoch 253/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6793 - binary_accuracy: 0.5569 - precision: 0.7222 - recall: 0.0439 - val_loss: 0.6791 - val_binary_accuracy: 0.5569 - val_precision: 0.7222 - val_recall: 0.0439\n",
      "Epoch 254/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6791 - binary_accuracy: 0.5569 - precision: 0.7222 - recall: 0.0439 - val_loss: 0.6788 - val_binary_accuracy: 0.5554 - val_precision: 0.6842 - val_recall: 0.0439\n",
      "Epoch 255/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6788 - binary_accuracy: 0.5554 - precision: 0.6842 - recall: 0.0439 - val_loss: 0.6785 - val_binary_accuracy: 0.5569 - val_precision: 0.6538 - val_recall: 0.0574\n",
      "Epoch 256/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6785 - binary_accuracy: 0.5569 - precision: 0.6538 - recall: 0.0574 - val_loss: 0.6781 - val_binary_accuracy: 0.5600 - val_precision: 0.6786 - val_recall: 0.0642\n",
      "Epoch 257/900\n",
      "650/650 [==============================] - 0s 125us/sample - loss: 0.6781 - binary_accuracy: 0.5600 - precision: 0.6786 - recall: 0.0642 - val_loss: 0.6776 - val_binary_accuracy: 0.5569 - val_precision: 0.6250 - val_recall: 0.0676\n",
      "Epoch 258/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6776 - binary_accuracy: 0.5569 - precision: 0.6250 - recall: 0.0676 - val_loss: 0.6769 - val_binary_accuracy: 0.5615 - val_precision: 0.6571 - val_recall: 0.0777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6769 - binary_accuracy: 0.5615 - precision: 0.6571 - recall: 0.0777 - val_loss: 0.6763 - val_binary_accuracy: 0.5662 - val_precision: 0.6944 - val_recall: 0.0845\n",
      "Epoch 260/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6763 - binary_accuracy: 0.5662 - precision: 0.6944 - recall: 0.0845 - val_loss: 0.6769 - val_binary_accuracy: 0.5815 - val_precision: 0.7000 - val_recall: 0.1419\n",
      "Epoch 261/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6769 - binary_accuracy: 0.5815 - precision: 0.7000 - recall: 0.1419 - val_loss: 0.6769 - val_binary_accuracy: 0.5554 - val_precision: 0.5507 - val_recall: 0.1284\n",
      "Epoch 262/900\n",
      "650/650 [==============================] - 0s 107us/sample - loss: 0.6769 - binary_accuracy: 0.5554 - precision: 0.5507 - recall: 0.1284 - val_loss: 0.6829 - val_binary_accuracy: 0.5462 - val_precision: 0.5028 - val_recall: 0.3007\n",
      "Epoch 263/900\n",
      "650/650 [==============================] - 0s 103us/sample - loss: 0.6829 - binary_accuracy: 0.5462 - precision: 0.5028 - recall: 0.3007 - val_loss: 0.6788 - val_binary_accuracy: 0.5646 - val_precision: 0.7097 - val_recall: 0.0743\n",
      "Epoch 264/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6788 - binary_accuracy: 0.5646 - precision: 0.7097 - recall: 0.0743 - val_loss: 0.7089 - val_binary_accuracy: 0.4492 - val_precision: 0.4460 - val_recall: 0.8649\n",
      "Epoch 265/900\n",
      "650/650 [==============================] - 0s 109us/sample - loss: 0.7089 - binary_accuracy: 0.4492 - precision: 0.4460 - recall: 0.8649 - val_loss: 0.6807 - val_binary_accuracy: 0.5415 - val_precision: 0.4889 - val_recall: 0.1486\n",
      "Epoch 266/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6807 - binary_accuracy: 0.5415 - precision: 0.4889 - recall: 0.1486 - val_loss: 0.6934 - val_binary_accuracy: 0.5677 - val_precision: 0.8947 - val_recall: 0.0574\n",
      "Epoch 267/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6934 - binary_accuracy: 0.5677 - precision: 0.8947 - recall: 0.0574 - val_loss: 0.6847 - val_binary_accuracy: 0.5738 - val_precision: 0.7436 - val_recall: 0.0980\n",
      "Epoch 268/900\n",
      "650/650 [==============================] - 0s 99us/sample - loss: 0.6847 - binary_accuracy: 0.5738 - precision: 0.7436 - recall: 0.0980 - val_loss: 0.6819 - val_binary_accuracy: 0.5631 - val_precision: 0.5938 - val_recall: 0.1284\n",
      "Epoch 269/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6819 - binary_accuracy: 0.5631 - precision: 0.5938 - recall: 0.1284 - val_loss: 0.6819 - val_binary_accuracy: 0.5662 - val_precision: 0.6167 - val_recall: 0.1250\n",
      "Epoch 270/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6819 - binary_accuracy: 0.5662 - precision: 0.6167 - recall: 0.1250 - val_loss: 0.6879 - val_binary_accuracy: 0.5677 - val_precision: 0.7419 - val_recall: 0.0777\n",
      "Epoch 271/900\n",
      "650/650 [==============================] - 0s 101us/sample - loss: 0.6879 - binary_accuracy: 0.5677 - precision: 0.7419 - recall: 0.0777 - val_loss: 0.6825 - val_binary_accuracy: 0.5677 - val_precision: 0.8000 - val_recall: 0.0676\n",
      "Epoch 272/900\n",
      "650/650 [==============================] - 0s 123us/sample - loss: 0.6825 - binary_accuracy: 0.5677 - precision: 0.8000 - recall: 0.0676 - val_loss: 0.6804 - val_binary_accuracy: 0.5662 - val_precision: 0.7692 - val_recall: 0.0676\n",
      "Epoch 273/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6804 - binary_accuracy: 0.5662 - precision: 0.7692 - recall: 0.0676 - val_loss: 0.6804 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 274/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6804 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6806 - val_binary_accuracy: 0.5538 - val_precision: 0.8000 - val_recall: 0.0270\n",
      "Epoch 275/900\n",
      "650/650 [==============================] - 0s 112us/sample - loss: 0.6806 - binary_accuracy: 0.5538 - precision: 0.8000 - recall: 0.0270 - val_loss: 0.6809 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 276/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6809 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6813 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 277/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6813 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6816 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 278/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6816 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 279/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 280/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 281/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6818 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 282/900\n",
      "650/650 [==============================] - 0s 105us/sample - loss: 0.6818 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6817 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 283/900\n",
      "650/650 [==============================] - 0s 102us/sample - loss: 0.6817 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6815 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 284/900\n",
      "650/650 [==============================] - 0s 128us/sample - loss: 0.6815 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6813 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 285/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6813 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6811 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 286/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6811 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6809 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 287/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6809 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6808 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 288/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6808 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6806 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 289/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6806 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6804 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 290/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6804 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6802 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 291/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6802 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6800 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 292/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6800 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6798 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/900\n",
      "650/650 [==============================] - 0s 95us/sample - loss: 0.6798 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6797 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 294/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 0.6797 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6796 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 295/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6796 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6795 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 296/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6795 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6794 - val_binary_accuracy: 0.5523 - val_precision: 1.0000 - val_recall: 0.0169\n",
      "Epoch 297/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6794 - binary_accuracy: 0.5523 - precision: 1.0000 - recall: 0.0169 - val_loss: 0.6793 - val_binary_accuracy: 0.5492 - val_precision: 0.7143 - val_recall: 0.0169\n",
      "Epoch 298/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6793 - binary_accuracy: 0.5492 - precision: 0.7143 - recall: 0.0169 - val_loss: 0.6792 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 299/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6792 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6792 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 300/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6792 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6791 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 301/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6791 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6788 - val_binary_accuracy: 0.5538 - val_precision: 0.8000 - val_recall: 0.0270\n",
      "Epoch 302/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6788 - binary_accuracy: 0.5538 - precision: 0.8000 - recall: 0.0270 - val_loss: 0.6787 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 303/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6787 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6785 - val_binary_accuracy: 0.5631 - val_precision: 0.8750 - val_recall: 0.0473\n",
      "Epoch 304/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6785 - binary_accuracy: 0.5631 - precision: 0.8750 - recall: 0.0473 - val_loss: 0.6783 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 305/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6783 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6781 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 306/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6781 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6779 - val_binary_accuracy: 0.5600 - val_precision: 0.8571 - val_recall: 0.0405\n",
      "Epoch 307/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6779 - binary_accuracy: 0.5600 - precision: 0.8571 - recall: 0.0405 - val_loss: 0.6775 - val_binary_accuracy: 0.5677 - val_precision: 0.8261 - val_recall: 0.0642\n",
      "Epoch 308/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6775 - binary_accuracy: 0.5677 - precision: 0.8261 - recall: 0.0642 - val_loss: 0.6771 - val_binary_accuracy: 0.5692 - val_precision: 0.7857 - val_recall: 0.0743\n",
      "Epoch 309/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6771 - binary_accuracy: 0.5692 - precision: 0.7857 - recall: 0.0743 - val_loss: 0.6769 - val_binary_accuracy: 0.5662 - val_precision: 0.6842 - val_recall: 0.0878\n",
      "Epoch 310/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6769 - binary_accuracy: 0.5662 - precision: 0.6842 - recall: 0.0878 - val_loss: 0.6762 - val_binary_accuracy: 0.5662 - val_precision: 0.7059 - val_recall: 0.0811\n",
      "Epoch 311/900\n",
      "650/650 [==============================] - 0s 113us/sample - loss: 0.6762 - binary_accuracy: 0.5662 - precision: 0.7059 - recall: 0.0811 - val_loss: 0.6757 - val_binary_accuracy: 0.5677 - val_precision: 0.7586 - val_recall: 0.0743\n",
      "Epoch 312/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6757 - binary_accuracy: 0.5677 - precision: 0.7586 - recall: 0.0743 - val_loss: 0.6753 - val_binary_accuracy: 0.5723 - val_precision: 0.8214 - val_recall: 0.0777\n",
      "Epoch 313/900\n",
      "650/650 [==============================] - 0s 100us/sample - loss: 0.6753 - binary_accuracy: 0.5723 - precision: 0.8214 - recall: 0.0777 - val_loss: 0.6747 - val_binary_accuracy: 0.5600 - val_precision: 0.6316 - val_recall: 0.0811\n",
      "Epoch 314/900\n",
      "650/650 [==============================] - 0s 131us/sample - loss: 0.6747 - binary_accuracy: 0.5600 - precision: 0.6316 - recall: 0.0811 - val_loss: 0.6743 - val_binary_accuracy: 0.5754 - val_precision: 0.7083 - val_recall: 0.1149\n",
      "Epoch 315/900\n",
      "650/650 [==============================] - 0s 114us/sample - loss: 0.6743 - binary_accuracy: 0.5754 - precision: 0.7083 - recall: 0.1149 - val_loss: 0.6737 - val_binary_accuracy: 0.5677 - val_precision: 0.6744 - val_recall: 0.0980\n",
      "Epoch 316/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6737 - binary_accuracy: 0.5677 - precision: 0.6744 - recall: 0.0980 - val_loss: 0.6733 - val_binary_accuracy: 0.5646 - val_precision: 0.6585 - val_recall: 0.0912\n",
      "Epoch 317/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6733 - binary_accuracy: 0.5646 - precision: 0.6585 - recall: 0.0912 - val_loss: 0.6726 - val_binary_accuracy: 0.5692 - val_precision: 0.6818 - val_recall: 0.1014\n",
      "Epoch 318/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6726 - binary_accuracy: 0.5692 - precision: 0.6818 - recall: 0.1014 - val_loss: 0.6722 - val_binary_accuracy: 0.5846 - val_precision: 0.7031 - val_recall: 0.1520\n",
      "Epoch 319/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6722 - binary_accuracy: 0.5846 - precision: 0.7031 - recall: 0.1520 - val_loss: 0.6715 - val_binary_accuracy: 0.5862 - val_precision: 0.7368 - val_recall: 0.1419\n",
      "Epoch 320/900\n",
      "650/650 [==============================] - 0s 122us/sample - loss: 0.6715 - binary_accuracy: 0.5862 - precision: 0.7368 - recall: 0.1419 - val_loss: 0.6710 - val_binary_accuracy: 0.5831 - val_precision: 0.7358 - val_recall: 0.1318\n",
      "Epoch 321/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6710 - binary_accuracy: 0.5831 - precision: 0.7358 - recall: 0.1318 - val_loss: 0.6704 - val_binary_accuracy: 0.5908 - val_precision: 0.7206 - val_recall: 0.1655\n",
      "Epoch 322/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6704 - binary_accuracy: 0.5908 - precision: 0.7206 - recall: 0.1655 - val_loss: 0.6696 - val_binary_accuracy: 0.5862 - val_precision: 0.7077 - val_recall: 0.1554\n",
      "Epoch 323/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6696 - binary_accuracy: 0.5862 - precision: 0.7077 - recall: 0.1554 - val_loss: 0.6690 - val_binary_accuracy: 0.5846 - val_precision: 0.6912 - val_recall: 0.1588\n",
      "Epoch 324/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6690 - binary_accuracy: 0.5846 - precision: 0.6912 - recall: 0.1588 - val_loss: 0.6685 - val_binary_accuracy: 0.5785 - val_precision: 0.6410 - val_recall: 0.1689\n",
      "Epoch 325/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6685 - binary_accuracy: 0.5785 - precision: 0.6410 - recall: 0.1689 - val_loss: 0.6689 - val_binary_accuracy: 0.5662 - val_precision: 0.5946 - val_recall: 0.1486\n",
      "Epoch 326/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6689 - binary_accuracy: 0.5662 - precision: 0.5946 - recall: 0.1486 - val_loss: 0.6717 - val_binary_accuracy: 0.5646 - val_precision: 0.5644 - val_recall: 0.1926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6717 - binary_accuracy: 0.5646 - precision: 0.5644 - recall: 0.1926 - val_loss: 0.6794 - val_binary_accuracy: 0.5523 - val_precision: 0.5126 - val_recall: 0.3446\n",
      "Epoch 328/900\n",
      "650/650 [==============================] - 0s 121us/sample - loss: 0.6794 - binary_accuracy: 0.5523 - precision: 0.5126 - recall: 0.3446 - val_loss: 0.6763 - val_binary_accuracy: 0.5585 - val_precision: 0.5584 - val_recall: 0.1453\n",
      "Epoch 329/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6763 - binary_accuracy: 0.5585 - precision: 0.5584 - recall: 0.1453 - val_loss: 0.6715 - val_binary_accuracy: 0.5785 - val_precision: 0.6250 - val_recall: 0.1858\n",
      "Epoch 330/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6715 - binary_accuracy: 0.5785 - precision: 0.6250 - recall: 0.1858 - val_loss: 0.6685 - val_binary_accuracy: 0.5708 - val_precision: 0.5714 - val_recall: 0.2297\n",
      "Epoch 331/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6685 - binary_accuracy: 0.5708 - precision: 0.5714 - recall: 0.2297 - val_loss: 0.6747 - val_binary_accuracy: 0.5631 - val_precision: 0.5275 - val_recall: 0.3885\n",
      "Epoch 332/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6747 - binary_accuracy: 0.5631 - precision: 0.5275 - recall: 0.3885 - val_loss: 0.6708 - val_binary_accuracy: 0.5708 - val_precision: 0.6308 - val_recall: 0.1385\n",
      "Epoch 333/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6708 - binary_accuracy: 0.5708 - precision: 0.6308 - recall: 0.1385 - val_loss: 0.6690 - val_binary_accuracy: 0.5846 - val_precision: 0.6757 - val_recall: 0.1689\n",
      "Epoch 334/900\n",
      "650/650 [==============================] - 0s 120us/sample - loss: 0.6690 - binary_accuracy: 0.5846 - precision: 0.6757 - recall: 0.1689 - val_loss: 0.6734 - val_binary_accuracy: 0.5723 - val_precision: 0.5776 - val_recall: 0.2264\n",
      "Epoch 335/900\n",
      "650/650 [==============================] - 0s 116us/sample - loss: 0.6734 - binary_accuracy: 0.5723 - precision: 0.5776 - recall: 0.2264 - val_loss: 0.6701 - val_binary_accuracy: 0.5738 - val_precision: 0.6792 - val_recall: 0.1216\n",
      "Epoch 336/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6701 - binary_accuracy: 0.5738 - precision: 0.6792 - recall: 0.1216 - val_loss: 0.6757 - val_binary_accuracy: 0.5538 - val_precision: 0.5294 - val_recall: 0.1824\n",
      "Epoch 337/900\n",
      "650/650 [==============================] - 0s 117us/sample - loss: 0.6757 - binary_accuracy: 0.5538 - precision: 0.5294 - recall: 0.1824 - val_loss: 0.6728 - val_binary_accuracy: 0.5692 - val_precision: 0.6081 - val_recall: 0.1520\n",
      "Epoch 338/900\n",
      "650/650 [==============================] - 0s 119us/sample - loss: 0.6728 - binary_accuracy: 0.5692 - precision: 0.6081 - recall: 0.1520 - val_loss: 0.6665 - val_binary_accuracy: 0.5723 - val_precision: 0.6500 - val_recall: 0.1318\n",
      "Epoch 339/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6665 - binary_accuracy: 0.5723 - precision: 0.6500 - recall: 0.1318 - val_loss: 0.6735 - val_binary_accuracy: 0.5754 - val_precision: 0.5893 - val_recall: 0.2230\n",
      "Epoch 340/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6735 - binary_accuracy: 0.5754 - precision: 0.5893 - recall: 0.2230 - val_loss: 0.6674 - val_binary_accuracy: 0.5846 - val_precision: 0.7031 - val_recall: 0.1520\n",
      "Epoch 341/900\n",
      "650/650 [==============================] - 0s 115us/sample - loss: 0.6674 - binary_accuracy: 0.5846 - precision: 0.7031 - recall: 0.1520 - val_loss: 0.6685 - val_binary_accuracy: 0.5831 - val_precision: 0.8049 - val_recall: 0.1115\n",
      "Epoch 342/900\n",
      "650/650 [==============================] - 0s 118us/sample - loss: 0.6685 - binary_accuracy: 0.5831 - precision: 0.8049 - recall: 0.1115 - val_loss: 0.6699 - val_binary_accuracy: 0.5692 - val_precision: 0.6600 - val_recall: 0.1115\n",
      "Epoch 343/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6699 - binary_accuracy: 0.5692 - precision: 0.6600 - recall: 0.1115 - val_loss: 0.6692 - val_binary_accuracy: 0.5846 - val_precision: 0.6857 - val_recall: 0.1622\n",
      "Epoch 344/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6692 - binary_accuracy: 0.5846 - precision: 0.6857 - recall: 0.1622 - val_loss: 0.6679 - val_binary_accuracy: 0.5692 - val_precision: 0.5909 - val_recall: 0.1757\n",
      "Epoch 345/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6679 - binary_accuracy: 0.5692 - precision: 0.5909 - recall: 0.1757 - val_loss: 0.6682 - val_binary_accuracy: 0.5769 - val_precision: 0.6235 - val_recall: 0.1791\n",
      "Epoch 346/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6682 - binary_accuracy: 0.5769 - precision: 0.6235 - recall: 0.1791 - val_loss: 0.6667 - val_binary_accuracy: 0.5754 - val_precision: 0.6724 - val_recall: 0.1318\n",
      "Epoch 347/900\n",
      "650/650 [==============================] - 0s 165us/sample - loss: 0.6667 - binary_accuracy: 0.5754 - precision: 0.6724 - recall: 0.1318 - val_loss: 0.6670 - val_binary_accuracy: 0.5923 - val_precision: 0.8444 - val_recall: 0.1284\n",
      "Epoch 348/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6670 - binary_accuracy: 0.5923 - precision: 0.8444 - recall: 0.1284 - val_loss: 0.6651 - val_binary_accuracy: 0.5846 - val_precision: 0.7500 - val_recall: 0.1318\n",
      "Epoch 349/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6651 - binary_accuracy: 0.5846 - precision: 0.7500 - recall: 0.1318 - val_loss: 0.6644 - val_binary_accuracy: 0.5646 - val_precision: 0.5747 - val_recall: 0.1689\n",
      "Epoch 350/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6644 - binary_accuracy: 0.5646 - precision: 0.5747 - recall: 0.1689 - val_loss: 0.6647 - val_binary_accuracy: 0.5646 - val_precision: 0.5565 - val_recall: 0.2162\n",
      "Epoch 351/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.6647 - binary_accuracy: 0.5646 - precision: 0.5565 - recall: 0.2162 - val_loss: 0.6633 - val_binary_accuracy: 0.5738 - val_precision: 0.6067 - val_recall: 0.1824\n",
      "Epoch 352/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6633 - binary_accuracy: 0.5738 - precision: 0.6067 - recall: 0.1824 - val_loss: 0.6625 - val_binary_accuracy: 0.5754 - val_precision: 0.6667 - val_recall: 0.1351\n",
      "Epoch 353/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6625 - binary_accuracy: 0.5754 - precision: 0.6667 - recall: 0.1351 - val_loss: 0.6633 - val_binary_accuracy: 0.5877 - val_precision: 0.7917 - val_recall: 0.1284\n",
      "Epoch 354/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6633 - binary_accuracy: 0.5877 - precision: 0.7917 - recall: 0.1284 - val_loss: 0.6622 - val_binary_accuracy: 0.5831 - val_precision: 0.7451 - val_recall: 0.1284\n",
      "Epoch 355/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6622 - binary_accuracy: 0.5831 - precision: 0.7451 - recall: 0.1284 - val_loss: 0.6610 - val_binary_accuracy: 0.5677 - val_precision: 0.6027 - val_recall: 0.1486\n",
      "Epoch 356/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6610 - binary_accuracy: 0.5677 - precision: 0.6027 - recall: 0.1486 - val_loss: 0.6613 - val_binary_accuracy: 0.5708 - val_precision: 0.5825 - val_recall: 0.2027\n",
      "Epoch 357/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6613 - binary_accuracy: 0.5708 - precision: 0.5825 - recall: 0.2027 - val_loss: 0.6610 - val_binary_accuracy: 0.5677 - val_precision: 0.5701 - val_recall: 0.2061\n",
      "Epoch 358/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6610 - binary_accuracy: 0.5677 - precision: 0.5701 - recall: 0.2061 - val_loss: 0.6602 - val_binary_accuracy: 0.5769 - val_precision: 0.6400 - val_recall: 0.1622\n",
      "Epoch 359/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6602 - binary_accuracy: 0.5769 - precision: 0.6400 - recall: 0.1622 - val_loss: 0.6599 - val_binary_accuracy: 0.5800 - val_precision: 0.7018 - val_recall: 0.1351\n",
      "Epoch 360/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6599 - binary_accuracy: 0.5800 - precision: 0.7018 - recall: 0.1351 - val_loss: 0.6601 - val_binary_accuracy: 0.5738 - val_precision: 0.6610 - val_recall: 0.1318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.6601 - binary_accuracy: 0.5738 - precision: 0.6610 - recall: 0.1318 - val_loss: 0.6592 - val_binary_accuracy: 0.5754 - val_precision: 0.6515 - val_recall: 0.1453\n",
      "Epoch 362/900\n",
      "650/650 [==============================] - 0s 164us/sample - loss: 0.6592 - binary_accuracy: 0.5754 - precision: 0.6515 - recall: 0.1453 - val_loss: 0.6589 - val_binary_accuracy: 0.5723 - val_precision: 0.6098 - val_recall: 0.1689\n",
      "Epoch 363/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6589 - binary_accuracy: 0.5723 - precision: 0.6098 - recall: 0.1689 - val_loss: 0.6588 - val_binary_accuracy: 0.5723 - val_precision: 0.5918 - val_recall: 0.1959\n",
      "Epoch 364/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.6588 - binary_accuracy: 0.5723 - precision: 0.5918 - recall: 0.1959 - val_loss: 0.6584 - val_binary_accuracy: 0.5677 - val_precision: 0.5862 - val_recall: 0.1723\n",
      "Epoch 365/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6584 - binary_accuracy: 0.5677 - precision: 0.5862 - recall: 0.1723 - val_loss: 0.6578 - val_binary_accuracy: 0.5785 - val_precision: 0.6719 - val_recall: 0.1453\n",
      "Epoch 366/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6578 - binary_accuracy: 0.5785 - precision: 0.6719 - recall: 0.1453 - val_loss: 0.6578 - val_binary_accuracy: 0.5800 - val_precision: 0.6825 - val_recall: 0.1453\n",
      "Epoch 367/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6578 - binary_accuracy: 0.5800 - precision: 0.6825 - recall: 0.1453 - val_loss: 0.6573 - val_binary_accuracy: 0.5785 - val_precision: 0.6719 - val_recall: 0.1453\n",
      "Epoch 368/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6573 - binary_accuracy: 0.5785 - precision: 0.6719 - recall: 0.1453 - val_loss: 0.6569 - val_binary_accuracy: 0.5708 - val_precision: 0.6232 - val_recall: 0.1453\n",
      "Epoch 369/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6569 - binary_accuracy: 0.5708 - precision: 0.6232 - recall: 0.1453 - val_loss: 0.6567 - val_binary_accuracy: 0.5754 - val_precision: 0.6163 - val_recall: 0.1791\n",
      "Epoch 370/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6567 - binary_accuracy: 0.5754 - precision: 0.6163 - recall: 0.1791 - val_loss: 0.6562 - val_binary_accuracy: 0.5785 - val_precision: 0.6250 - val_recall: 0.1858\n",
      "Epoch 371/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6562 - binary_accuracy: 0.5785 - precision: 0.6250 - recall: 0.1858 - val_loss: 0.6557 - val_binary_accuracy: 0.5785 - val_precision: 0.6486 - val_recall: 0.1622\n",
      "Epoch 372/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6557 - binary_accuracy: 0.5785 - precision: 0.6486 - recall: 0.1622 - val_loss: 0.6554 - val_binary_accuracy: 0.5785 - val_precision: 0.6667 - val_recall: 0.1486\n",
      "Epoch 373/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6554 - binary_accuracy: 0.5785 - precision: 0.6667 - recall: 0.1486 - val_loss: 0.6551 - val_binary_accuracy: 0.5785 - val_precision: 0.6486 - val_recall: 0.1622\n",
      "Epoch 374/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6551 - binary_accuracy: 0.5785 - precision: 0.6486 - recall: 0.1622 - val_loss: 0.6546 - val_binary_accuracy: 0.5785 - val_precision: 0.6375 - val_recall: 0.1723\n",
      "Epoch 375/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6546 - binary_accuracy: 0.5785 - precision: 0.6375 - recall: 0.1723 - val_loss: 0.6543 - val_binary_accuracy: 0.5800 - val_precision: 0.6264 - val_recall: 0.1926\n",
      "Epoch 376/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6543 - binary_accuracy: 0.5800 - precision: 0.6264 - recall: 0.1926 - val_loss: 0.6540 - val_binary_accuracy: 0.5800 - val_precision: 0.6264 - val_recall: 0.1926\n",
      "Epoch 377/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6540 - binary_accuracy: 0.5800 - precision: 0.6264 - recall: 0.1926 - val_loss: 0.6537 - val_binary_accuracy: 0.5800 - val_precision: 0.6533 - val_recall: 0.1655\n",
      "Epoch 378/900\n",
      "650/650 [==============================] - 0s 164us/sample - loss: 0.6537 - binary_accuracy: 0.5800 - precision: 0.6533 - recall: 0.1655 - val_loss: 0.6533 - val_binary_accuracy: 0.5738 - val_precision: 0.6338 - val_recall: 0.1520\n",
      "Epoch 379/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.6533 - binary_accuracy: 0.5738 - precision: 0.6338 - recall: 0.1520 - val_loss: 0.6530 - val_binary_accuracy: 0.5815 - val_precision: 0.6463 - val_recall: 0.1791\n",
      "Epoch 380/900\n",
      "650/650 [==============================] - 0s 149us/sample - loss: 0.6530 - binary_accuracy: 0.5815 - precision: 0.6463 - recall: 0.1791 - val_loss: 0.6528 - val_binary_accuracy: 0.5800 - val_precision: 0.6353 - val_recall: 0.1824\n",
      "Epoch 381/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6528 - binary_accuracy: 0.5800 - precision: 0.6353 - recall: 0.1824 - val_loss: 0.6525 - val_binary_accuracy: 0.5769 - val_precision: 0.6207 - val_recall: 0.1824\n",
      "Epoch 382/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6525 - binary_accuracy: 0.5769 - precision: 0.6207 - recall: 0.1824 - val_loss: 0.6522 - val_binary_accuracy: 0.5723 - val_precision: 0.6286 - val_recall: 0.1486\n",
      "Epoch 383/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6522 - binary_accuracy: 0.5723 - precision: 0.6286 - recall: 0.1486 - val_loss: 0.6519 - val_binary_accuracy: 0.5723 - val_precision: 0.6286 - val_recall: 0.1486\n",
      "Epoch 384/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6519 - binary_accuracy: 0.5723 - precision: 0.6286 - recall: 0.1486 - val_loss: 0.6515 - val_binary_accuracy: 0.5769 - val_precision: 0.6207 - val_recall: 0.1824\n",
      "Epoch 385/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6515 - binary_accuracy: 0.5769 - precision: 0.6207 - recall: 0.1824 - val_loss: 0.6513 - val_binary_accuracy: 0.5800 - val_precision: 0.6264 - val_recall: 0.1926\n",
      "Epoch 386/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6513 - binary_accuracy: 0.5800 - precision: 0.6264 - recall: 0.1926 - val_loss: 0.6511 - val_binary_accuracy: 0.5846 - val_precision: 0.6300 - val_recall: 0.2128\n",
      "Epoch 387/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6511 - binary_accuracy: 0.5846 - precision: 0.6300 - recall: 0.2128 - val_loss: 0.6511 - val_binary_accuracy: 0.5815 - val_precision: 0.6622 - val_recall: 0.1655\n",
      "Epoch 388/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6511 - binary_accuracy: 0.5815 - precision: 0.6622 - recall: 0.1655 - val_loss: 0.6529 - val_binary_accuracy: 0.5769 - val_precision: 0.5981 - val_recall: 0.2162\n",
      "Epoch 389/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6529 - binary_accuracy: 0.5769 - precision: 0.5981 - recall: 0.2162 - val_loss: 0.6619 - val_binary_accuracy: 0.5646 - val_precision: 0.5783 - val_recall: 0.1622\n",
      "Epoch 390/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6619 - binary_accuracy: 0.5646 - precision: 0.5783 - recall: 0.1622 - val_loss: 0.6787 - val_binary_accuracy: 0.5462 - val_precision: 0.5021 - val_recall: 0.4122\n",
      "Epoch 391/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6787 - binary_accuracy: 0.5462 - precision: 0.5021 - recall: 0.4122 - val_loss: 0.6927 - val_binary_accuracy: 0.5415 - val_precision: 0.4762 - val_recall: 0.0676\n",
      "Epoch 392/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6927 - binary_accuracy: 0.5415 - precision: 0.4762 - recall: 0.0676 - val_loss: 0.6963 - val_binary_accuracy: 0.5508 - val_precision: 0.7500 - val_recall: 0.0203\n",
      "Epoch 393/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6963 - binary_accuracy: 0.5508 - precision: 0.7500 - recall: 0.0203 - val_loss: 0.6831 - val_binary_accuracy: 0.5800 - val_precision: 0.7949 - val_recall: 0.1047\n",
      "Epoch 394/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6831 - binary_accuracy: 0.5800 - precision: 0.7949 - recall: 0.1047 - val_loss: 0.6784 - val_binary_accuracy: 0.5569 - val_precision: 0.5217 - val_recall: 0.3243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6784 - binary_accuracy: 0.5569 - precision: 0.5217 - recall: 0.3243 - val_loss: 0.6788 - val_binary_accuracy: 0.5738 - val_precision: 0.5503 - val_recall: 0.3514\n",
      "Epoch 396/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6788 - binary_accuracy: 0.5738 - precision: 0.5503 - recall: 0.3514 - val_loss: 0.6749 - val_binary_accuracy: 0.5877 - val_precision: 0.7333 - val_recall: 0.1486\n",
      "Epoch 397/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6749 - binary_accuracy: 0.5877 - precision: 0.7333 - recall: 0.1486 - val_loss: 0.6740 - val_binary_accuracy: 0.5785 - val_precision: 0.6833 - val_recall: 0.1385\n",
      "Epoch 398/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6740 - binary_accuracy: 0.5785 - precision: 0.6833 - recall: 0.1385 - val_loss: 0.6740 - val_binary_accuracy: 0.5754 - val_precision: 0.6562 - val_recall: 0.1419\n",
      "Epoch 399/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6740 - binary_accuracy: 0.5754 - precision: 0.6562 - recall: 0.1419 - val_loss: 0.6725 - val_binary_accuracy: 0.5785 - val_precision: 0.6833 - val_recall: 0.1385\n",
      "Epoch 400/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6725 - binary_accuracy: 0.5785 - precision: 0.6833 - recall: 0.1385 - val_loss: 0.6701 - val_binary_accuracy: 0.5831 - val_precision: 0.7119 - val_recall: 0.1419\n",
      "Epoch 401/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6701 - binary_accuracy: 0.5831 - precision: 0.7119 - recall: 0.1419 - val_loss: 0.6686 - val_binary_accuracy: 0.5831 - val_precision: 0.6667 - val_recall: 0.1689\n",
      "Epoch 402/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6686 - binary_accuracy: 0.5831 - precision: 0.6667 - recall: 0.1689 - val_loss: 0.6680 - val_binary_accuracy: 0.5708 - val_precision: 0.5876 - val_recall: 0.1926\n",
      "Epoch 403/900\n",
      "650/650 [==============================] - 0s 165us/sample - loss: 0.6680 - binary_accuracy: 0.5708 - precision: 0.5876 - recall: 0.1926 - val_loss: 0.6683 - val_binary_accuracy: 0.5785 - val_precision: 0.6078 - val_recall: 0.2095\n",
      "Epoch 404/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.6683 - binary_accuracy: 0.5785 - precision: 0.6078 - recall: 0.2095 - val_loss: 0.6670 - val_binary_accuracy: 0.5615 - val_precision: 0.5679 - val_recall: 0.1554\n",
      "Epoch 405/900\n",
      "650/650 [==============================] - 0s 164us/sample - loss: 0.6670 - binary_accuracy: 0.5615 - precision: 0.5679 - recall: 0.1554 - val_loss: 0.6653 - val_binary_accuracy: 0.5815 - val_precision: 0.6818 - val_recall: 0.1520\n",
      "Epoch 406/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6653 - binary_accuracy: 0.5815 - precision: 0.6818 - recall: 0.1520 - val_loss: 0.6679 - val_binary_accuracy: 0.5831 - val_precision: 0.6623 - val_recall: 0.1723\n",
      "Epoch 407/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6679 - binary_accuracy: 0.5831 - precision: 0.6623 - recall: 0.1723 - val_loss: 0.6659 - val_binary_accuracy: 0.5785 - val_precision: 0.6571 - val_recall: 0.1554\n",
      "Epoch 408/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6659 - binary_accuracy: 0.5785 - precision: 0.6571 - recall: 0.1554 - val_loss: 0.6667 - val_binary_accuracy: 0.5615 - val_precision: 0.5632 - val_recall: 0.1655\n",
      "Epoch 409/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6667 - binary_accuracy: 0.5615 - precision: 0.5632 - recall: 0.1655 - val_loss: 0.6649 - val_binary_accuracy: 0.5662 - val_precision: 0.5686 - val_recall: 0.1959\n",
      "Epoch 410/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6649 - binary_accuracy: 0.5662 - precision: 0.5686 - recall: 0.1959 - val_loss: 0.6649 - val_binary_accuracy: 0.5677 - val_precision: 0.5610 - val_recall: 0.2331\n",
      "Epoch 411/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6649 - binary_accuracy: 0.5677 - precision: 0.5610 - recall: 0.2331 - val_loss: 0.6651 - val_binary_accuracy: 0.5954 - val_precision: 0.5873 - val_recall: 0.3750\n",
      "Epoch 412/900\n",
      "650/650 [==============================] - 0s 149us/sample - loss: 0.6651 - binary_accuracy: 0.5954 - precision: 0.5873 - recall: 0.3750 - val_loss: 0.6627 - val_binary_accuracy: 0.5754 - val_precision: 0.5909 - val_recall: 0.2196\n",
      "Epoch 413/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6627 - binary_accuracy: 0.5754 - precision: 0.5909 - recall: 0.2196 - val_loss: 0.6627 - val_binary_accuracy: 0.5769 - val_precision: 0.6105 - val_recall: 0.1959\n",
      "Epoch 414/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6627 - binary_accuracy: 0.5769 - precision: 0.6105 - recall: 0.1959 - val_loss: 0.6629 - val_binary_accuracy: 0.5585 - val_precision: 0.5366 - val_recall: 0.2230\n",
      "Epoch 415/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6629 - binary_accuracy: 0.5585 - precision: 0.5366 - recall: 0.2230 - val_loss: 0.6616 - val_binary_accuracy: 0.5738 - val_precision: 0.6044 - val_recall: 0.1858\n",
      "Epoch 416/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6616 - binary_accuracy: 0.5738 - precision: 0.6044 - recall: 0.1858 - val_loss: 0.6631 - val_binary_accuracy: 0.5815 - val_precision: 0.6395 - val_recall: 0.1858\n",
      "Epoch 417/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6631 - binary_accuracy: 0.5815 - precision: 0.6395 - recall: 0.1858 - val_loss: 0.6617 - val_binary_accuracy: 0.5862 - val_precision: 0.5860 - val_recall: 0.3108\n",
      "Epoch 418/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6617 - binary_accuracy: 0.5862 - precision: 0.5860 - recall: 0.3108 - val_loss: 0.6601 - val_binary_accuracy: 0.5738 - val_precision: 0.5922 - val_recall: 0.2061\n",
      "Epoch 419/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6601 - binary_accuracy: 0.5738 - precision: 0.5922 - recall: 0.2061 - val_loss: 0.6608 - val_binary_accuracy: 0.5785 - val_precision: 0.6100 - val_recall: 0.2061\n",
      "Epoch 420/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.6608 - binary_accuracy: 0.5785 - precision: 0.6100 - recall: 0.2061 - val_loss: 0.6605 - val_binary_accuracy: 0.5892 - val_precision: 0.5819 - val_recall: 0.3480\n",
      "Epoch 421/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6605 - binary_accuracy: 0.5892 - precision: 0.5819 - recall: 0.3480 - val_loss: 0.6582 - val_binary_accuracy: 0.5662 - val_precision: 0.5714 - val_recall: 0.1892\n",
      "Epoch 422/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6582 - binary_accuracy: 0.5662 - precision: 0.5714 - recall: 0.1892 - val_loss: 0.6580 - val_binary_accuracy: 0.5754 - val_precision: 0.6163 - val_recall: 0.1791\n",
      "Epoch 423/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6580 - binary_accuracy: 0.5754 - precision: 0.6163 - recall: 0.1791 - val_loss: 0.6581 - val_binary_accuracy: 0.5646 - val_precision: 0.5489 - val_recall: 0.2466\n",
      "Epoch 424/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6581 - binary_accuracy: 0.5646 - precision: 0.5489 - recall: 0.2466 - val_loss: 0.6569 - val_binary_accuracy: 0.5662 - val_precision: 0.5875 - val_recall: 0.1588\n",
      "Epoch 425/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6569 - binary_accuracy: 0.5662 - precision: 0.5875 - recall: 0.1588 - val_loss: 0.6560 - val_binary_accuracy: 0.5723 - val_precision: 0.6098 - val_recall: 0.1689\n",
      "Epoch 426/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6560 - binary_accuracy: 0.5723 - precision: 0.6098 - recall: 0.1689 - val_loss: 0.6558 - val_binary_accuracy: 0.5754 - val_precision: 0.5746 - val_recall: 0.2601\n",
      "Epoch 427/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6558 - binary_accuracy: 0.5754 - precision: 0.5746 - recall: 0.2601 - val_loss: 0.6563 - val_binary_accuracy: 0.5692 - val_precision: 0.5889 - val_recall: 0.1791\n",
      "Epoch 428/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6563 - binary_accuracy: 0.5692 - precision: 0.5889 - recall: 0.1791 - val_loss: 0.6549 - val_binary_accuracy: 0.5862 - val_precision: 0.5860 - val_recall: 0.3108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6549 - binary_accuracy: 0.5862 - precision: 0.5860 - recall: 0.3108 - val_loss: 0.6545 - val_binary_accuracy: 0.5708 - val_precision: 0.5934 - val_recall: 0.1824\n",
      "Epoch 430/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6545 - binary_accuracy: 0.5708 - precision: 0.5934 - recall: 0.1824 - val_loss: 0.6536 - val_binary_accuracy: 0.5800 - val_precision: 0.5935 - val_recall: 0.2466\n",
      "Epoch 431/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6536 - binary_accuracy: 0.5800 - precision: 0.5935 - recall: 0.2466 - val_loss: 0.6532 - val_binary_accuracy: 0.5800 - val_precision: 0.5891 - val_recall: 0.2568\n",
      "Epoch 432/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6532 - binary_accuracy: 0.5800 - precision: 0.5891 - recall: 0.2568 - val_loss: 0.6532 - val_binary_accuracy: 0.5708 - val_precision: 0.5914 - val_recall: 0.1858\n",
      "Epoch 433/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6532 - binary_accuracy: 0.5708 - precision: 0.5914 - recall: 0.1858 - val_loss: 0.6531 - val_binary_accuracy: 0.5985 - val_precision: 0.6115 - val_recall: 0.3243\n",
      "Epoch 434/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6531 - binary_accuracy: 0.5985 - precision: 0.6115 - recall: 0.3243 - val_loss: 0.6533 - val_binary_accuracy: 0.5754 - val_precision: 0.6190 - val_recall: 0.1757\n",
      "Epoch 435/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6533 - binary_accuracy: 0.5754 - precision: 0.6190 - recall: 0.1757 - val_loss: 0.6527 - val_binary_accuracy: 0.6046 - val_precision: 0.6383 - val_recall: 0.3041\n",
      "Epoch 436/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6527 - binary_accuracy: 0.6046 - precision: 0.6383 - recall: 0.3041 - val_loss: 0.6518 - val_binary_accuracy: 0.5800 - val_precision: 0.6667 - val_recall: 0.1554\n",
      "Epoch 437/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6518 - binary_accuracy: 0.5800 - precision: 0.6667 - recall: 0.1554 - val_loss: 0.6510 - val_binary_accuracy: 0.5785 - val_precision: 0.6310 - val_recall: 0.1791\n",
      "Epoch 438/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6510 - binary_accuracy: 0.5785 - precision: 0.6310 - recall: 0.1791 - val_loss: 0.6514 - val_binary_accuracy: 0.5985 - val_precision: 0.6207 - val_recall: 0.3041\n",
      "Epoch 439/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6514 - binary_accuracy: 0.5985 - precision: 0.6207 - recall: 0.3041 - val_loss: 0.6520 - val_binary_accuracy: 0.5738 - val_precision: 0.6173 - val_recall: 0.1689\n",
      "Epoch 440/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6520 - binary_accuracy: 0.5738 - precision: 0.6173 - recall: 0.1689 - val_loss: 0.6516 - val_binary_accuracy: 0.6062 - val_precision: 0.6333 - val_recall: 0.3209\n",
      "Epoch 441/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6516 - binary_accuracy: 0.6062 - precision: 0.6333 - recall: 0.3209 - val_loss: 0.6510 - val_binary_accuracy: 0.5815 - val_precision: 0.6714 - val_recall: 0.1588\n",
      "Epoch 442/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6510 - binary_accuracy: 0.5815 - precision: 0.6714 - recall: 0.1588 - val_loss: 0.6501 - val_binary_accuracy: 0.5846 - val_precision: 0.6548 - val_recall: 0.1858\n",
      "Epoch 443/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6501 - binary_accuracy: 0.5846 - precision: 0.6548 - recall: 0.1858 - val_loss: 0.6508 - val_binary_accuracy: 0.6062 - val_precision: 0.6266 - val_recall: 0.3345\n",
      "Epoch 444/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6508 - binary_accuracy: 0.6062 - precision: 0.6266 - recall: 0.3345 - val_loss: 0.6536 - val_binary_accuracy: 0.5754 - val_precision: 0.6282 - val_recall: 0.1655\n",
      "Epoch 445/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6536 - binary_accuracy: 0.5754 - precision: 0.6282 - recall: 0.1655 - val_loss: 0.6563 - val_binary_accuracy: 0.5723 - val_precision: 0.5385 - val_recall: 0.4257\n",
      "Epoch 446/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6563 - binary_accuracy: 0.5723 - precision: 0.5385 - recall: 0.4257 - val_loss: 0.6547 - val_binary_accuracy: 0.5862 - val_precision: 0.7547 - val_recall: 0.1351\n",
      "Epoch 447/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6547 - binary_accuracy: 0.5862 - precision: 0.7547 - recall: 0.1351 - val_loss: 0.6507 - val_binary_accuracy: 0.5846 - val_precision: 0.7407 - val_recall: 0.1351\n",
      "Epoch 448/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6507 - binary_accuracy: 0.5846 - precision: 0.7407 - recall: 0.1351 - val_loss: 0.6570 - val_binary_accuracy: 0.5708 - val_precision: 0.5365 - val_recall: 0.4223\n",
      "Epoch 449/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6570 - binary_accuracy: 0.5708 - precision: 0.5365 - recall: 0.4223 - val_loss: 0.6507 - val_binary_accuracy: 0.5800 - val_precision: 0.6667 - val_recall: 0.1554\n",
      "Epoch 450/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6507 - binary_accuracy: 0.5800 - precision: 0.6667 - recall: 0.1554 - val_loss: 0.6512 - val_binary_accuracy: 0.5800 - val_precision: 0.6620 - val_recall: 0.1588\n",
      "Epoch 451/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6512 - binary_accuracy: 0.5800 - precision: 0.6620 - recall: 0.1588 - val_loss: 0.6530 - val_binary_accuracy: 0.6000 - val_precision: 0.6023 - val_recall: 0.3581\n",
      "Epoch 452/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6530 - binary_accuracy: 0.6000 - precision: 0.6023 - recall: 0.3581 - val_loss: 0.6489 - val_binary_accuracy: 0.5831 - val_precision: 0.6506 - val_recall: 0.1824\n",
      "Epoch 453/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6489 - binary_accuracy: 0.5831 - precision: 0.6506 - recall: 0.1824 - val_loss: 0.6526 - val_binary_accuracy: 0.5892 - val_precision: 0.7544 - val_recall: 0.1453\n",
      "Epoch 454/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6526 - binary_accuracy: 0.5892 - precision: 0.7544 - recall: 0.1453 - val_loss: 0.6481 - val_binary_accuracy: 0.5800 - val_precision: 0.6575 - val_recall: 0.1622\n",
      "Epoch 455/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6481 - binary_accuracy: 0.5800 - precision: 0.6575 - recall: 0.1622 - val_loss: 0.6514 - val_binary_accuracy: 0.6000 - val_precision: 0.6071 - val_recall: 0.3446\n",
      "Epoch 456/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6514 - binary_accuracy: 0.6000 - precision: 0.6071 - recall: 0.3446 - val_loss: 0.6481 - val_binary_accuracy: 0.5754 - val_precision: 0.6316 - val_recall: 0.1622\n",
      "Epoch 457/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6481 - binary_accuracy: 0.5754 - precision: 0.6316 - recall: 0.1622 - val_loss: 0.6489 - val_binary_accuracy: 0.5862 - val_precision: 0.6800 - val_recall: 0.1723\n",
      "Epoch 458/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6489 - binary_accuracy: 0.5862 - precision: 0.6800 - recall: 0.1723 - val_loss: 0.6495 - val_binary_accuracy: 0.5969 - val_precision: 0.5977 - val_recall: 0.3514\n",
      "Epoch 459/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6495 - binary_accuracy: 0.5969 - precision: 0.5977 - recall: 0.3514 - val_loss: 0.6464 - val_binary_accuracy: 0.5877 - val_precision: 0.6667 - val_recall: 0.1892\n",
      "Epoch 460/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6464 - binary_accuracy: 0.5877 - precision: 0.6667 - recall: 0.1892 - val_loss: 0.6482 - val_binary_accuracy: 0.5908 - val_precision: 0.7344 - val_recall: 0.1588\n",
      "Epoch 461/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6482 - binary_accuracy: 0.5908 - precision: 0.7344 - recall: 0.1588 - val_loss: 0.6470 - val_binary_accuracy: 0.6062 - val_precision: 0.6266 - val_recall: 0.3345\n",
      "Epoch 462/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6470 - binary_accuracy: 0.6062 - precision: 0.6266 - recall: 0.3345 - val_loss: 0.6450 - val_binary_accuracy: 0.5954 - val_precision: 0.6514 - val_recall: 0.2399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6450 - binary_accuracy: 0.5954 - precision: 0.6514 - recall: 0.2399 - val_loss: 0.6462 - val_binary_accuracy: 0.5862 - val_precision: 0.6667 - val_recall: 0.1824\n",
      "Epoch 464/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6462 - binary_accuracy: 0.5862 - precision: 0.6667 - recall: 0.1824 - val_loss: 0.6479 - val_binary_accuracy: 0.5908 - val_precision: 0.5758 - val_recall: 0.3851\n",
      "Epoch 465/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6479 - binary_accuracy: 0.5908 - precision: 0.5758 - recall: 0.3851 - val_loss: 0.6493 - val_binary_accuracy: 0.5908 - val_precision: 0.7500 - val_recall: 0.1520\n",
      "Epoch 466/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6493 - binary_accuracy: 0.5908 - precision: 0.7500 - recall: 0.1520 - val_loss: 0.6441 - val_binary_accuracy: 0.5985 - val_precision: 0.6259 - val_recall: 0.2939\n",
      "Epoch 467/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6441 - binary_accuracy: 0.5985 - precision: 0.6259 - recall: 0.2939 - val_loss: 0.6433 - val_binary_accuracy: 0.6031 - val_precision: 0.6418 - val_recall: 0.2905\n",
      "Epoch 468/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6433 - binary_accuracy: 0.6031 - precision: 0.6418 - recall: 0.2905 - val_loss: 0.6464 - val_binary_accuracy: 0.5923 - val_precision: 0.7246 - val_recall: 0.1689\n",
      "Epoch 469/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.6464 - binary_accuracy: 0.5923 - precision: 0.7246 - recall: 0.1689 - val_loss: 0.6455 - val_binary_accuracy: 0.5985 - val_precision: 0.5862 - val_recall: 0.4020\n",
      "Epoch 470/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6455 - binary_accuracy: 0.5985 - precision: 0.5862 - recall: 0.4020 - val_loss: 0.6450 - val_binary_accuracy: 0.5908 - val_precision: 0.7273 - val_recall: 0.1622\n",
      "Epoch 471/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.6450 - binary_accuracy: 0.5908 - precision: 0.7273 - recall: 0.1622 - val_loss: 0.6413 - val_binary_accuracy: 0.6077 - val_precision: 0.6589 - val_recall: 0.2872\n",
      "Epoch 472/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6413 - binary_accuracy: 0.6077 - precision: 0.6589 - recall: 0.2872 - val_loss: 0.6404 - val_binary_accuracy: 0.6031 - val_precision: 0.6557 - val_recall: 0.2703\n",
      "Epoch 473/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6404 - binary_accuracy: 0.6031 - precision: 0.6557 - recall: 0.2703 - val_loss: 0.6422 - val_binary_accuracy: 0.5954 - val_precision: 0.7324 - val_recall: 0.1757\n",
      "Epoch 474/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6422 - binary_accuracy: 0.5954 - precision: 0.7324 - recall: 0.1757 - val_loss: 0.6505 - val_binary_accuracy: 0.5877 - val_precision: 0.5515 - val_recall: 0.5068\n",
      "Epoch 475/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6505 - binary_accuracy: 0.5877 - precision: 0.5515 - recall: 0.5068 - val_loss: 0.6707 - val_binary_accuracy: 0.5738 - val_precision: 0.6203 - val_recall: 0.1655\n",
      "Epoch 476/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6707 - binary_accuracy: 0.5738 - precision: 0.6203 - recall: 0.1655 - val_loss: 0.6576 - val_binary_accuracy: 0.5892 - val_precision: 0.8718 - val_recall: 0.1149\n",
      "Epoch 477/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6576 - binary_accuracy: 0.5892 - precision: 0.8718 - recall: 0.1149 - val_loss: 0.6564 - val_binary_accuracy: 0.5954 - val_precision: 0.9459 - val_recall: 0.1182\n",
      "Epoch 478/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6564 - binary_accuracy: 0.5954 - precision: 0.9459 - recall: 0.1182 - val_loss: 0.6623 - val_binary_accuracy: 0.5677 - val_precision: 0.5330 - val_recall: 0.4088\n",
      "Epoch 479/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6623 - binary_accuracy: 0.5677 - precision: 0.5330 - recall: 0.4088 - val_loss: 0.6628 - val_binary_accuracy: 0.5677 - val_precision: 0.5342 - val_recall: 0.3953\n",
      "Epoch 480/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6628 - binary_accuracy: 0.5677 - precision: 0.5342 - recall: 0.3953 - val_loss: 0.6581 - val_binary_accuracy: 0.5831 - val_precision: 0.7907 - val_recall: 0.1149\n",
      "Epoch 481/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6581 - binary_accuracy: 0.5831 - precision: 0.7907 - recall: 0.1149 - val_loss: 0.6558 - val_binary_accuracy: 0.5892 - val_precision: 0.9143 - val_recall: 0.1081\n",
      "Epoch 482/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6558 - binary_accuracy: 0.5892 - precision: 0.9143 - recall: 0.1081 - val_loss: 0.6506 - val_binary_accuracy: 0.5908 - val_precision: 0.8750 - val_recall: 0.1182\n",
      "Epoch 483/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.6506 - binary_accuracy: 0.5908 - precision: 0.8750 - recall: 0.1182 - val_loss: 0.6472 - val_binary_accuracy: 0.5938 - val_precision: 0.8077 - val_recall: 0.1419\n",
      "Epoch 484/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.6472 - binary_accuracy: 0.5938 - precision: 0.8077 - recall: 0.1419 - val_loss: 0.6642 - val_binary_accuracy: 0.5785 - val_precision: 0.5948 - val_recall: 0.2331\n",
      "Epoch 485/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6642 - binary_accuracy: 0.5785 - precision: 0.5948 - recall: 0.2331 - val_loss: 0.6742 - val_binary_accuracy: 0.5569 - val_precision: 0.5123 - val_recall: 0.5642\n",
      "Epoch 486/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6742 - binary_accuracy: 0.5569 - precision: 0.5123 - recall: 0.5642 - val_loss: 0.6479 - val_binary_accuracy: 0.6062 - val_precision: 0.6471 - val_recall: 0.2973\n",
      "Epoch 487/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6479 - binary_accuracy: 0.6062 - precision: 0.6471 - recall: 0.2973 - val_loss: 0.6554 - val_binary_accuracy: 0.5892 - val_precision: 0.7959 - val_recall: 0.1318\n",
      "Epoch 488/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6554 - binary_accuracy: 0.5892 - precision: 0.7959 - recall: 0.1318 - val_loss: 0.6572 - val_binary_accuracy: 0.5815 - val_precision: 0.7609 - val_recall: 0.1182\n",
      "Epoch 489/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6572 - binary_accuracy: 0.5815 - precision: 0.7609 - recall: 0.1182 - val_loss: 0.6515 - val_binary_accuracy: 0.5923 - val_precision: 0.8444 - val_recall: 0.1284\n",
      "Epoch 490/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6515 - binary_accuracy: 0.5923 - precision: 0.8444 - recall: 0.1284 - val_loss: 0.6503 - val_binary_accuracy: 0.6000 - val_precision: 0.7432 - val_recall: 0.1858\n",
      "Epoch 491/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.6503 - binary_accuracy: 0.6000 - precision: 0.7432 - recall: 0.1858 - val_loss: 0.6506 - val_binary_accuracy: 0.6015 - val_precision: 0.6135 - val_recall: 0.3378\n",
      "Epoch 492/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6506 - binary_accuracy: 0.6015 - precision: 0.6135 - recall: 0.3378 - val_loss: 0.6518 - val_binary_accuracy: 0.5908 - val_precision: 0.5758 - val_recall: 0.3851\n",
      "Epoch 493/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6518 - binary_accuracy: 0.5908 - precision: 0.5758 - recall: 0.3851 - val_loss: 0.6508 - val_binary_accuracy: 0.6031 - val_precision: 0.5913 - val_recall: 0.4155\n",
      "Epoch 494/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.6508 - binary_accuracy: 0.6031 - precision: 0.5913 - recall: 0.4155 - val_loss: 0.6479 - val_binary_accuracy: 0.5908 - val_precision: 0.5652 - val_recall: 0.4392\n",
      "Epoch 495/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6479 - binary_accuracy: 0.5908 - precision: 0.5652 - recall: 0.4392 - val_loss: 0.6449 - val_binary_accuracy: 0.6169 - val_precision: 0.6391 - val_recall: 0.3649\n",
      "Epoch 496/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6449 - binary_accuracy: 0.6169 - precision: 0.6391 - recall: 0.3649 - val_loss: 0.6437 - val_binary_accuracy: 0.5862 - val_precision: 0.6627 - val_recall: 0.1858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6437 - binary_accuracy: 0.5862 - precision: 0.6627 - recall: 0.1858 - val_loss: 0.6440 - val_binary_accuracy: 0.5985 - val_precision: 0.7869 - val_recall: 0.1622\n",
      "Epoch 498/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6440 - binary_accuracy: 0.5985 - precision: 0.7869 - recall: 0.1622 - val_loss: 0.6440 - val_binary_accuracy: 0.6031 - val_precision: 0.7375 - val_recall: 0.1993\n",
      "Epoch 499/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.6440 - binary_accuracy: 0.6031 - precision: 0.7375 - recall: 0.1993 - val_loss: 0.6432 - val_binary_accuracy: 0.6123 - val_precision: 0.7157 - val_recall: 0.2466\n",
      "Epoch 500/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6432 - binary_accuracy: 0.6123 - precision: 0.7157 - recall: 0.2466 - val_loss: 0.6412 - val_binary_accuracy: 0.6077 - val_precision: 0.7253 - val_recall: 0.2230\n",
      "Epoch 501/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.6412 - binary_accuracy: 0.6077 - precision: 0.7253 - recall: 0.2230 - val_loss: 0.6404 - val_binary_accuracy: 0.6077 - val_precision: 0.6990 - val_recall: 0.2432\n",
      "Epoch 502/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6404 - binary_accuracy: 0.6077 - precision: 0.6990 - recall: 0.2432 - val_loss: 0.6394 - val_binary_accuracy: 0.6262 - val_precision: 0.6587 - val_recall: 0.3716\n",
      "Epoch 503/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6394 - binary_accuracy: 0.6262 - precision: 0.6587 - recall: 0.3716 - val_loss: 0.6372 - val_binary_accuracy: 0.6046 - val_precision: 0.6585 - val_recall: 0.2736\n",
      "Epoch 504/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6372 - binary_accuracy: 0.6046 - precision: 0.6585 - recall: 0.2736 - val_loss: 0.6357 - val_binary_accuracy: 0.6108 - val_precision: 0.6807 - val_recall: 0.2736\n",
      "Epoch 505/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6357 - binary_accuracy: 0.6108 - precision: 0.6807 - recall: 0.2736 - val_loss: 0.6352 - val_binary_accuracy: 0.6092 - val_precision: 0.6479 - val_recall: 0.3108\n",
      "Epoch 506/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6352 - binary_accuracy: 0.6092 - precision: 0.6479 - recall: 0.3108 - val_loss: 0.6346 - val_binary_accuracy: 0.6092 - val_precision: 0.6641 - val_recall: 0.2872\n",
      "Epoch 507/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6346 - binary_accuracy: 0.6092 - precision: 0.6641 - recall: 0.2872 - val_loss: 0.6337 - val_binary_accuracy: 0.6138 - val_precision: 0.6667 - val_recall: 0.3041\n",
      "Epoch 508/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6337 - binary_accuracy: 0.6138 - precision: 0.6667 - recall: 0.3041 - val_loss: 0.6328 - val_binary_accuracy: 0.6092 - val_precision: 0.6346 - val_recall: 0.3345\n",
      "Epoch 509/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6328 - binary_accuracy: 0.6092 - precision: 0.6346 - recall: 0.3345 - val_loss: 0.6330 - val_binary_accuracy: 0.6169 - val_precision: 0.6850 - val_recall: 0.2939\n",
      "Epoch 510/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6330 - binary_accuracy: 0.6169 - precision: 0.6850 - recall: 0.2939 - val_loss: 0.6312 - val_binary_accuracy: 0.6138 - val_precision: 0.6301 - val_recall: 0.3682\n",
      "Epoch 511/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6312 - binary_accuracy: 0.6138 - precision: 0.6301 - recall: 0.3682 - val_loss: 0.6354 - val_binary_accuracy: 0.6031 - val_precision: 0.6979 - val_recall: 0.2264\n",
      "Epoch 512/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6354 - binary_accuracy: 0.6031 - precision: 0.6979 - recall: 0.2264 - val_loss: 0.6527 - val_binary_accuracy: 0.5754 - val_precision: 0.5355 - val_recall: 0.5101\n",
      "Epoch 513/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6527 - binary_accuracy: 0.5754 - precision: 0.5355 - recall: 0.5101 - val_loss: 0.6929 - val_binary_accuracy: 0.5692 - val_precision: 0.5816 - val_recall: 0.1926\n",
      "Epoch 514/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6929 - binary_accuracy: 0.5692 - precision: 0.5816 - recall: 0.1926 - val_loss: 0.6658 - val_binary_accuracy: 0.5800 - val_precision: 0.6949 - val_recall: 0.1385\n",
      "Epoch 515/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.6658 - binary_accuracy: 0.5800 - precision: 0.6949 - recall: 0.1385 - val_loss: 0.6633 - val_binary_accuracy: 0.5892 - val_precision: 0.9394 - val_recall: 0.1047\n",
      "Epoch 516/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6633 - binary_accuracy: 0.5892 - precision: 0.9394 - recall: 0.1047 - val_loss: 0.6661 - val_binary_accuracy: 0.5862 - val_precision: 0.9091 - val_recall: 0.1014\n",
      "Epoch 517/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6661 - binary_accuracy: 0.5862 - precision: 0.9091 - recall: 0.1014 - val_loss: 0.6623 - val_binary_accuracy: 0.5862 - val_precision: 0.9355 - val_recall: 0.0980\n",
      "Epoch 518/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.6623 - binary_accuracy: 0.5862 - precision: 0.9355 - recall: 0.0980 - val_loss: 0.6591 - val_binary_accuracy: 0.5954 - val_precision: 0.9459 - val_recall: 0.1182\n",
      "Epoch 519/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6591 - binary_accuracy: 0.5954 - precision: 0.9459 - recall: 0.1182 - val_loss: 0.6549 - val_binary_accuracy: 0.5985 - val_precision: 0.7108 - val_recall: 0.1993\n",
      "Epoch 520/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6549 - binary_accuracy: 0.5985 - precision: 0.7108 - recall: 0.1993 - val_loss: 0.6506 - val_binary_accuracy: 0.5954 - val_precision: 0.5912 - val_recall: 0.3615\n",
      "Epoch 521/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6506 - binary_accuracy: 0.5954 - precision: 0.5912 - recall: 0.3615 - val_loss: 0.6546 - val_binary_accuracy: 0.6092 - val_precision: 0.6082 - val_recall: 0.3986\n",
      "Epoch 522/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6546 - binary_accuracy: 0.6092 - precision: 0.6082 - recall: 0.3986 - val_loss: 0.6462 - val_binary_accuracy: 0.5954 - val_precision: 0.5721 - val_recall: 0.4426\n",
      "Epoch 523/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6462 - binary_accuracy: 0.5954 - precision: 0.5721 - recall: 0.4426 - val_loss: 0.6439 - val_binary_accuracy: 0.5938 - val_precision: 0.5714 - val_recall: 0.4324\n",
      "Epoch 524/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6439 - binary_accuracy: 0.5938 - precision: 0.5714 - recall: 0.4324 - val_loss: 0.6384 - val_binary_accuracy: 0.6154 - val_precision: 0.7396 - val_recall: 0.2399\n",
      "Epoch 525/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6384 - binary_accuracy: 0.6154 - precision: 0.7396 - recall: 0.2399 - val_loss: 0.6426 - val_binary_accuracy: 0.6046 - val_precision: 0.8545 - val_recall: 0.1588\n",
      "Epoch 526/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6426 - binary_accuracy: 0.6046 - precision: 0.8545 - recall: 0.1588 - val_loss: 0.6429 - val_binary_accuracy: 0.6031 - val_precision: 0.8519 - val_recall: 0.1554\n",
      "Epoch 527/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6429 - binary_accuracy: 0.6031 - precision: 0.8519 - recall: 0.1554 - val_loss: 0.6375 - val_binary_accuracy: 0.6108 - val_precision: 0.7945 - val_recall: 0.1959\n",
      "Epoch 528/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6375 - binary_accuracy: 0.6108 - precision: 0.7945 - recall: 0.1959 - val_loss: 0.6369 - val_binary_accuracy: 0.6169 - val_precision: 0.6621 - val_recall: 0.3243\n",
      "Epoch 529/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6369 - binary_accuracy: 0.6169 - precision: 0.6621 - recall: 0.3243 - val_loss: 0.6332 - val_binary_accuracy: 0.6200 - val_precision: 0.6788 - val_recall: 0.3142\n",
      "Epoch 530/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6332 - binary_accuracy: 0.6200 - precision: 0.6788 - recall: 0.3142 - val_loss: 0.6352 - val_binary_accuracy: 0.6185 - val_precision: 0.6935 - val_recall: 0.2905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 531/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6352 - binary_accuracy: 0.6185 - precision: 0.6935 - recall: 0.2905 - val_loss: 0.6337 - val_binary_accuracy: 0.6215 - val_precision: 0.6603 - val_recall: 0.3480\n",
      "Epoch 532/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6337 - binary_accuracy: 0.6215 - precision: 0.6603 - recall: 0.3480 - val_loss: 0.6344 - val_binary_accuracy: 0.6231 - val_precision: 0.6409 - val_recall: 0.3919\n",
      "Epoch 533/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6344 - binary_accuracy: 0.6231 - precision: 0.6409 - recall: 0.3919 - val_loss: 0.6319 - val_binary_accuracy: 0.6246 - val_precision: 0.6912 - val_recall: 0.3176\n",
      "Epoch 534/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6319 - binary_accuracy: 0.6246 - precision: 0.6912 - recall: 0.3176 - val_loss: 0.6326 - val_binary_accuracy: 0.6231 - val_precision: 0.7297 - val_recall: 0.2736\n",
      "Epoch 535/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6326 - binary_accuracy: 0.6231 - precision: 0.7297 - recall: 0.2736 - val_loss: 0.6308 - val_binary_accuracy: 0.6185 - val_precision: 0.7000 - val_recall: 0.2838\n",
      "Epoch 536/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6308 - binary_accuracy: 0.6185 - precision: 0.7000 - recall: 0.2838 - val_loss: 0.6319 - val_binary_accuracy: 0.6308 - val_precision: 0.6818 - val_recall: 0.3547\n",
      "Epoch 537/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6319 - binary_accuracy: 0.6308 - precision: 0.6818 - recall: 0.3547 - val_loss: 0.6291 - val_binary_accuracy: 0.6231 - val_precision: 0.7040 - val_recall: 0.2973\n",
      "Epoch 538/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6291 - binary_accuracy: 0.6231 - precision: 0.7040 - recall: 0.2973 - val_loss: 0.6292 - val_binary_accuracy: 0.6231 - val_precision: 0.7073 - val_recall: 0.2939\n",
      "Epoch 539/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6292 - binary_accuracy: 0.6231 - precision: 0.7073 - recall: 0.2939 - val_loss: 0.6279 - val_binary_accuracy: 0.6323 - val_precision: 0.6629 - val_recall: 0.3919\n",
      "Epoch 540/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6279 - binary_accuracy: 0.6323 - precision: 0.6629 - recall: 0.3919 - val_loss: 0.6262 - val_binary_accuracy: 0.6246 - val_precision: 0.6605 - val_recall: 0.3615\n",
      "Epoch 541/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6262 - binary_accuracy: 0.6246 - precision: 0.6605 - recall: 0.3615 - val_loss: 0.6255 - val_binary_accuracy: 0.6338 - val_precision: 0.7231 - val_recall: 0.3176\n",
      "Epoch 542/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6255 - binary_accuracy: 0.6338 - precision: 0.7231 - recall: 0.3176 - val_loss: 0.6238 - val_binary_accuracy: 0.6354 - val_precision: 0.7185 - val_recall: 0.3277\n",
      "Epoch 543/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6238 - binary_accuracy: 0.6354 - precision: 0.7185 - recall: 0.3277 - val_loss: 0.6239 - val_binary_accuracy: 0.6277 - val_precision: 0.6667 - val_recall: 0.3649\n",
      "Epoch 544/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.6239 - binary_accuracy: 0.6277 - precision: 0.6667 - recall: 0.3649 - val_loss: 0.6221 - val_binary_accuracy: 0.6292 - val_precision: 0.7099 - val_recall: 0.3142\n",
      "Epoch 545/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6221 - binary_accuracy: 0.6292 - precision: 0.7099 - recall: 0.3142 - val_loss: 0.6211 - val_binary_accuracy: 0.6323 - val_precision: 0.7317 - val_recall: 0.3041\n",
      "Epoch 546/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6211 - binary_accuracy: 0.6323 - precision: 0.7317 - recall: 0.3041 - val_loss: 0.6200 - val_binary_accuracy: 0.6354 - val_precision: 0.6903 - val_recall: 0.3615\n",
      "Epoch 547/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6200 - binary_accuracy: 0.6354 - precision: 0.6903 - recall: 0.3615 - val_loss: 0.6189 - val_binary_accuracy: 0.6446 - val_precision: 0.7559 - val_recall: 0.3243\n",
      "Epoch 548/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6189 - binary_accuracy: 0.6446 - precision: 0.7559 - recall: 0.3243 - val_loss: 0.6174 - val_binary_accuracy: 0.6308 - val_precision: 0.6918 - val_recall: 0.3412\n",
      "Epoch 549/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6174 - binary_accuracy: 0.6308 - precision: 0.6918 - recall: 0.3412 - val_loss: 0.6160 - val_binary_accuracy: 0.6323 - val_precision: 0.6913 - val_recall: 0.3480\n",
      "Epoch 550/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6160 - binary_accuracy: 0.6323 - precision: 0.6913 - recall: 0.3480 - val_loss: 0.6158 - val_binary_accuracy: 0.6385 - val_precision: 0.7607 - val_recall: 0.3007\n",
      "Epoch 551/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6158 - binary_accuracy: 0.6385 - precision: 0.7607 - recall: 0.3007 - val_loss: 0.6152 - val_binary_accuracy: 0.6369 - val_precision: 0.6899 - val_recall: 0.3682\n",
      "Epoch 552/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6152 - binary_accuracy: 0.6369 - precision: 0.6899 - recall: 0.3682 - val_loss: 0.6151 - val_binary_accuracy: 0.6415 - val_precision: 0.7788 - val_recall: 0.2973\n",
      "Epoch 553/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6151 - binary_accuracy: 0.6415 - precision: 0.7788 - recall: 0.2973 - val_loss: 0.6138 - val_binary_accuracy: 0.6246 - val_precision: 0.6461 - val_recall: 0.3885\n",
      "Epoch 554/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6138 - binary_accuracy: 0.6246 - precision: 0.6461 - recall: 0.3885 - val_loss: 0.6177 - val_binary_accuracy: 0.6338 - val_precision: 0.7636 - val_recall: 0.2838\n",
      "Epoch 555/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6177 - binary_accuracy: 0.6338 - precision: 0.7636 - recall: 0.2838 - val_loss: 0.6190 - val_binary_accuracy: 0.6262 - val_precision: 0.6293 - val_recall: 0.4358\n",
      "Epoch 556/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6190 - binary_accuracy: 0.6262 - precision: 0.6293 - recall: 0.4358 - val_loss: 0.6492 - val_binary_accuracy: 0.6000 - val_precision: 0.7093 - val_recall: 0.2061\n",
      "Epoch 557/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6492 - binary_accuracy: 0.6000 - precision: 0.7093 - recall: 0.2061 - val_loss: 0.6429 - val_binary_accuracy: 0.6092 - val_precision: 0.7917 - val_recall: 0.1926\n",
      "Epoch 558/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6429 - binary_accuracy: 0.6092 - precision: 0.7917 - recall: 0.1926 - val_loss: 0.6288 - val_binary_accuracy: 0.6246 - val_precision: 0.7407 - val_recall: 0.2703\n",
      "Epoch 559/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6288 - binary_accuracy: 0.6246 - precision: 0.7407 - recall: 0.2703 - val_loss: 0.6522 - val_binary_accuracy: 0.5538 - val_precision: 0.5110 - val_recall: 0.4696\n",
      "Epoch 560/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6522 - binary_accuracy: 0.5538 - precision: 0.5110 - recall: 0.4696 - val_loss: 0.6255 - val_binary_accuracy: 0.6123 - val_precision: 0.7895 - val_recall: 0.2027\n",
      "Epoch 561/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6255 - binary_accuracy: 0.6123 - precision: 0.7895 - recall: 0.2027 - val_loss: 0.6374 - val_binary_accuracy: 0.6169 - val_precision: 0.7374 - val_recall: 0.2466\n",
      "Epoch 562/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6374 - binary_accuracy: 0.6169 - precision: 0.7374 - recall: 0.2466 - val_loss: 0.6290 - val_binary_accuracy: 0.6154 - val_precision: 0.7674 - val_recall: 0.2230\n",
      "Epoch 563/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6290 - binary_accuracy: 0.6154 - precision: 0.7674 - recall: 0.2230 - val_loss: 0.6102 - val_binary_accuracy: 0.6262 - val_precision: 0.7431 - val_recall: 0.2736\n",
      "Epoch 564/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6102 - binary_accuracy: 0.6262 - precision: 0.7431 - recall: 0.2736 - val_loss: 0.6484 - val_binary_accuracy: 0.5877 - val_precision: 0.5680 - val_recall: 0.3953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6484 - binary_accuracy: 0.5877 - precision: 0.5680 - recall: 0.3953 - val_loss: 0.6289 - val_binary_accuracy: 0.6138 - val_precision: 0.7103 - val_recall: 0.2568\n",
      "Epoch 566/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6289 - binary_accuracy: 0.6138 - precision: 0.7103 - recall: 0.2568 - val_loss: 0.6136 - val_binary_accuracy: 0.6431 - val_precision: 0.9324 - val_recall: 0.2331\n",
      "Epoch 567/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6136 - binary_accuracy: 0.6431 - precision: 0.9324 - recall: 0.2331 - val_loss: 0.6166 - val_binary_accuracy: 0.6292 - val_precision: 0.8986 - val_recall: 0.2095\n",
      "Epoch 568/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6166 - binary_accuracy: 0.6292 - precision: 0.8986 - recall: 0.2095 - val_loss: 0.6249 - val_binary_accuracy: 0.6231 - val_precision: 0.8923 - val_recall: 0.1959\n",
      "Epoch 569/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.6249 - binary_accuracy: 0.6231 - precision: 0.8923 - recall: 0.1959 - val_loss: 0.6117 - val_binary_accuracy: 0.6292 - val_precision: 0.8767 - val_recall: 0.2162\n",
      "Epoch 570/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6117 - binary_accuracy: 0.6292 - precision: 0.8767 - recall: 0.2162 - val_loss: 0.6072 - val_binary_accuracy: 0.6431 - val_precision: 0.8333 - val_recall: 0.2703\n",
      "Epoch 571/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.6072 - binary_accuracy: 0.6431 - precision: 0.8333 - recall: 0.2703 - val_loss: 0.6077 - val_binary_accuracy: 0.6215 - val_precision: 0.6736 - val_recall: 0.3277\n",
      "Epoch 572/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6077 - binary_accuracy: 0.6215 - precision: 0.6736 - recall: 0.3277 - val_loss: 0.6097 - val_binary_accuracy: 0.6369 - val_precision: 0.6485 - val_recall: 0.4426\n",
      "Epoch 573/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6097 - binary_accuracy: 0.6369 - precision: 0.6485 - recall: 0.4426 - val_loss: 0.5999 - val_binary_accuracy: 0.6354 - val_precision: 0.6595 - val_recall: 0.4122\n",
      "Epoch 574/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5999 - binary_accuracy: 0.6354 - precision: 0.6595 - recall: 0.4122 - val_loss: 0.5994 - val_binary_accuracy: 0.6569 - val_precision: 0.7355 - val_recall: 0.3851\n",
      "Epoch 575/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.5994 - binary_accuracy: 0.6569 - precision: 0.7355 - recall: 0.3851 - val_loss: 0.5935 - val_binary_accuracy: 0.6431 - val_precision: 0.7222 - val_recall: 0.3514\n",
      "Epoch 576/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.5935 - binary_accuracy: 0.6431 - precision: 0.7222 - recall: 0.3514 - val_loss: 0.5938 - val_binary_accuracy: 0.6446 - val_precision: 0.7372 - val_recall: 0.3412\n",
      "Epoch 577/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.5938 - binary_accuracy: 0.6446 - precision: 0.7372 - recall: 0.3412 - val_loss: 0.5916 - val_binary_accuracy: 0.6431 - val_precision: 0.7424 - val_recall: 0.3311\n",
      "Epoch 578/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.5916 - binary_accuracy: 0.6431 - precision: 0.7424 - recall: 0.3311 - val_loss: 0.5893 - val_binary_accuracy: 0.6385 - val_precision: 0.7480 - val_recall: 0.3108\n",
      "Epoch 579/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.5893 - binary_accuracy: 0.6385 - precision: 0.7480 - recall: 0.3108 - val_loss: 0.5875 - val_binary_accuracy: 0.6492 - val_precision: 0.7073 - val_recall: 0.3919\n",
      "Epoch 580/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.5875 - binary_accuracy: 0.6492 - precision: 0.7073 - recall: 0.3919 - val_loss: 0.5886 - val_binary_accuracy: 0.6523 - val_precision: 0.6768 - val_recall: 0.4527\n",
      "Epoch 581/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.5886 - binary_accuracy: 0.6523 - precision: 0.6768 - recall: 0.4527 - val_loss: 0.5824 - val_binary_accuracy: 0.6354 - val_precision: 0.6311 - val_recall: 0.4797\n",
      "Epoch 582/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.5824 - binary_accuracy: 0.6354 - precision: 0.6311 - recall: 0.4797 - val_loss: 0.5858 - val_binary_accuracy: 0.6400 - val_precision: 0.6615 - val_recall: 0.4291\n",
      "Epoch 583/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.5858 - binary_accuracy: 0.6400 - precision: 0.6615 - recall: 0.4291 - val_loss: 0.5790 - val_binary_accuracy: 0.6554 - val_precision: 0.6714 - val_recall: 0.4764\n",
      "Epoch 584/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5790 - binary_accuracy: 0.6554 - precision: 0.6714 - recall: 0.4764 - val_loss: 0.5803 - val_binary_accuracy: 0.6431 - val_precision: 0.6280 - val_recall: 0.5304\n",
      "Epoch 585/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5803 - binary_accuracy: 0.6431 - precision: 0.6280 - recall: 0.5304 - val_loss: 0.5814 - val_binary_accuracy: 0.6600 - val_precision: 0.7419 - val_recall: 0.3885\n",
      "Epoch 586/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5814 - binary_accuracy: 0.6600 - precision: 0.7419 - recall: 0.3885 - val_loss: 0.5723 - val_binary_accuracy: 0.6400 - val_precision: 0.6598 - val_recall: 0.4324\n",
      "Epoch 587/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5723 - binary_accuracy: 0.6400 - precision: 0.6598 - recall: 0.4324 - val_loss: 0.5772 - val_binary_accuracy: 0.6600 - val_precision: 0.6271 - val_recall: 0.6250\n",
      "Epoch 588/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5772 - binary_accuracy: 0.6600 - precision: 0.6271 - recall: 0.6250 - val_loss: 0.5670 - val_binary_accuracy: 0.6462 - val_precision: 0.6241 - val_recall: 0.5608\n",
      "Epoch 589/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.5670 - binary_accuracy: 0.6462 - precision: 0.6241 - recall: 0.5608 - val_loss: 0.5812 - val_binary_accuracy: 0.6369 - val_precision: 0.6786 - val_recall: 0.3851\n",
      "Epoch 590/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5812 - binary_accuracy: 0.6369 - precision: 0.6786 - recall: 0.3851 - val_loss: 0.5897 - val_binary_accuracy: 0.6446 - val_precision: 0.6836 - val_recall: 0.4088\n",
      "Epoch 591/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5897 - binary_accuracy: 0.6446 - precision: 0.6836 - recall: 0.4088 - val_loss: 0.6308 - val_binary_accuracy: 0.6277 - val_precision: 0.5860 - val_recall: 0.6216\n",
      "Epoch 592/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6308 - binary_accuracy: 0.6277 - precision: 0.5860 - recall: 0.6216 - val_loss: 0.6527 - val_binary_accuracy: 0.6015 - val_precision: 0.6947 - val_recall: 0.2230\n",
      "Epoch 593/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6527 - binary_accuracy: 0.6015 - precision: 0.6947 - recall: 0.2230 - val_loss: 0.6344 - val_binary_accuracy: 0.6077 - val_precision: 0.7253 - val_recall: 0.2230\n",
      "Epoch 594/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6344 - binary_accuracy: 0.6077 - precision: 0.7253 - recall: 0.2230 - val_loss: 0.6242 - val_binary_accuracy: 0.6354 - val_precision: 0.6497 - val_recall: 0.4324\n",
      "Epoch 595/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6242 - binary_accuracy: 0.6354 - precision: 0.6497 - recall: 0.4324 - val_loss: 0.6326 - val_binary_accuracy: 0.6369 - val_precision: 0.6079 - val_recall: 0.5709\n",
      "Epoch 596/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6326 - binary_accuracy: 0.6369 - precision: 0.6079 - recall: 0.5709 - val_loss: 0.6207 - val_binary_accuracy: 0.6569 - val_precision: 0.6229 - val_recall: 0.6250\n",
      "Epoch 597/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6207 - binary_accuracy: 0.6569 - precision: 0.6229 - recall: 0.6250 - val_loss: 0.6202 - val_binary_accuracy: 0.6492 - val_precision: 0.6241 - val_recall: 0.5777\n",
      "Epoch 598/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.6202 - binary_accuracy: 0.6492 - precision: 0.6241 - recall: 0.5777 - val_loss: 0.6201 - val_binary_accuracy: 0.6400 - val_precision: 0.6115 - val_recall: 0.5743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.6201 - binary_accuracy: 0.6400 - precision: 0.6115 - recall: 0.5743 - val_loss: 0.6068 - val_binary_accuracy: 0.6492 - val_precision: 0.6269 - val_recall: 0.5676\n",
      "Epoch 600/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.6068 - binary_accuracy: 0.6492 - precision: 0.6269 - recall: 0.5676 - val_loss: 0.6077 - val_binary_accuracy: 0.6338 - val_precision: 0.6074 - val_recall: 0.5541\n",
      "Epoch 601/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.6077 - binary_accuracy: 0.6338 - precision: 0.6074 - recall: 0.5541 - val_loss: 0.6060 - val_binary_accuracy: 0.6508 - val_precision: 0.6273 - val_recall: 0.5743\n",
      "Epoch 602/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6060 - binary_accuracy: 0.6508 - precision: 0.6273 - recall: 0.5743 - val_loss: 0.6008 - val_binary_accuracy: 0.6323 - val_precision: 0.6135 - val_recall: 0.5203\n",
      "Epoch 603/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.6008 - binary_accuracy: 0.6323 - precision: 0.6135 - recall: 0.5203 - val_loss: 0.6001 - val_binary_accuracy: 0.6123 - val_precision: 0.6000 - val_recall: 0.4459\n",
      "Epoch 604/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6001 - binary_accuracy: 0.6123 - precision: 0.6000 - recall: 0.4459 - val_loss: 0.5981 - val_binary_accuracy: 0.6046 - val_precision: 0.6242 - val_recall: 0.3311\n",
      "Epoch 605/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5981 - binary_accuracy: 0.6046 - precision: 0.6242 - recall: 0.3311 - val_loss: 0.5945 - val_binary_accuracy: 0.5985 - val_precision: 0.6159 - val_recall: 0.3142\n",
      "Epoch 606/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5945 - binary_accuracy: 0.5985 - precision: 0.6159 - recall: 0.3142 - val_loss: 0.5896 - val_binary_accuracy: 0.6415 - val_precision: 0.6493 - val_recall: 0.4628\n",
      "Epoch 607/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.5896 - binary_accuracy: 0.6415 - precision: 0.6493 - recall: 0.4628 - val_loss: 0.5872 - val_binary_accuracy: 0.6446 - val_precision: 0.6360 - val_recall: 0.5135\n",
      "Epoch 608/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.5872 - binary_accuracy: 0.6446 - precision: 0.6360 - recall: 0.5135 - val_loss: 0.5835 - val_binary_accuracy: 0.6600 - val_precision: 0.6448 - val_recall: 0.5642\n",
      "Epoch 609/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5835 - binary_accuracy: 0.6600 - precision: 0.6448 - recall: 0.5642 - val_loss: 0.5773 - val_binary_accuracy: 0.6492 - val_precision: 0.6269 - val_recall: 0.5676\n",
      "Epoch 610/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.5773 - binary_accuracy: 0.6492 - precision: 0.6269 - recall: 0.5676 - val_loss: 0.5742 - val_binary_accuracy: 0.6415 - val_precision: 0.6226 - val_recall: 0.5405\n",
      "Epoch 611/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.5742 - binary_accuracy: 0.6415 - precision: 0.6226 - recall: 0.5405 - val_loss: 0.5705 - val_binary_accuracy: 0.6385 - val_precision: 0.6151 - val_recall: 0.5507\n",
      "Epoch 612/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5705 - binary_accuracy: 0.6385 - precision: 0.6151 - recall: 0.5507 - val_loss: 0.5687 - val_binary_accuracy: 0.6569 - val_precision: 0.6263 - val_recall: 0.6115\n",
      "Epoch 613/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5687 - binary_accuracy: 0.6569 - precision: 0.6263 - recall: 0.6115 - val_loss: 0.5638 - val_binary_accuracy: 0.6585 - val_precision: 0.6225 - val_recall: 0.6351\n",
      "Epoch 614/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5638 - binary_accuracy: 0.6585 - precision: 0.6225 - recall: 0.6351 - val_loss: 0.5623 - val_binary_accuracy: 0.6815 - val_precision: 0.6488 - val_recall: 0.6554\n",
      "Epoch 615/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5623 - binary_accuracy: 0.6815 - precision: 0.6488 - recall: 0.6554 - val_loss: 0.5571 - val_binary_accuracy: 0.6646 - val_precision: 0.6309 - val_recall: 0.6351\n",
      "Epoch 616/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5571 - binary_accuracy: 0.6646 - precision: 0.6309 - recall: 0.6351 - val_loss: 0.5551 - val_binary_accuracy: 0.6692 - val_precision: 0.6392 - val_recall: 0.6284\n",
      "Epoch 617/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5551 - binary_accuracy: 0.6692 - precision: 0.6392 - recall: 0.6284 - val_loss: 0.5527 - val_binary_accuracy: 0.6908 - val_precision: 0.6599 - val_recall: 0.6622\n",
      "Epoch 618/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5527 - binary_accuracy: 0.6908 - precision: 0.6599 - recall: 0.6622 - val_loss: 0.5483 - val_binary_accuracy: 0.6769 - val_precision: 0.6424 - val_recall: 0.6554\n",
      "Epoch 619/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5483 - binary_accuracy: 0.6769 - precision: 0.6424 - recall: 0.6554 - val_loss: 0.5467 - val_binary_accuracy: 0.6815 - val_precision: 0.6584 - val_recall: 0.6250\n",
      "Epoch 620/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5467 - binary_accuracy: 0.6815 - precision: 0.6584 - recall: 0.6250 - val_loss: 0.5432 - val_binary_accuracy: 0.6831 - val_precision: 0.6596 - val_recall: 0.6284\n",
      "Epoch 621/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5432 - binary_accuracy: 0.6831 - precision: 0.6596 - recall: 0.6284 - val_loss: 0.5384 - val_binary_accuracy: 0.6846 - val_precision: 0.6522 - val_recall: 0.6588\n",
      "Epoch 622/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5384 - binary_accuracy: 0.6846 - precision: 0.6522 - recall: 0.6588 - val_loss: 0.5360 - val_binary_accuracy: 0.6877 - val_precision: 0.6620 - val_recall: 0.6419\n",
      "Epoch 623/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.5360 - binary_accuracy: 0.6877 - precision: 0.6620 - recall: 0.6419 - val_loss: 0.5320 - val_binary_accuracy: 0.7015 - val_precision: 0.6747 - val_recall: 0.6655\n",
      "Epoch 624/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5320 - binary_accuracy: 0.7015 - precision: 0.6747 - recall: 0.6655 - val_loss: 0.5279 - val_binary_accuracy: 0.6985 - val_precision: 0.6603 - val_recall: 0.6959\n",
      "Epoch 625/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5279 - binary_accuracy: 0.6985 - precision: 0.6603 - recall: 0.6959 - val_loss: 0.5252 - val_binary_accuracy: 0.6985 - val_precision: 0.6773 - val_recall: 0.6453\n",
      "Epoch 626/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5252 - binary_accuracy: 0.6985 - precision: 0.6773 - recall: 0.6453 - val_loss: 0.5223 - val_binary_accuracy: 0.7015 - val_precision: 0.6614 - val_recall: 0.7061\n",
      "Epoch 627/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5223 - binary_accuracy: 0.7015 - precision: 0.6614 - recall: 0.7061 - val_loss: 0.5181 - val_binary_accuracy: 0.7138 - val_precision: 0.7200 - val_recall: 0.6081\n",
      "Epoch 628/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.5181 - binary_accuracy: 0.7138 - precision: 0.7200 - recall: 0.6081 - val_loss: 0.5141 - val_binary_accuracy: 0.7169 - val_precision: 0.6830 - val_recall: 0.7061\n",
      "Epoch 629/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5141 - binary_accuracy: 0.7169 - precision: 0.6830 - recall: 0.7061 - val_loss: 0.5095 - val_binary_accuracy: 0.7138 - val_precision: 0.7099 - val_recall: 0.6284\n",
      "Epoch 630/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.5095 - binary_accuracy: 0.7138 - precision: 0.7099 - recall: 0.6284 - val_loss: 0.5074 - val_binary_accuracy: 0.7108 - val_precision: 0.6667 - val_recall: 0.7297\n",
      "Epoch 631/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5074 - binary_accuracy: 0.7108 - precision: 0.6667 - recall: 0.7297 - val_loss: 0.5103 - val_binary_accuracy: 0.7154 - val_precision: 0.7817 - val_recall: 0.5203\n",
      "Epoch 632/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5103 - binary_accuracy: 0.7154 - precision: 0.7817 - recall: 0.5203 - val_loss: 0.5588 - val_binary_accuracy: 0.6769 - val_precision: 0.5964 - val_recall: 0.8986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5588 - binary_accuracy: 0.6769 - precision: 0.5964 - recall: 0.8986 - val_loss: 0.6146 - val_binary_accuracy: 0.6600 - val_precision: 0.6923 - val_recall: 0.4561\n",
      "Epoch 634/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.6146 - binary_accuracy: 0.6600 - precision: 0.6923 - recall: 0.4561 - val_loss: 0.6028 - val_binary_accuracy: 0.6369 - val_precision: 0.6648 - val_recall: 0.4088\n",
      "Epoch 635/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.6028 - binary_accuracy: 0.6369 - precision: 0.6648 - recall: 0.4088 - val_loss: 0.5909 - val_binary_accuracy: 0.6262 - val_precision: 0.5917 - val_recall: 0.5777\n",
      "Epoch 636/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5909 - binary_accuracy: 0.6262 - precision: 0.5917 - recall: 0.5777 - val_loss: 0.6125 - val_binary_accuracy: 0.6323 - val_precision: 0.6014 - val_recall: 0.5709\n",
      "Epoch 637/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.6125 - binary_accuracy: 0.6323 - precision: 0.6014 - recall: 0.5709 - val_loss: 0.5634 - val_binary_accuracy: 0.6708 - val_precision: 0.6952 - val_recall: 0.4932\n",
      "Epoch 638/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.5634 - binary_accuracy: 0.6708 - precision: 0.6952 - recall: 0.4932 - val_loss: 0.5784 - val_binary_accuracy: 0.6600 - val_precision: 0.7095 - val_recall: 0.4291\n",
      "Epoch 639/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5784 - binary_accuracy: 0.6600 - precision: 0.7095 - recall: 0.4291 - val_loss: 0.5600 - val_binary_accuracy: 0.7015 - val_precision: 0.7161 - val_recall: 0.5709\n",
      "Epoch 640/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5600 - binary_accuracy: 0.7015 - precision: 0.7161 - recall: 0.5709 - val_loss: 0.5860 - val_binary_accuracy: 0.6969 - val_precision: 0.7089 - val_recall: 0.5676\n",
      "Epoch 641/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.5860 - binary_accuracy: 0.6969 - precision: 0.7089 - recall: 0.5676 - val_loss: 0.5525 - val_binary_accuracy: 0.6938 - val_precision: 0.7046 - val_recall: 0.5642\n",
      "Epoch 642/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.5525 - binary_accuracy: 0.6938 - precision: 0.7046 - recall: 0.5642 - val_loss: 0.5266 - val_binary_accuracy: 0.7277 - val_precision: 0.7820 - val_recall: 0.5574\n",
      "Epoch 643/900\n",
      "650/650 [==============================] - 0s 162us/sample - loss: 0.5266 - binary_accuracy: 0.7277 - precision: 0.7820 - recall: 0.5574 - val_loss: 0.5414 - val_binary_accuracy: 0.7308 - val_precision: 0.7763 - val_recall: 0.5743\n",
      "Epoch 644/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.5414 - binary_accuracy: 0.7308 - precision: 0.7763 - recall: 0.5743 - val_loss: 0.5383 - val_binary_accuracy: 0.7031 - val_precision: 0.6988 - val_recall: 0.6115\n",
      "Epoch 645/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.5383 - binary_accuracy: 0.7031 - precision: 0.6988 - recall: 0.6115 - val_loss: 0.5228 - val_binary_accuracy: 0.7215 - val_precision: 0.6936 - val_recall: 0.6959\n",
      "Epoch 646/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.5228 - binary_accuracy: 0.7215 - precision: 0.6936 - recall: 0.6959 - val_loss: 0.5157 - val_binary_accuracy: 0.7215 - val_precision: 0.7309 - val_recall: 0.6149\n",
      "Epoch 647/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.5157 - binary_accuracy: 0.7215 - precision: 0.7309 - recall: 0.6149 - val_loss: 0.5084 - val_binary_accuracy: 0.7277 - val_precision: 0.7390 - val_recall: 0.6216\n",
      "Epoch 648/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.5084 - binary_accuracy: 0.7277 - precision: 0.7390 - recall: 0.6216 - val_loss: 0.5050 - val_binary_accuracy: 0.7277 - val_precision: 0.7228 - val_recall: 0.6520\n",
      "Epoch 649/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.5050 - binary_accuracy: 0.7277 - precision: 0.7228 - recall: 0.6520 - val_loss: 0.5032 - val_binary_accuracy: 0.7323 - val_precision: 0.6943 - val_recall: 0.7365\n",
      "Epoch 650/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.5032 - binary_accuracy: 0.7323 - precision: 0.6943 - recall: 0.7365 - val_loss: 0.4888 - val_binary_accuracy: 0.7585 - val_precision: 0.7324 - val_recall: 0.7399\n",
      "Epoch 651/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4888 - binary_accuracy: 0.7585 - precision: 0.7324 - recall: 0.7399 - val_loss: 0.4956 - val_binary_accuracy: 0.7462 - val_precision: 0.7631 - val_recall: 0.6419\n",
      "Epoch 652/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.4956 - binary_accuracy: 0.7462 - precision: 0.7631 - recall: 0.6419 - val_loss: 0.4843 - val_binary_accuracy: 0.7662 - val_precision: 0.7590 - val_recall: 0.7128\n",
      "Epoch 653/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.4843 - binary_accuracy: 0.7662 - precision: 0.7590 - recall: 0.7128 - val_loss: 0.4812 - val_binary_accuracy: 0.7538 - val_precision: 0.7615 - val_recall: 0.6689\n",
      "Epoch 654/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.4812 - binary_accuracy: 0.7538 - precision: 0.7615 - recall: 0.6689 - val_loss: 0.4849 - val_binary_accuracy: 0.7600 - val_precision: 0.7632 - val_recall: 0.6858\n",
      "Epoch 655/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.4849 - binary_accuracy: 0.7600 - precision: 0.7632 - recall: 0.6858 - val_loss: 0.4726 - val_binary_accuracy: 0.7508 - val_precision: 0.7376 - val_recall: 0.7027\n",
      "Epoch 656/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4726 - binary_accuracy: 0.7508 - precision: 0.7376 - recall: 0.7027 - val_loss: 0.4709 - val_binary_accuracy: 0.7708 - val_precision: 0.8155 - val_recall: 0.6419\n",
      "Epoch 657/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4709 - binary_accuracy: 0.7708 - precision: 0.8155 - recall: 0.6419 - val_loss: 0.4853 - val_binary_accuracy: 0.7400 - val_precision: 0.7343 - val_recall: 0.6723\n",
      "Epoch 658/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4853 - binary_accuracy: 0.7400 - precision: 0.7343 - recall: 0.6723 - val_loss: 0.4643 - val_binary_accuracy: 0.7831 - val_precision: 0.7627 - val_recall: 0.7601\n",
      "Epoch 659/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.4643 - binary_accuracy: 0.7831 - precision: 0.7627 - recall: 0.7601 - val_loss: 0.4649 - val_binary_accuracy: 0.7585 - val_precision: 0.7791 - val_recall: 0.6554\n",
      "Epoch 660/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.4649 - binary_accuracy: 0.7585 - precision: 0.7791 - recall: 0.6554 - val_loss: 0.4861 - val_binary_accuracy: 0.7431 - val_precision: 0.7768 - val_recall: 0.6115\n",
      "Epoch 661/900\n",
      "650/650 [==============================] - 0s 158us/sample - loss: 0.4861 - binary_accuracy: 0.7431 - precision: 0.7768 - recall: 0.6115 - val_loss: 0.4740 - val_binary_accuracy: 0.7600 - val_precision: 0.7482 - val_recall: 0.7128\n",
      "Epoch 662/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.4740 - binary_accuracy: 0.7600 - precision: 0.7482 - recall: 0.7128 - val_loss: 0.4813 - val_binary_accuracy: 0.7354 - val_precision: 0.6802 - val_recall: 0.7905\n",
      "Epoch 663/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4813 - binary_accuracy: 0.7354 - precision: 0.6802 - recall: 0.7905 - val_loss: 0.5091 - val_binary_accuracy: 0.7092 - val_precision: 0.9213 - val_recall: 0.3953\n",
      "Epoch 664/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.5091 - binary_accuracy: 0.7092 - precision: 0.9213 - recall: 0.3953 - val_loss: 0.5221 - val_binary_accuracy: 0.7108 - val_precision: 0.6607 - val_recall: 0.7500\n",
      "Epoch 665/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.5221 - binary_accuracy: 0.7108 - precision: 0.6607 - recall: 0.7500 - val_loss: 0.5204 - val_binary_accuracy: 0.7123 - val_precision: 0.6677 - val_recall: 0.7331\n",
      "Epoch 666/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.5204 - binary_accuracy: 0.7123 - precision: 0.6677 - recall: 0.7331 - val_loss: 0.4654 - val_binary_accuracy: 0.7585 - val_precision: 0.7491 - val_recall: 0.7061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.4654 - binary_accuracy: 0.7585 - precision: 0.7491 - recall: 0.7061 - val_loss: 0.4732 - val_binary_accuracy: 0.7615 - val_precision: 0.8190 - val_recall: 0.6115\n",
      "Epoch 668/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.4732 - binary_accuracy: 0.7615 - precision: 0.8190 - recall: 0.6115 - val_loss: 0.4837 - val_binary_accuracy: 0.7262 - val_precision: 0.8598 - val_recall: 0.4764\n",
      "Epoch 669/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.4837 - binary_accuracy: 0.7262 - precision: 0.8598 - recall: 0.4764 - val_loss: 0.4464 - val_binary_accuracy: 0.7662 - val_precision: 0.7400 - val_recall: 0.7500\n",
      "Epoch 670/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.4464 - binary_accuracy: 0.7662 - precision: 0.7400 - recall: 0.7500 - val_loss: 0.4539 - val_binary_accuracy: 0.7492 - val_precision: 0.6873 - val_recall: 0.8243\n",
      "Epoch 671/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4539 - binary_accuracy: 0.7492 - precision: 0.6873 - recall: 0.8243 - val_loss: 0.4595 - val_binary_accuracy: 0.7769 - val_precision: 0.7397 - val_recall: 0.7872\n",
      "Epoch 672/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4595 - binary_accuracy: 0.7769 - precision: 0.7397 - recall: 0.7872 - val_loss: 0.4375 - val_binary_accuracy: 0.7938 - val_precision: 0.8045 - val_recall: 0.7230\n",
      "Epoch 673/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.4375 - binary_accuracy: 0.7938 - precision: 0.8045 - recall: 0.7230 - val_loss: 0.4775 - val_binary_accuracy: 0.7492 - val_precision: 0.8446 - val_recall: 0.5507\n",
      "Epoch 674/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.4775 - binary_accuracy: 0.7492 - precision: 0.8446 - recall: 0.5507 - val_loss: 0.4418 - val_binary_accuracy: 0.8015 - val_precision: 0.8249 - val_recall: 0.7162\n",
      "Epoch 675/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.4418 - binary_accuracy: 0.8015 - precision: 0.8249 - recall: 0.7162 - val_loss: 0.4471 - val_binary_accuracy: 0.7662 - val_precision: 0.7483 - val_recall: 0.7331\n",
      "Epoch 676/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.4471 - binary_accuracy: 0.7662 - precision: 0.7483 - recall: 0.7331 - val_loss: 0.4454 - val_binary_accuracy: 0.7785 - val_precision: 0.7436 - val_recall: 0.7838\n",
      "Epoch 677/900\n",
      "650/650 [==============================] - 0s 157us/sample - loss: 0.4454 - binary_accuracy: 0.7785 - precision: 0.7436 - recall: 0.7838 - val_loss: 0.4206 - val_binary_accuracy: 0.7985 - val_precision: 0.7570 - val_recall: 0.8209\n",
      "Epoch 678/900\n",
      "650/650 [==============================] - 0s 161us/sample - loss: 0.4206 - binary_accuracy: 0.7985 - precision: 0.7570 - recall: 0.8209 - val_loss: 0.4355 - val_binary_accuracy: 0.7646 - val_precision: 0.8265 - val_recall: 0.6115\n",
      "Epoch 679/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4355 - binary_accuracy: 0.7646 - precision: 0.8265 - recall: 0.6115 - val_loss: 0.4165 - val_binary_accuracy: 0.7908 - val_precision: 0.8125 - val_recall: 0.7027\n",
      "Epoch 680/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.4165 - binary_accuracy: 0.7908 - precision: 0.8125 - recall: 0.7027 - val_loss: 0.4110 - val_binary_accuracy: 0.8046 - val_precision: 0.8051 - val_recall: 0.7534\n",
      "Epoch 681/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4110 - binary_accuracy: 0.8046 - precision: 0.8051 - recall: 0.7534 - val_loss: 0.4113 - val_binary_accuracy: 0.7969 - val_precision: 0.7789 - val_recall: 0.7736\n",
      "Epoch 682/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4113 - binary_accuracy: 0.7969 - precision: 0.7789 - recall: 0.7736 - val_loss: 0.4027 - val_binary_accuracy: 0.7862 - val_precision: 0.7524 - val_recall: 0.7905\n",
      "Epoch 683/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4027 - binary_accuracy: 0.7862 - precision: 0.7524 - recall: 0.7905 - val_loss: 0.3972 - val_binary_accuracy: 0.8077 - val_precision: 0.8251 - val_recall: 0.7331\n",
      "Epoch 684/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3972 - binary_accuracy: 0.8077 - precision: 0.8251 - recall: 0.7331 - val_loss: 0.4000 - val_binary_accuracy: 0.8000 - val_precision: 0.8487 - val_recall: 0.6824\n",
      "Epoch 685/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.4000 - binary_accuracy: 0.8000 - precision: 0.8487 - recall: 0.6824 - val_loss: 0.3953 - val_binary_accuracy: 0.8185 - val_precision: 0.8371 - val_recall: 0.7466\n",
      "Epoch 686/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3953 - binary_accuracy: 0.8185 - precision: 0.8371 - recall: 0.7466 - val_loss: 0.3805 - val_binary_accuracy: 0.8046 - val_precision: 0.7717 - val_recall: 0.8108\n",
      "Epoch 687/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.3805 - binary_accuracy: 0.8046 - precision: 0.7717 - recall: 0.8108 - val_loss: 0.3778 - val_binary_accuracy: 0.8169 - val_precision: 0.8062 - val_recall: 0.7872\n",
      "Epoch 688/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3778 - binary_accuracy: 0.8169 - precision: 0.8062 - recall: 0.7872 - val_loss: 0.3931 - val_binary_accuracy: 0.8185 - val_precision: 0.8870 - val_recall: 0.6892\n",
      "Epoch 689/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.3931 - binary_accuracy: 0.8185 - precision: 0.8870 - recall: 0.6892 - val_loss: 0.4121 - val_binary_accuracy: 0.7908 - val_precision: 0.8175 - val_recall: 0.6959\n",
      "Epoch 690/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.4121 - binary_accuracy: 0.7908 - precision: 0.8175 - recall: 0.6959 - val_loss: 0.4912 - val_binary_accuracy: 0.7585 - val_precision: 0.7235 - val_recall: 0.7601\n",
      "Epoch 691/900\n",
      "650/650 [==============================] - 0s 160us/sample - loss: 0.4912 - binary_accuracy: 0.7585 - precision: 0.7235 - recall: 0.7601 - val_loss: 0.5503 - val_binary_accuracy: 0.7123 - val_precision: 0.6430 - val_recall: 0.8277\n",
      "Epoch 692/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.5503 - binary_accuracy: 0.7123 - precision: 0.6430 - recall: 0.8277 - val_loss: 0.6911 - val_binary_accuracy: 0.6492 - val_precision: 0.7152 - val_recall: 0.3818\n",
      "Epoch 693/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.6911 - binary_accuracy: 0.6492 - precision: 0.7152 - recall: 0.3818 - val_loss: 0.4595 - val_binary_accuracy: 0.7554 - val_precision: 0.8374 - val_recall: 0.5743\n",
      "Epoch 694/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.4595 - binary_accuracy: 0.7554 - precision: 0.8374 - recall: 0.5743 - val_loss: 0.5756 - val_binary_accuracy: 0.6862 - val_precision: 0.6369 - val_recall: 0.7230\n",
      "Epoch 695/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5756 - binary_accuracy: 0.6862 - precision: 0.6369 - recall: 0.7230 - val_loss: 0.5512 - val_binary_accuracy: 0.6862 - val_precision: 0.6292 - val_recall: 0.7568\n",
      "Epoch 696/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.5512 - binary_accuracy: 0.6862 - precision: 0.6292 - recall: 0.7568 - val_loss: 0.4608 - val_binary_accuracy: 0.7862 - val_precision: 0.7985 - val_recall: 0.7095\n",
      "Epoch 697/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4608 - binary_accuracy: 0.7862 - precision: 0.7985 - recall: 0.7095 - val_loss: 0.5338 - val_binary_accuracy: 0.7369 - val_precision: 0.7753 - val_recall: 0.5946\n",
      "Epoch 698/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.5338 - binary_accuracy: 0.7369 - precision: 0.7753 - recall: 0.5946 - val_loss: 0.5298 - val_binary_accuracy: 0.7123 - val_precision: 0.8759 - val_recall: 0.4291\n",
      "Epoch 699/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.5298 - binary_accuracy: 0.7123 - precision: 0.8759 - recall: 0.4291 - val_loss: 0.4626 - val_binary_accuracy: 0.7631 - val_precision: 0.8515 - val_recall: 0.5811\n",
      "Epoch 700/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.4626 - binary_accuracy: 0.7631 - precision: 0.8515 - recall: 0.5811 - val_loss: 0.4761 - val_binary_accuracy: 0.7431 - val_precision: 0.6949 - val_recall: 0.7770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 701/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4761 - binary_accuracy: 0.7431 - precision: 0.6949 - recall: 0.7770 - val_loss: 0.5093 - val_binary_accuracy: 0.7215 - val_precision: 0.6567 - val_recall: 0.8142\n",
      "Epoch 702/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.5093 - binary_accuracy: 0.7215 - precision: 0.6567 - recall: 0.8142 - val_loss: 0.4473 - val_binary_accuracy: 0.7677 - val_precision: 0.7231 - val_recall: 0.7939\n",
      "Epoch 703/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4473 - binary_accuracy: 0.7677 - precision: 0.7231 - recall: 0.7939 - val_loss: 0.4368 - val_binary_accuracy: 0.7677 - val_precision: 0.7778 - val_recall: 0.6858\n",
      "Epoch 704/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4368 - binary_accuracy: 0.7677 - precision: 0.7778 - recall: 0.6858 - val_loss: 0.4617 - val_binary_accuracy: 0.7477 - val_precision: 0.8511 - val_recall: 0.5405\n",
      "Epoch 705/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.4617 - binary_accuracy: 0.7477 - precision: 0.8511 - recall: 0.5405 - val_loss: 0.4263 - val_binary_accuracy: 0.7754 - val_precision: 0.8989 - val_recall: 0.5709\n",
      "Epoch 706/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4263 - binary_accuracy: 0.7754 - precision: 0.8989 - recall: 0.5709 - val_loss: 0.4347 - val_binary_accuracy: 0.7877 - val_precision: 0.8591 - val_recall: 0.6385\n",
      "Epoch 707/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4347 - binary_accuracy: 0.7877 - precision: 0.8591 - recall: 0.6385 - val_loss: 0.4339 - val_binary_accuracy: 0.7738 - val_precision: 0.7614 - val_recall: 0.7331\n",
      "Epoch 708/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.4339 - binary_accuracy: 0.7738 - precision: 0.7614 - recall: 0.7331 - val_loss: 0.4140 - val_binary_accuracy: 0.7769 - val_precision: 0.7214 - val_recall: 0.8311\n",
      "Epoch 709/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.4140 - binary_accuracy: 0.7769 - precision: 0.7214 - recall: 0.8311 - val_loss: 0.4105 - val_binary_accuracy: 0.7969 - val_precision: 0.7515 - val_recall: 0.8277\n",
      "Epoch 710/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.4105 - binary_accuracy: 0.7969 - precision: 0.7515 - recall: 0.8277 - val_loss: 0.4074 - val_binary_accuracy: 0.7800 - val_precision: 0.7802 - val_recall: 0.7196\n",
      "Epoch 711/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4074 - binary_accuracy: 0.7800 - precision: 0.7802 - recall: 0.7196 - val_loss: 0.3898 - val_binary_accuracy: 0.8031 - val_precision: 0.8784 - val_recall: 0.6588\n",
      "Epoch 712/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3898 - binary_accuracy: 0.8031 - precision: 0.8784 - recall: 0.6588 - val_loss: 0.4013 - val_binary_accuracy: 0.7908 - val_precision: 0.8846 - val_recall: 0.6216\n",
      "Epoch 713/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.4013 - binary_accuracy: 0.7908 - precision: 0.8846 - recall: 0.6216 - val_loss: 0.3840 - val_binary_accuracy: 0.8231 - val_precision: 0.8787 - val_recall: 0.7095\n",
      "Epoch 714/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3840 - binary_accuracy: 0.8231 - precision: 0.8787 - recall: 0.7095 - val_loss: 0.3697 - val_binary_accuracy: 0.8277 - val_precision: 0.8194 - val_recall: 0.7973\n",
      "Epoch 715/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3697 - binary_accuracy: 0.8277 - precision: 0.8194 - recall: 0.7973 - val_loss: 0.3840 - val_binary_accuracy: 0.8000 - val_precision: 0.7712 - val_recall: 0.7973\n",
      "Epoch 716/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3840 - binary_accuracy: 0.8000 - precision: 0.7712 - recall: 0.7973 - val_loss: 0.3680 - val_binary_accuracy: 0.8046 - val_precision: 0.7864 - val_recall: 0.7838\n",
      "Epoch 717/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3680 - binary_accuracy: 0.8046 - precision: 0.7864 - recall: 0.7838 - val_loss: 0.3573 - val_binary_accuracy: 0.8338 - val_precision: 0.8672 - val_recall: 0.7500\n",
      "Epoch 718/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.3573 - binary_accuracy: 0.8338 - precision: 0.8672 - recall: 0.7500 - val_loss: 0.3661 - val_binary_accuracy: 0.8215 - val_precision: 0.9091 - val_recall: 0.6757\n",
      "Epoch 719/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3661 - binary_accuracy: 0.8215 - precision: 0.9091 - recall: 0.6757 - val_loss: 0.3451 - val_binary_accuracy: 0.8415 - val_precision: 0.9142 - val_recall: 0.7196\n",
      "Epoch 720/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3451 - binary_accuracy: 0.8415 - precision: 0.9142 - recall: 0.7196 - val_loss: 0.3519 - val_binary_accuracy: 0.8308 - val_precision: 0.8444 - val_recall: 0.7703\n",
      "Epoch 721/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.3519 - binary_accuracy: 0.8308 - precision: 0.8444 - recall: 0.7703 - val_loss: 0.3406 - val_binary_accuracy: 0.8523 - val_precision: 0.8497 - val_recall: 0.8209\n",
      "Epoch 722/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3406 - binary_accuracy: 0.8523 - precision: 0.8497 - recall: 0.8209 - val_loss: 0.3465 - val_binary_accuracy: 0.8323 - val_precision: 0.8351 - val_recall: 0.7872\n",
      "Epoch 723/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3465 - binary_accuracy: 0.8323 - precision: 0.8351 - recall: 0.7872 - val_loss: 0.3342 - val_binary_accuracy: 0.8292 - val_precision: 0.8339 - val_recall: 0.7804\n",
      "Epoch 724/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.3342 - binary_accuracy: 0.8292 - precision: 0.8339 - recall: 0.7804 - val_loss: 0.3336 - val_binary_accuracy: 0.8369 - val_precision: 0.8958 - val_recall: 0.7264\n",
      "Epoch 725/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3336 - binary_accuracy: 0.8369 - precision: 0.8958 - recall: 0.7264 - val_loss: 0.3198 - val_binary_accuracy: 0.8462 - val_precision: 0.8952 - val_recall: 0.7500\n",
      "Epoch 726/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3198 - binary_accuracy: 0.8462 - precision: 0.8952 - recall: 0.7500 - val_loss: 0.3250 - val_binary_accuracy: 0.8400 - val_precision: 0.8453 - val_recall: 0.7939\n",
      "Epoch 727/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3250 - binary_accuracy: 0.8400 - precision: 0.8453 - recall: 0.7939 - val_loss: 0.3295 - val_binary_accuracy: 0.8415 - val_precision: 0.8434 - val_recall: 0.8007\n",
      "Epoch 728/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3295 - binary_accuracy: 0.8415 - precision: 0.8434 - recall: 0.8007 - val_loss: 0.3056 - val_binary_accuracy: 0.8538 - val_precision: 0.8681 - val_recall: 0.8007\n",
      "Epoch 729/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3056 - binary_accuracy: 0.8538 - precision: 0.8681 - recall: 0.8007 - val_loss: 0.3083 - val_binary_accuracy: 0.8538 - val_precision: 0.8972 - val_recall: 0.7669\n",
      "Epoch 730/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3083 - binary_accuracy: 0.8538 - precision: 0.8972 - recall: 0.7669 - val_loss: 0.3017 - val_binary_accuracy: 0.8646 - val_precision: 0.9228 - val_recall: 0.7669\n",
      "Epoch 731/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3017 - binary_accuracy: 0.8646 - precision: 0.9228 - recall: 0.7669 - val_loss: 0.2926 - val_binary_accuracy: 0.8723 - val_precision: 0.9019 - val_recall: 0.8074\n",
      "Epoch 732/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2926 - binary_accuracy: 0.8723 - precision: 0.9019 - recall: 0.8074 - val_loss: 0.2954 - val_binary_accuracy: 0.8677 - val_precision: 0.8671 - val_recall: 0.8378\n",
      "Epoch 733/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2954 - binary_accuracy: 0.8677 - precision: 0.8671 - recall: 0.8378 - val_loss: 0.2809 - val_binary_accuracy: 0.8831 - val_precision: 0.9297 - val_recall: 0.8041\n",
      "Epoch 734/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2809 - binary_accuracy: 0.8831 - precision: 0.9297 - recall: 0.8041 - val_loss: 0.2795 - val_binary_accuracy: 0.8769 - val_precision: 0.9463 - val_recall: 0.7736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 735/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2795 - binary_accuracy: 0.8769 - precision: 0.9463 - recall: 0.7736 - val_loss: 0.2817 - val_binary_accuracy: 0.8692 - val_precision: 0.8809 - val_recall: 0.8243\n",
      "Epoch 736/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2817 - binary_accuracy: 0.8692 - precision: 0.8809 - recall: 0.8243 - val_loss: 0.2889 - val_binary_accuracy: 0.8692 - val_precision: 0.9042 - val_recall: 0.7973\n",
      "Epoch 737/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2889 - binary_accuracy: 0.8692 - precision: 0.9042 - recall: 0.7973 - val_loss: 0.3103 - val_binary_accuracy: 0.8323 - val_precision: 0.8400 - val_recall: 0.7804\n",
      "Epoch 738/900\n",
      "650/650 [==============================] - 0s 152us/sample - loss: 0.3103 - binary_accuracy: 0.8323 - precision: 0.8400 - recall: 0.7804 - val_loss: 0.3910 - val_binary_accuracy: 0.8154 - val_precision: 0.8761 - val_recall: 0.6926\n",
      "Epoch 739/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.3910 - binary_accuracy: 0.8154 - precision: 0.8761 - recall: 0.6926 - val_loss: 0.3113 - val_binary_accuracy: 0.8523 - val_precision: 0.8378 - val_recall: 0.8378\n",
      "Epoch 740/900\n",
      "650/650 [==============================] - 0s 159us/sample - loss: 0.3113 - binary_accuracy: 0.8523 - precision: 0.8378 - recall: 0.8378 - val_loss: 0.3985 - val_binary_accuracy: 0.7969 - val_precision: 0.7808 - val_recall: 0.7703\n",
      "Epoch 741/900\n",
      "650/650 [==============================] - 0s 153us/sample - loss: 0.3985 - binary_accuracy: 0.7969 - precision: 0.7808 - recall: 0.7703 - val_loss: 0.4236 - val_binary_accuracy: 0.7985 - val_precision: 0.9188 - val_recall: 0.6115\n",
      "Epoch 742/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.4236 - binary_accuracy: 0.7985 - precision: 0.9188 - recall: 0.6115 - val_loss: 0.4225 - val_binary_accuracy: 0.7831 - val_precision: 0.7719 - val_recall: 0.7432\n",
      "Epoch 743/900\n",
      "650/650 [==============================] - 0s 156us/sample - loss: 0.4225 - binary_accuracy: 0.7831 - precision: 0.7719 - recall: 0.7432 - val_loss: 0.3405 - val_binary_accuracy: 0.8231 - val_precision: 0.7768 - val_recall: 0.8581\n",
      "Epoch 744/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.3405 - binary_accuracy: 0.8231 - precision: 0.7768 - recall: 0.8581 - val_loss: 0.3594 - val_binary_accuracy: 0.7985 - val_precision: 0.8767 - val_recall: 0.6486\n",
      "Epoch 745/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.3594 - binary_accuracy: 0.7985 - precision: 0.8767 - recall: 0.6486 - val_loss: 0.3806 - val_binary_accuracy: 0.7969 - val_precision: 0.9059 - val_recall: 0.6182\n",
      "Epoch 746/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.3806 - binary_accuracy: 0.7969 - precision: 0.9059 - recall: 0.6182 - val_loss: 0.3004 - val_binary_accuracy: 0.8662 - val_precision: 0.9130 - val_recall: 0.7804\n",
      "Epoch 747/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.3004 - binary_accuracy: 0.8662 - precision: 0.9130 - recall: 0.7804 - val_loss: 0.3394 - val_binary_accuracy: 0.8154 - val_precision: 0.7514 - val_recall: 0.8885\n",
      "Epoch 748/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.3394 - binary_accuracy: 0.8154 - precision: 0.7514 - recall: 0.8885 - val_loss: 0.3263 - val_binary_accuracy: 0.8492 - val_precision: 0.8694 - val_recall: 0.7872\n",
      "Epoch 749/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3263 - binary_accuracy: 0.8492 - precision: 0.8694 - recall: 0.7872 - val_loss: 0.2858 - val_binary_accuracy: 0.8615 - val_precision: 0.9087 - val_recall: 0.7736\n",
      "Epoch 750/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2858 - binary_accuracy: 0.8615 - precision: 0.9087 - recall: 0.7736 - val_loss: 0.3176 - val_binary_accuracy: 0.8338 - val_precision: 0.8701 - val_recall: 0.7466\n",
      "Epoch 751/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.3176 - binary_accuracy: 0.8338 - precision: 0.8701 - recall: 0.7466 - val_loss: 0.2791 - val_binary_accuracy: 0.8785 - val_precision: 0.9189 - val_recall: 0.8041\n",
      "Epoch 752/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2791 - binary_accuracy: 0.8785 - precision: 0.9189 - recall: 0.8041 - val_loss: 0.2898 - val_binary_accuracy: 0.8662 - val_precision: 0.8746 - val_recall: 0.8243\n",
      "Epoch 753/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2898 - binary_accuracy: 0.8662 - precision: 0.8746 - recall: 0.8243 - val_loss: 0.2811 - val_binary_accuracy: 0.8738 - val_precision: 0.8963 - val_recall: 0.8176\n",
      "Epoch 754/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.2811 - binary_accuracy: 0.8738 - precision: 0.8963 - recall: 0.8176 - val_loss: 0.2642 - val_binary_accuracy: 0.8754 - val_precision: 0.8938 - val_recall: 0.8243\n",
      "Epoch 755/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2642 - binary_accuracy: 0.8754 - precision: 0.8938 - recall: 0.8243 - val_loss: 0.2701 - val_binary_accuracy: 0.8677 - val_precision: 0.8889 - val_recall: 0.8108\n",
      "Epoch 756/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2701 - binary_accuracy: 0.8677 - precision: 0.8889 - recall: 0.8108 - val_loss: 0.2603 - val_binary_accuracy: 0.8800 - val_precision: 0.9160 - val_recall: 0.8108\n",
      "Epoch 757/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2603 - binary_accuracy: 0.8800 - precision: 0.9160 - recall: 0.8108 - val_loss: 0.2588 - val_binary_accuracy: 0.8754 - val_precision: 0.8938 - val_recall: 0.8243\n",
      "Epoch 758/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2588 - binary_accuracy: 0.8754 - precision: 0.8938 - recall: 0.8243 - val_loss: 0.2411 - val_binary_accuracy: 0.9169 - val_precision: 0.9416 - val_recall: 0.8716\n",
      "Epoch 759/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2411 - binary_accuracy: 0.9169 - precision: 0.9416 - recall: 0.8716 - val_loss: 0.2530 - val_binary_accuracy: 0.8862 - val_precision: 0.9173 - val_recall: 0.8243\n",
      "Epoch 760/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2530 - binary_accuracy: 0.8862 - precision: 0.9173 - recall: 0.8243 - val_loss: 0.2345 - val_binary_accuracy: 0.9062 - val_precision: 0.9401 - val_recall: 0.8480\n",
      "Epoch 761/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2345 - binary_accuracy: 0.9062 - precision: 0.9401 - recall: 0.8480 - val_loss: 0.2484 - val_binary_accuracy: 0.8908 - val_precision: 0.8893 - val_recall: 0.8682\n",
      "Epoch 762/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2484 - binary_accuracy: 0.8908 - precision: 0.8893 - recall: 0.8682 - val_loss: 0.2196 - val_binary_accuracy: 0.9154 - val_precision: 0.9382 - val_recall: 0.8716\n",
      "Epoch 763/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2196 - binary_accuracy: 0.9154 - precision: 0.9382 - recall: 0.8716 - val_loss: 0.2360 - val_binary_accuracy: 0.8938 - val_precision: 0.9283 - val_recall: 0.8311\n",
      "Epoch 764/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2360 - binary_accuracy: 0.8938 - precision: 0.9283 - recall: 0.8311 - val_loss: 0.2228 - val_binary_accuracy: 0.9046 - val_precision: 0.9366 - val_recall: 0.8480\n",
      "Epoch 765/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2228 - binary_accuracy: 0.9046 - precision: 0.9366 - recall: 0.8480 - val_loss: 0.2498 - val_binary_accuracy: 0.8954 - val_precision: 0.9014 - val_recall: 0.8649\n",
      "Epoch 766/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2498 - binary_accuracy: 0.8954 - precision: 0.9014 - recall: 0.8649 - val_loss: 0.3387 - val_binary_accuracy: 0.8477 - val_precision: 0.8689 - val_recall: 0.7838\n",
      "Epoch 767/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3387 - binary_accuracy: 0.8477 - precision: 0.8689 - recall: 0.7838 - val_loss: 0.3251 - val_binary_accuracy: 0.8385 - val_precision: 0.8215 - val_recall: 0.8243\n",
      "Epoch 768/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.3251 - binary_accuracy: 0.8385 - precision: 0.8215 - recall: 0.8243 - val_loss: 0.3006 - val_binary_accuracy: 0.8600 - val_precision: 0.9253 - val_recall: 0.7534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.3006 - binary_accuracy: 0.8600 - precision: 0.9253 - recall: 0.7534 - val_loss: 0.2953 - val_binary_accuracy: 0.8785 - val_precision: 0.8511 - val_recall: 0.8885\n",
      "Epoch 770/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2953 - binary_accuracy: 0.8785 - precision: 0.8511 - recall: 0.8885 - val_loss: 0.2828 - val_binary_accuracy: 0.8677 - val_precision: 0.8918 - val_recall: 0.8074\n",
      "Epoch 771/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2828 - binary_accuracy: 0.8677 - precision: 0.8918 - recall: 0.8074 - val_loss: 0.2745 - val_binary_accuracy: 0.8708 - val_precision: 0.9649 - val_recall: 0.7432\n",
      "Epoch 772/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2745 - binary_accuracy: 0.8708 - precision: 0.9649 - recall: 0.7432 - val_loss: 0.2868 - val_binary_accuracy: 0.8631 - val_precision: 0.8462 - val_recall: 0.8547\n",
      "Epoch 773/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2868 - binary_accuracy: 0.8631 - precision: 0.8462 - recall: 0.8547 - val_loss: 0.2392 - val_binary_accuracy: 0.8708 - val_precision: 0.8354 - val_recall: 0.8919\n",
      "Epoch 774/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2392 - binary_accuracy: 0.8708 - precision: 0.8354 - recall: 0.8919 - val_loss: 0.2467 - val_binary_accuracy: 0.8862 - val_precision: 0.9336 - val_recall: 0.8074\n",
      "Epoch 775/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2467 - binary_accuracy: 0.8862 - precision: 0.9336 - recall: 0.8074 - val_loss: 0.2441 - val_binary_accuracy: 0.8877 - val_precision: 0.9514 - val_recall: 0.7939\n",
      "Epoch 776/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.2441 - binary_accuracy: 0.8877 - precision: 0.9514 - recall: 0.7939 - val_loss: 0.2403 - val_binary_accuracy: 0.8862 - val_precision: 0.8964 - val_recall: 0.8480\n",
      "Epoch 777/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2403 - binary_accuracy: 0.8862 - precision: 0.8964 - recall: 0.8480 - val_loss: 0.2333 - val_binary_accuracy: 0.8892 - val_precision: 0.8613 - val_recall: 0.9020\n",
      "Epoch 778/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2333 - binary_accuracy: 0.8892 - precision: 0.8613 - recall: 0.9020 - val_loss: 0.2175 - val_binary_accuracy: 0.9092 - val_precision: 0.9341 - val_recall: 0.8615\n",
      "Epoch 779/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2175 - binary_accuracy: 0.9092 - precision: 0.9341 - recall: 0.8615 - val_loss: 0.2283 - val_binary_accuracy: 0.9046 - val_precision: 0.9795 - val_recall: 0.8074\n",
      "Epoch 780/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2283 - binary_accuracy: 0.9046 - precision: 0.9795 - recall: 0.8074 - val_loss: 0.2025 - val_binary_accuracy: 0.9092 - val_precision: 0.9405 - val_recall: 0.8547\n",
      "Epoch 781/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.2025 - binary_accuracy: 0.9092 - precision: 0.9405 - recall: 0.8547 - val_loss: 0.2189 - val_binary_accuracy: 0.8923 - val_precision: 0.8717 - val_recall: 0.8953\n",
      "Epoch 782/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2189 - binary_accuracy: 0.8923 - precision: 0.8717 - recall: 0.8953 - val_loss: 0.1928 - val_binary_accuracy: 0.9231 - val_precision: 0.9590 - val_recall: 0.8682\n",
      "Epoch 783/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1928 - binary_accuracy: 0.9231 - precision: 0.9590 - recall: 0.8682 - val_loss: 0.1981 - val_binary_accuracy: 0.9185 - val_precision: 0.9728 - val_recall: 0.8446\n",
      "Epoch 784/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1981 - binary_accuracy: 0.9185 - precision: 0.9728 - recall: 0.8446 - val_loss: 0.1934 - val_binary_accuracy: 0.9123 - val_precision: 0.9509 - val_recall: 0.8514\n",
      "Epoch 785/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1934 - binary_accuracy: 0.9123 - precision: 0.9509 - recall: 0.8514 - val_loss: 0.1876 - val_binary_accuracy: 0.9200 - val_precision: 0.8910 - val_recall: 0.9392\n",
      "Epoch 786/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1876 - binary_accuracy: 0.9200 - precision: 0.8910 - recall: 0.9392 - val_loss: 0.1842 - val_binary_accuracy: 0.9200 - val_precision: 0.9388 - val_recall: 0.8818\n",
      "Epoch 787/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1842 - binary_accuracy: 0.9200 - precision: 0.9388 - recall: 0.8818 - val_loss: 0.1852 - val_binary_accuracy: 0.9262 - val_precision: 0.9844 - val_recall: 0.8514\n",
      "Epoch 788/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1852 - binary_accuracy: 0.9262 - precision: 0.9844 - recall: 0.8514 - val_loss: 0.1797 - val_binary_accuracy: 0.9308 - val_precision: 0.9631 - val_recall: 0.8818\n",
      "Epoch 789/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1797 - binary_accuracy: 0.9308 - precision: 0.9631 - recall: 0.8818 - val_loss: 0.1743 - val_binary_accuracy: 0.9200 - val_precision: 0.8935 - val_recall: 0.9358\n",
      "Epoch 790/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1743 - binary_accuracy: 0.9200 - precision: 0.8935 - recall: 0.9358 - val_loss: 0.1689 - val_binary_accuracy: 0.9277 - val_precision: 0.9278 - val_recall: 0.9122\n",
      "Epoch 791/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1689 - binary_accuracy: 0.9277 - precision: 0.9278 - recall: 0.9122 - val_loss: 0.1686 - val_binary_accuracy: 0.9308 - val_precision: 0.9846 - val_recall: 0.8615\n",
      "Epoch 792/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1686 - binary_accuracy: 0.9308 - precision: 0.9846 - recall: 0.8615 - val_loss: 0.1643 - val_binary_accuracy: 0.9308 - val_precision: 0.9564 - val_recall: 0.8885\n",
      "Epoch 793/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1643 - binary_accuracy: 0.9308 - precision: 0.9564 - recall: 0.8885 - val_loss: 0.1572 - val_binary_accuracy: 0.9446 - val_precision: 0.9514 - val_recall: 0.9257\n",
      "Epoch 794/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1572 - binary_accuracy: 0.9446 - precision: 0.9514 - recall: 0.9257 - val_loss: 0.1649 - val_binary_accuracy: 0.9308 - val_precision: 0.9254 - val_recall: 0.9223\n",
      "Epoch 795/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1649 - binary_accuracy: 0.9308 - precision: 0.9254 - recall: 0.9223 - val_loss: 0.1589 - val_binary_accuracy: 0.9323 - val_precision: 0.9701 - val_recall: 0.8784\n",
      "Epoch 796/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1589 - binary_accuracy: 0.9323 - precision: 0.9701 - recall: 0.8784 - val_loss: 0.1565 - val_binary_accuracy: 0.9400 - val_precision: 0.9606 - val_recall: 0.9054\n",
      "Epoch 797/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1565 - binary_accuracy: 0.9400 - precision: 0.9606 - recall: 0.9054 - val_loss: 0.1640 - val_binary_accuracy: 0.9292 - val_precision: 0.9195 - val_recall: 0.9257\n",
      "Epoch 798/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1640 - binary_accuracy: 0.9292 - precision: 0.9195 - recall: 0.9257 - val_loss: 0.1558 - val_binary_accuracy: 0.9385 - val_precision: 0.9672 - val_recall: 0.8953\n",
      "Epoch 799/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1558 - binary_accuracy: 0.9385 - precision: 0.9672 - recall: 0.8953 - val_loss: 0.1357 - val_binary_accuracy: 0.9492 - val_precision: 0.9550 - val_recall: 0.9324\n",
      "Epoch 800/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1357 - binary_accuracy: 0.9492 - precision: 0.9550 - recall: 0.9324 - val_loss: 0.1338 - val_binary_accuracy: 0.9554 - val_precision: 0.9890 - val_recall: 0.9122\n",
      "Epoch 801/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1338 - binary_accuracy: 0.9554 - precision: 0.9890 - recall: 0.9122 - val_loss: 0.1425 - val_binary_accuracy: 0.9415 - val_precision: 0.9574 - val_recall: 0.9122\n",
      "Epoch 802/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1425 - binary_accuracy: 0.9415 - precision: 0.9574 - recall: 0.9122 - val_loss: 0.2056 - val_binary_accuracy: 0.8923 - val_precision: 0.8951 - val_recall: 0.8649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 803/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2056 - binary_accuracy: 0.8923 - precision: 0.8951 - recall: 0.8649 - val_loss: 0.5463 - val_binary_accuracy: 0.7908 - val_precision: 0.7837 - val_recall: 0.7466\n",
      "Epoch 804/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.5463 - binary_accuracy: 0.7908 - precision: 0.7837 - recall: 0.7466 - val_loss: 0.3425 - val_binary_accuracy: 0.8508 - val_precision: 0.8373 - val_recall: 0.8345\n",
      "Epoch 805/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.3425 - binary_accuracy: 0.8508 - precision: 0.8373 - recall: 0.8345 - val_loss: 0.4688 - val_binary_accuracy: 0.7969 - val_precision: 0.7908 - val_recall: 0.7534\n",
      "Epoch 806/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.4688 - binary_accuracy: 0.7969 - precision: 0.7908 - recall: 0.7534 - val_loss: 0.2704 - val_binary_accuracy: 0.8662 - val_precision: 0.9197 - val_recall: 0.7736\n",
      "Epoch 807/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.2704 - binary_accuracy: 0.8662 - precision: 0.9197 - recall: 0.7736 - val_loss: 0.4423 - val_binary_accuracy: 0.7600 - val_precision: 0.6741 - val_recall: 0.9155\n",
      "Epoch 808/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.4423 - binary_accuracy: 0.7600 - precision: 0.6741 - recall: 0.9155 - val_loss: 0.2874 - val_binary_accuracy: 0.8754 - val_precision: 0.9909 - val_recall: 0.7331\n",
      "Epoch 809/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2874 - binary_accuracy: 0.8754 - precision: 0.9909 - recall: 0.7331 - val_loss: 0.3856 - val_binary_accuracy: 0.8262 - val_precision: 0.8327 - val_recall: 0.7736\n",
      "Epoch 810/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.3856 - binary_accuracy: 0.8262 - precision: 0.8327 - recall: 0.7736 - val_loss: 0.2278 - val_binary_accuracy: 0.8938 - val_precision: 0.8348 - val_recall: 0.9561\n",
      "Epoch 811/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2278 - binary_accuracy: 0.8938 - precision: 0.8348 - recall: 0.9561 - val_loss: 0.3366 - val_binary_accuracy: 0.8292 - val_precision: 0.8715 - val_recall: 0.7331\n",
      "Epoch 812/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.3366 - binary_accuracy: 0.8292 - precision: 0.8715 - recall: 0.7331 - val_loss: 0.1978 - val_binary_accuracy: 0.9123 - val_precision: 0.9314 - val_recall: 0.8716\n",
      "Epoch 813/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1978 - binary_accuracy: 0.9123 - precision: 0.9314 - recall: 0.8716 - val_loss: 0.2760 - val_binary_accuracy: 0.8585 - val_precision: 0.8493 - val_recall: 0.8378\n",
      "Epoch 814/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.2760 - binary_accuracy: 0.8585 - precision: 0.8493 - recall: 0.8378 - val_loss: 0.2028 - val_binary_accuracy: 0.9123 - val_precision: 0.9314 - val_recall: 0.8716\n",
      "Epoch 815/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2028 - binary_accuracy: 0.9123 - precision: 0.9314 - recall: 0.8716 - val_loss: 0.2031 - val_binary_accuracy: 0.9108 - val_precision: 0.9440 - val_recall: 0.8547\n",
      "Epoch 816/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2031 - binary_accuracy: 0.9108 - precision: 0.9440 - recall: 0.8547 - val_loss: 0.2281 - val_binary_accuracy: 0.8954 - val_precision: 0.9014 - val_recall: 0.8649\n",
      "Epoch 817/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.2281 - binary_accuracy: 0.8954 - precision: 0.9014 - recall: 0.8649 - val_loss: 0.1821 - val_binary_accuracy: 0.9246 - val_precision: 0.9103 - val_recall: 0.9257\n",
      "Epoch 818/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.1821 - binary_accuracy: 0.9246 - precision: 0.9103 - recall: 0.9257 - val_loss: 0.1921 - val_binary_accuracy: 0.9246 - val_precision: 0.9427 - val_recall: 0.8885\n",
      "Epoch 819/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.1921 - binary_accuracy: 0.9246 - precision: 0.9427 - recall: 0.8885 - val_loss: 0.1996 - val_binary_accuracy: 0.9108 - val_precision: 0.9648 - val_recall: 0.8345\n",
      "Epoch 820/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1996 - binary_accuracy: 0.9108 - precision: 0.9648 - recall: 0.8345 - val_loss: 0.1823 - val_binary_accuracy: 0.9231 - val_precision: 0.9393 - val_recall: 0.8885\n",
      "Epoch 821/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1823 - binary_accuracy: 0.9231 - precision: 0.9393 - recall: 0.8885 - val_loss: 0.1768 - val_binary_accuracy: 0.9292 - val_precision: 0.9371 - val_recall: 0.9054\n",
      "Epoch 822/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1768 - binary_accuracy: 0.9292 - precision: 0.9371 - recall: 0.9054 - val_loss: 0.1602 - val_binary_accuracy: 0.9415 - val_precision: 0.9674 - val_recall: 0.9020\n",
      "Epoch 823/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1602 - binary_accuracy: 0.9415 - precision: 0.9674 - recall: 0.9020 - val_loss: 0.1577 - val_binary_accuracy: 0.9385 - val_precision: 0.9604 - val_recall: 0.9020\n",
      "Epoch 824/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1577 - binary_accuracy: 0.9385 - precision: 0.9604 - recall: 0.9020 - val_loss: 0.1519 - val_binary_accuracy: 0.9354 - val_precision: 0.9504 - val_recall: 0.9054\n",
      "Epoch 825/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1519 - binary_accuracy: 0.9354 - precision: 0.9504 - recall: 0.9054 - val_loss: 0.1429 - val_binary_accuracy: 0.9554 - val_precision: 0.9751 - val_recall: 0.9257\n",
      "Epoch 826/900\n",
      "650/650 [==============================] - 0s 154us/sample - loss: 0.1429 - binary_accuracy: 0.9554 - precision: 0.9751 - recall: 0.9257 - val_loss: 0.1488 - val_binary_accuracy: 0.9400 - val_precision: 0.9573 - val_recall: 0.9088\n",
      "Epoch 827/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1488 - binary_accuracy: 0.9400 - precision: 0.9573 - recall: 0.9088 - val_loss: 0.1364 - val_binary_accuracy: 0.9569 - val_precision: 0.9786 - val_recall: 0.9257\n",
      "Epoch 828/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1364 - binary_accuracy: 0.9569 - precision: 0.9786 - recall: 0.9257 - val_loss: 0.1292 - val_binary_accuracy: 0.9538 - val_precision: 0.9854 - val_recall: 0.9122\n",
      "Epoch 829/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1292 - binary_accuracy: 0.9538 - precision: 0.9854 - recall: 0.9122 - val_loss: 0.1367 - val_binary_accuracy: 0.9523 - val_precision: 0.9492 - val_recall: 0.9459\n",
      "Epoch 830/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1367 - binary_accuracy: 0.9523 - precision: 0.9492 - recall: 0.9459 - val_loss: 0.1238 - val_binary_accuracy: 0.9538 - val_precision: 0.9586 - val_recall: 0.9392\n",
      "Epoch 831/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1238 - binary_accuracy: 0.9538 - precision: 0.9586 - recall: 0.9392 - val_loss: 0.1256 - val_binary_accuracy: 0.9523 - val_precision: 0.9749 - val_recall: 0.9189\n",
      "Epoch 832/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.1256 - binary_accuracy: 0.9523 - precision: 0.9749 - recall: 0.9189 - val_loss: 0.1217 - val_binary_accuracy: 0.9585 - val_precision: 0.9821 - val_recall: 0.9257\n",
      "Epoch 833/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1217 - binary_accuracy: 0.9585 - precision: 0.9821 - recall: 0.9257 - val_loss: 0.1130 - val_binary_accuracy: 0.9600 - val_precision: 0.9754 - val_recall: 0.9358\n",
      "Epoch 834/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.1130 - binary_accuracy: 0.9600 - precision: 0.9754 - recall: 0.9358 - val_loss: 0.1175 - val_binary_accuracy: 0.9585 - val_precision: 0.9686 - val_recall: 0.9392\n",
      "Epoch 835/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.1175 - binary_accuracy: 0.9585 - precision: 0.9686 - recall: 0.9392 - val_loss: 0.1064 - val_binary_accuracy: 0.9692 - val_precision: 0.9894 - val_recall: 0.9426\n",
      "Epoch 836/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1064 - binary_accuracy: 0.9692 - precision: 0.9894 - recall: 0.9426 - val_loss: 0.1080 - val_binary_accuracy: 0.9692 - val_precision: 0.9894 - val_recall: 0.9426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1080 - binary_accuracy: 0.9692 - precision: 0.9894 - recall: 0.9426 - val_loss: 0.1044 - val_binary_accuracy: 0.9677 - val_precision: 0.9758 - val_recall: 0.9527\n",
      "Epoch 838/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1044 - binary_accuracy: 0.9677 - precision: 0.9758 - recall: 0.9527 - val_loss: 0.0976 - val_binary_accuracy: 0.9692 - val_precision: 0.9726 - val_recall: 0.9595\n",
      "Epoch 839/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0976 - binary_accuracy: 0.9692 - precision: 0.9726 - recall: 0.9595 - val_loss: 0.1002 - val_binary_accuracy: 0.9723 - val_precision: 0.9860 - val_recall: 0.9527\n",
      "Epoch 840/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1002 - binary_accuracy: 0.9723 - precision: 0.9860 - recall: 0.9527 - val_loss: 0.0951 - val_binary_accuracy: 0.9615 - val_precision: 0.9927 - val_recall: 0.9223\n",
      "Epoch 841/900\n",
      "650/650 [==============================] - 0s 147us/sample - loss: 0.0951 - binary_accuracy: 0.9615 - precision: 0.9927 - recall: 0.9223 - val_loss: 0.0933 - val_binary_accuracy: 0.9769 - val_precision: 0.9828 - val_recall: 0.9662\n",
      "Epoch 842/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.0933 - binary_accuracy: 0.9769 - precision: 0.9828 - recall: 0.9662 - val_loss: 0.0915 - val_binary_accuracy: 0.9815 - val_precision: 0.9931 - val_recall: 0.9662\n",
      "Epoch 843/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.0915 - binary_accuracy: 0.9815 - precision: 0.9931 - recall: 0.9662 - val_loss: 0.0871 - val_binary_accuracy: 0.9723 - val_precision: 0.9894 - val_recall: 0.9493\n",
      "Epoch 844/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.0871 - binary_accuracy: 0.9723 - precision: 0.9894 - recall: 0.9493 - val_loss: 0.0832 - val_binary_accuracy: 0.9815 - val_precision: 0.9897 - val_recall: 0.9696\n",
      "Epoch 845/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.0832 - binary_accuracy: 0.9815 - precision: 0.9897 - recall: 0.9696 - val_loss: 0.0823 - val_binary_accuracy: 0.9815 - val_precision: 0.9897 - val_recall: 0.9696\n",
      "Epoch 846/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.0823 - binary_accuracy: 0.9815 - precision: 0.9897 - recall: 0.9696 - val_loss: 0.0837 - val_binary_accuracy: 0.9738 - val_precision: 0.9861 - val_recall: 0.9561\n",
      "Epoch 847/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0837 - binary_accuracy: 0.9738 - precision: 0.9861 - recall: 0.9561 - val_loss: 0.0784 - val_binary_accuracy: 0.9800 - val_precision: 0.9930 - val_recall: 0.9628\n",
      "Epoch 848/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.0784 - binary_accuracy: 0.9800 - precision: 0.9930 - recall: 0.9628 - val_loss: 0.0774 - val_binary_accuracy: 0.9862 - val_precision: 0.9832 - val_recall: 0.9865\n",
      "Epoch 849/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0774 - binary_accuracy: 0.9862 - precision: 0.9832 - recall: 0.9865 - val_loss: 0.0829 - val_binary_accuracy: 0.9723 - val_precision: 0.9964 - val_recall: 0.9426\n",
      "Epoch 850/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0829 - binary_accuracy: 0.9723 - precision: 0.9964 - recall: 0.9426 - val_loss: 0.0857 - val_binary_accuracy: 0.9738 - val_precision: 0.9574 - val_recall: 0.9865\n",
      "Epoch 851/900\n",
      "650/650 [==============================] - 0s 146us/sample - loss: 0.0857 - binary_accuracy: 0.9738 - precision: 0.9574 - recall: 0.9865 - val_loss: 0.1015 - val_binary_accuracy: 0.9569 - val_precision: 0.9855 - val_recall: 0.9189\n",
      "Epoch 852/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1015 - binary_accuracy: 0.9569 - precision: 0.9855 - recall: 0.9189 - val_loss: 0.1187 - val_binary_accuracy: 0.9492 - val_precision: 0.9071 - val_recall: 0.9899\n",
      "Epoch 853/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1187 - binary_accuracy: 0.9492 - precision: 0.9071 - recall: 0.9899 - val_loss: 0.1656 - val_binary_accuracy: 0.9200 - val_precision: 0.9552 - val_recall: 0.8649\n",
      "Epoch 854/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1656 - binary_accuracy: 0.9200 - precision: 0.9552 - recall: 0.8649 - val_loss: 0.3733 - val_binary_accuracy: 0.8508 - val_precision: 0.8241 - val_recall: 0.8547\n",
      "Epoch 855/900\n",
      "650/650 [==============================] - 0s 135us/sample - loss: 0.3733 - binary_accuracy: 0.8508 - precision: 0.8241 - recall: 0.8547 - val_loss: 0.7544 - val_binary_accuracy: 0.7369 - val_precision: 0.6972 - val_recall: 0.7466\n",
      "Epoch 856/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.7544 - binary_accuracy: 0.7369 - precision: 0.6972 - recall: 0.7466 - val_loss: 0.2921 - val_binary_accuracy: 0.8754 - val_precision: 0.9249 - val_recall: 0.7905\n",
      "Epoch 857/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2921 - binary_accuracy: 0.8754 - precision: 0.9249 - recall: 0.7905 - val_loss: 0.6249 - val_binary_accuracy: 0.7477 - val_precision: 0.6813 - val_recall: 0.8378\n",
      "Epoch 858/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.6249 - binary_accuracy: 0.7477 - precision: 0.6813 - recall: 0.8378 - val_loss: 0.4036 - val_binary_accuracy: 0.8492 - val_precision: 0.8837 - val_recall: 0.7703\n",
      "Epoch 859/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.4036 - binary_accuracy: 0.8492 - precision: 0.8837 - recall: 0.7703 - val_loss: 0.3974 - val_binary_accuracy: 0.8385 - val_precision: 0.8259 - val_recall: 0.8176\n",
      "Epoch 860/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.3974 - binary_accuracy: 0.8385 - precision: 0.8259 - recall: 0.8176 - val_loss: 0.3430 - val_binary_accuracy: 0.8646 - val_precision: 0.8562 - val_recall: 0.8446\n",
      "Epoch 861/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.3430 - binary_accuracy: 0.8646 - precision: 0.8562 - recall: 0.8446 - val_loss: 0.2538 - val_binary_accuracy: 0.8969 - val_precision: 0.9288 - val_recall: 0.8378\n",
      "Epoch 862/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.2538 - binary_accuracy: 0.8969 - precision: 0.9288 - recall: 0.8378 - val_loss: 0.3044 - val_binary_accuracy: 0.8415 - val_precision: 0.8249 - val_recall: 0.8277\n",
      "Epoch 863/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.3044 - binary_accuracy: 0.8415 - precision: 0.8249 - recall: 0.8277 - val_loss: 0.2697 - val_binary_accuracy: 0.8769 - val_precision: 0.8750 - val_recall: 0.8514\n",
      "Epoch 864/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.2697 - binary_accuracy: 0.8769 - precision: 0.8750 - recall: 0.8514 - val_loss: 0.1848 - val_binary_accuracy: 0.9169 - val_precision: 0.9231 - val_recall: 0.8919\n",
      "Epoch 865/900\n",
      "650/650 [==============================] - 0s 138us/sample - loss: 0.1848 - binary_accuracy: 0.9169 - precision: 0.9231 - recall: 0.8919 - val_loss: 0.2501 - val_binary_accuracy: 0.8923 - val_precision: 0.9065 - val_recall: 0.8514\n",
      "Epoch 866/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.2501 - binary_accuracy: 0.8923 - precision: 0.9065 - recall: 0.8514 - val_loss: 0.2155 - val_binary_accuracy: 0.9108 - val_precision: 0.8993 - val_recall: 0.9054\n",
      "Epoch 867/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.2155 - binary_accuracy: 0.9108 - precision: 0.8993 - recall: 0.9054 - val_loss: 0.1688 - val_binary_accuracy: 0.9323 - val_precision: 0.9375 - val_recall: 0.9122\n",
      "Epoch 868/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1688 - binary_accuracy: 0.9323 - precision: 0.9375 - recall: 0.9122 - val_loss: 0.2072 - val_binary_accuracy: 0.9062 - val_precision: 0.9502 - val_recall: 0.8378\n",
      "Epoch 869/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.2072 - binary_accuracy: 0.9062 - precision: 0.9502 - recall: 0.8378 - val_loss: 0.1704 - val_binary_accuracy: 0.9262 - val_precision: 0.9493 - val_recall: 0.8851\n",
      "Epoch 870/900\n",
      "650/650 [==============================] - 0s 145us/sample - loss: 0.1704 - binary_accuracy: 0.9262 - precision: 0.9493 - recall: 0.8851 - val_loss: 0.1501 - val_binary_accuracy: 0.9431 - val_precision: 0.9246 - val_recall: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1501 - binary_accuracy: 0.9431 - precision: 0.9246 - recall: 0.9527 - val_loss: 0.1620 - val_binary_accuracy: 0.9415 - val_precision: 0.9607 - val_recall: 0.9088\n",
      "Epoch 872/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1620 - binary_accuracy: 0.9415 - precision: 0.9607 - recall: 0.9088 - val_loss: 0.1567 - val_binary_accuracy: 0.9323 - val_precision: 0.9737 - val_recall: 0.8750\n",
      "Epoch 873/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1567 - binary_accuracy: 0.9323 - precision: 0.9737 - recall: 0.8750 - val_loss: 0.1443 - val_binary_accuracy: 0.9400 - val_precision: 0.9477 - val_recall: 0.9189\n",
      "Epoch 874/900\n",
      "650/650 [==============================] - 0s 136us/sample - loss: 0.1443 - binary_accuracy: 0.9400 - precision: 0.9477 - recall: 0.9189 - val_loss: 0.1457 - val_binary_accuracy: 0.9400 - val_precision: 0.9241 - val_recall: 0.9459\n",
      "Epoch 875/900\n",
      "650/650 [==============================] - 0s 134us/sample - loss: 0.1457 - binary_accuracy: 0.9400 - precision: 0.9241 - recall: 0.9459 - val_loss: 0.1216 - val_binary_accuracy: 0.9569 - val_precision: 0.9558 - val_recall: 0.9493\n",
      "Epoch 876/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.1216 - binary_accuracy: 0.9569 - precision: 0.9558 - recall: 0.9493 - val_loss: 0.1284 - val_binary_accuracy: 0.9492 - val_precision: 0.9817 - val_recall: 0.9054\n",
      "Epoch 877/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1284 - binary_accuracy: 0.9492 - precision: 0.9817 - recall: 0.9054 - val_loss: 0.1293 - val_binary_accuracy: 0.9446 - val_precision: 0.9610 - val_recall: 0.9155\n",
      "Epoch 878/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.1293 - binary_accuracy: 0.9446 - precision: 0.9610 - recall: 0.9155 - val_loss: 0.1105 - val_binary_accuracy: 0.9585 - val_precision: 0.9529 - val_recall: 0.9561\n",
      "Epoch 879/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.1105 - binary_accuracy: 0.9585 - precision: 0.9529 - recall: 0.9561 - val_loss: 0.1087 - val_binary_accuracy: 0.9631 - val_precision: 0.9595 - val_recall: 0.9595\n",
      "Epoch 880/900\n",
      "650/650 [==============================] - 0s 140us/sample - loss: 0.1087 - binary_accuracy: 0.9631 - precision: 0.9595 - recall: 0.9595 - val_loss: 0.1101 - val_binary_accuracy: 0.9585 - val_precision: 0.9786 - val_recall: 0.9291\n",
      "Epoch 881/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.1101 - binary_accuracy: 0.9585 - precision: 0.9786 - recall: 0.9291 - val_loss: 0.1022 - val_binary_accuracy: 0.9631 - val_precision: 0.9857 - val_recall: 0.9324\n",
      "Epoch 882/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.1022 - binary_accuracy: 0.9631 - precision: 0.9857 - recall: 0.9324 - val_loss: 0.0972 - val_binary_accuracy: 0.9738 - val_precision: 0.9761 - val_recall: 0.9662\n",
      "Epoch 883/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0972 - binary_accuracy: 0.9738 - precision: 0.9761 - recall: 0.9662 - val_loss: 0.0991 - val_binary_accuracy: 0.9615 - val_precision: 0.9472 - val_recall: 0.9696\n",
      "Epoch 884/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0991 - binary_accuracy: 0.9615 - precision: 0.9472 - recall: 0.9696 - val_loss: 0.0906 - val_binary_accuracy: 0.9800 - val_precision: 0.9930 - val_recall: 0.9628\n",
      "Epoch 885/900\n",
      "650/650 [==============================] - 0s 151us/sample - loss: 0.0906 - binary_accuracy: 0.9800 - precision: 0.9930 - recall: 0.9628 - val_loss: 0.0928 - val_binary_accuracy: 0.9662 - val_precision: 0.9928 - val_recall: 0.9324\n",
      "Epoch 886/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.0928 - binary_accuracy: 0.9662 - precision: 0.9928 - recall: 0.9324 - val_loss: 0.0864 - val_binary_accuracy: 0.9723 - val_precision: 0.9860 - val_recall: 0.9527\n",
      "Epoch 887/900\n",
      "650/650 [==============================] - 0s 143us/sample - loss: 0.0864 - binary_accuracy: 0.9723 - precision: 0.9860 - recall: 0.9527 - val_loss: 0.0846 - val_binary_accuracy: 0.9831 - val_precision: 0.9831 - val_recall: 0.9797\n",
      "Epoch 888/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0846 - binary_accuracy: 0.9831 - precision: 0.9831 - recall: 0.9797 - val_loss: 0.0826 - val_binary_accuracy: 0.9800 - val_precision: 0.9863 - val_recall: 0.9696\n",
      "Epoch 889/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0826 - binary_accuracy: 0.9800 - precision: 0.9863 - recall: 0.9696 - val_loss: 0.0791 - val_binary_accuracy: 0.9785 - val_precision: 0.9930 - val_recall: 0.9595\n",
      "Epoch 890/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0791 - binary_accuracy: 0.9785 - precision: 0.9930 - recall: 0.9595 - val_loss: 0.0757 - val_binary_accuracy: 0.9815 - val_precision: 0.9863 - val_recall: 0.9730\n",
      "Epoch 891/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0757 - binary_accuracy: 0.9815 - precision: 0.9863 - recall: 0.9730 - val_loss: 0.0745 - val_binary_accuracy: 0.9800 - val_precision: 0.9764 - val_recall: 0.9797\n",
      "Epoch 892/900\n",
      "650/650 [==============================] - 0s 142us/sample - loss: 0.0745 - binary_accuracy: 0.9800 - precision: 0.9764 - recall: 0.9797 - val_loss: 0.0713 - val_binary_accuracy: 0.9831 - val_precision: 0.9897 - val_recall: 0.9730\n",
      "Epoch 893/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.0713 - binary_accuracy: 0.9831 - precision: 0.9897 - recall: 0.9730 - val_loss: 0.0681 - val_binary_accuracy: 0.9815 - val_precision: 0.9965 - val_recall: 0.9628\n",
      "Epoch 894/900\n",
      "650/650 [==============================] - 0s 144us/sample - loss: 0.0681 - binary_accuracy: 0.9815 - precision: 0.9965 - recall: 0.9628 - val_loss: 0.0673 - val_binary_accuracy: 0.9800 - val_precision: 0.9896 - val_recall: 0.9662\n",
      "Epoch 895/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0673 - binary_accuracy: 0.9800 - precision: 0.9896 - recall: 0.9662 - val_loss: 0.0658 - val_binary_accuracy: 0.9815 - val_precision: 0.9897 - val_recall: 0.9696\n",
      "Epoch 896/900\n",
      "650/650 [==============================] - 0s 137us/sample - loss: 0.0658 - binary_accuracy: 0.9815 - precision: 0.9897 - recall: 0.9696 - val_loss: 0.0615 - val_binary_accuracy: 0.9877 - val_precision: 0.9966 - val_recall: 0.9764\n",
      "Epoch 897/900\n",
      "650/650 [==============================] - 0s 139us/sample - loss: 0.0615 - binary_accuracy: 0.9877 - precision: 0.9966 - recall: 0.9764 - val_loss: 0.0608 - val_binary_accuracy: 0.9862 - val_precision: 0.9965 - val_recall: 0.9730\n",
      "Epoch 898/900\n",
      "650/650 [==============================] - 0s 141us/sample - loss: 0.0608 - binary_accuracy: 0.9862 - precision: 0.9965 - recall: 0.9730 - val_loss: 0.0586 - val_binary_accuracy: 0.9892 - val_precision: 0.9932 - val_recall: 0.9831\n",
      "Epoch 899/900\n",
      "650/650 [==============================] - 0s 150us/sample - loss: 0.0586 - binary_accuracy: 0.9892 - precision: 0.9932 - recall: 0.9831 - val_loss: 0.0577 - val_binary_accuracy: 0.9877 - val_precision: 0.9898 - val_recall: 0.9831\n",
      "Epoch 900/900\n",
      "650/650 [==============================] - 0s 155us/sample - loss: 0.0577 - binary_accuracy: 0.9877 - precision: 0.9898 - recall: 0.9831 - val_loss: 0.0546 - val_binary_accuracy: 0.9877 - val_precision: 0.9932 - val_recall: 0.9797\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model for classification\n",
    "tf.keras.backend.clear_session()\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "ts_layer_1 = layers.LSTM(500, return_sequences=True)(num_features)\n",
    "ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1, activation='sigmoid')(ts_layer_5)\n",
    "\n",
    "model = keras.Model(input_log_returns, output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(), metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "print(model.summary())\n",
    "\n",
    "history_cls = model.fit(x=X, y=y_cls, batch_size=batch_size, epochs=900, validation_data =(X, y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(10, 10), tight_layout=True)\n",
    "ax[0].plot(history_cls.history['val_loss'])\n",
    "ax[0].plot(history_cls.history['loss'])\n",
    "ax[0].set_title('loss: Binary Cross Entropy')\n",
    "ax[1].plot(history_cls.history['binary_accuracy'])\n",
    "ax[1].plot(history_cls.history['val_binary_accuracy'])\n",
    "ax[1].set_title('Binary Accuracy')\n",
    "ax[2].plot(history_cls.history['precision'])\n",
    "ax[2].plot(history_cls.history['val_precision'])\n",
    "ax[2].set_title('Precision')\n",
    "ax[3].plot(history_cls.history['recall'])\n",
    "ax[3].plot(history_cls.history['val_recall'])\n",
    "ax[3].set_title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>log_adj_daily_returns_WFC</th>\n",
       "      <th>docs_WFC</th>\n",
       "      <th>log_adj_daily_returns_JPM</th>\n",
       "      <th>docs_JPM</th>\n",
       "      <th>log_adj_daily_returns_BAC</th>\n",
       "      <th>docs_BAC</th>\n",
       "      <th>log_adj_daily_returns_C</th>\n",
       "      <th>docs_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  log_adj_daily_returns_WFC  \\\n",
       "0 2019-10-22                   0.003166   \n",
       "1 2019-10-21                   0.009758   \n",
       "2 2019-10-18                   0.007230   \n",
       "3 2019-10-17                   0.000403   \n",
       "4 2019-10-16                  -0.010431   \n",
       "5 2019-10-15                   0.016905   \n",
       "6 2019-10-14                   0.001219   \n",
       "7 2019-10-11                   0.011445   \n",
       "\n",
       "                                            docs_WFC  \\\n",
       "0  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "6                                                 []   \n",
       "7  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "\n",
       "   log_adj_daily_returns_JPM  \\\n",
       "0                   0.009986   \n",
       "1                   0.024498   \n",
       "2                   0.001743   \n",
       "3                   0.005583   \n",
       "4                  -0.002337   \n",
       "5                   0.029696   \n",
       "6                   0.002666   \n",
       "7                   0.016758   \n",
       "\n",
       "                                            docs_JPM  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "6                                                 []   \n",
       "7                                                 []   \n",
       "\n",
       "   log_adj_daily_returns_BAC  \\\n",
       "0                   0.005786   \n",
       "1                   0.021836   \n",
       "2                   0.002970   \n",
       "3                   0.002979   \n",
       "4                   0.014691   \n",
       "5                   0.020045   \n",
       "6                   0.007924   \n",
       "7                   0.016039   \n",
       "\n",
       "                                            docs_BAC  log_adj_daily_returns_C  \\\n",
       "0                                                 []                 0.003475   \n",
       "1                                                 []                 0.029250   \n",
       "2                                                 []                 0.002009   \n",
       "3                                                 []                 0.001438   \n",
       "4  [\"/media/Data/Programs/FinTech/data/documents/...                -0.024447   \n",
       "5                                                 []                 0.013856   \n",
       "6                                                 []                 0.001995   \n",
       "7                                                 []                 0.021339   \n",
       "\n",
       "                                              docs_C  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
       "6                                                 []  \n",
       "7                                                 []  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset_size = 1000\n",
    "batch_size = 2\n",
    "\n",
    "preprocessed_df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "\n",
    "features_to_test = ['log_adj_daily_returns', 'docs']\n",
    "data_df = preprocessed_df[['timestamp'] + ['_'.join([feature, t]) for t in tickers for feature in features_to_test]]\n",
    "data_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp(t-5)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t-5)</th>\n",
       "      <th>docs_WFC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t-5)</th>\n",
       "      <th>docs_JPM(t-5)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t-5)</th>\n",
       "      <th>docs_BAC(t-5)</th>\n",
       "      <th>log_adj_daily_returns_C(t-5)</th>\n",
       "      <th>docs_C(t-5)</th>\n",
       "      <th>timestamp(t-4)</th>\n",
       "      <th>...</th>\n",
       "      <th>docs_C(t+0)</th>\n",
       "      <th>timestamp(t+1)</th>\n",
       "      <th>log_adj_daily_returns_WFC(t+1)</th>\n",
       "      <th>docs_WFC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_JPM(t+1)</th>\n",
       "      <th>docs_JPM(t+1)</th>\n",
       "      <th>log_adj_daily_returns_BAC(t+1)</th>\n",
       "      <th>docs_BAC(t+1)</th>\n",
       "      <th>log_adj_daily_returns_C(t+1)</th>\n",
       "      <th>docs_C(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.029250</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002979</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>-0.020491</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>-0.022548</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.024313</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-09</td>\n",
       "      <td>...</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>[\"/media/Data/Programs/FinTech/data/documents/...</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp(t-5)  log_adj_daily_returns_WFC(t-5)  \\\n",
       "1     2019-10-14                        0.001219   \n",
       "2     2019-10-11                        0.011445   \n",
       "3     2019-10-10                        0.010331   \n",
       "4     2019-10-09                        0.006877   \n",
       "5     2019-10-08                       -0.020491   \n",
       "\n",
       "                                       docs_WFC(t-5)  \\\n",
       "1                                                 []   \n",
       "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t-5) docs_JPM(t-5)  \\\n",
       "1                        0.002666            []   \n",
       "2                        0.016758            []   \n",
       "3                        0.013931            []   \n",
       "4                        0.007218            []   \n",
       "5                       -0.022548            []   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t-5) docs_BAC(t-5)  log_adj_daily_returns_C(t-5)  \\\n",
       "1                        0.007924            []                      0.001995   \n",
       "2                        0.016039            []                      0.021339   \n",
       "3                        0.019880            []                      0.017494   \n",
       "4                        0.009366            []                      0.015393   \n",
       "5                       -0.024313            []                     -0.026014   \n",
       "\n",
       "  docs_C(t-5) timestamp(t-4)  ...  \\\n",
       "1          []     2019-10-15  ...   \n",
       "2          []     2019-10-14  ...   \n",
       "3          []     2019-10-11  ...   \n",
       "4          []     2019-10-10  ...   \n",
       "5          []     2019-10-09  ...   \n",
       "\n",
       "                                         docs_C(t+0) timestamp(t+1)  \\\n",
       "1                                                 []     2019-10-22   \n",
       "2                                                 []     2019-10-21   \n",
       "3                                                 []     2019-10-18   \n",
       "4                                                 []     2019-10-17   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...     2019-10-16   \n",
       "\n",
       "   log_adj_daily_returns_WFC(t+1)  \\\n",
       "1                        0.003166   \n",
       "2                        0.009758   \n",
       "3                        0.007230   \n",
       "4                        0.000403   \n",
       "5                       -0.010431   \n",
       "\n",
       "                                       docs_WFC(t+1)  \\\n",
       "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "5                                                 []   \n",
       "\n",
       "   log_adj_daily_returns_JPM(t+1) docs_JPM(t+1)  \\\n",
       "1                        0.009986            []   \n",
       "2                        0.024498            []   \n",
       "3                        0.001743            []   \n",
       "4                        0.005583            []   \n",
       "5                       -0.002337            []   \n",
       "\n",
       "   log_adj_daily_returns_BAC(t+1)  \\\n",
       "1                        0.005786   \n",
       "2                        0.021836   \n",
       "3                        0.002970   \n",
       "4                        0.002979   \n",
       "5                        0.014691   \n",
       "\n",
       "                                       docs_BAC(t+1)  \\\n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
       "\n",
       "  log_adj_daily_returns_C(t+1)  docs_C(t+1)  \n",
       "1                     0.003475           []  \n",
       "2                     0.029250           []  \n",
       "3                     0.002009           []  \n",
       "4                     0.001438           []  \n",
       "5                    -0.024447           []  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_time_series(data_df, data_df.columns, n_trail=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'log_adj_daily_returns': ['log_adj_daily_returns_WFC(t-5)', 'log_adj_daily_returns_WFC(t-4)', 'log_adj_daily_returns_WFC(t-3)', 'log_adj_daily_returns_WFC(t-2)', 'log_adj_daily_returns_WFC(t-1)', 'log_adj_daily_returns_WFC(t+0)', 'log_adj_daily_returns_WFC(t+1)'], 'docs': ['docs_WFC(t-5)', 'docs_WFC(t-4)', 'docs_WFC(t-3)', 'docs_WFC(t-2)', 'docs_WFC(t-1)', 'docs_WFC(t+0)', 'docs_WFC(t+1)']}, {'log_adj_daily_returns': ['log_adj_daily_returns_JPM(t-5)', 'log_adj_daily_returns_JPM(t-4)', 'log_adj_daily_returns_JPM(t-3)', 'log_adj_daily_returns_JPM(t-2)', 'log_adj_daily_returns_JPM(t-1)', 'log_adj_daily_returns_JPM(t+0)', 'log_adj_daily_returns_JPM(t+1)'], 'docs': ['docs_JPM(t-5)', 'docs_JPM(t-4)', 'docs_JPM(t-3)', 'docs_JPM(t-2)', 'docs_JPM(t-1)', 'docs_JPM(t+0)', 'docs_JPM(t+1)']}, {'log_adj_daily_returns': ['log_adj_daily_returns_BAC(t-5)', 'log_adj_daily_returns_BAC(t-4)', 'log_adj_daily_returns_BAC(t-3)', 'log_adj_daily_returns_BAC(t-2)', 'log_adj_daily_returns_BAC(t-1)', 'log_adj_daily_returns_BAC(t+0)', 'log_adj_daily_returns_BAC(t+1)'], 'docs': ['docs_BAC(t-5)', 'docs_BAC(t-4)', 'docs_BAC(t-3)', 'docs_BAC(t-2)', 'docs_BAC(t-1)', 'docs_BAC(t+0)', 'docs_BAC(t+1)']}, {'log_adj_daily_returns': ['log_adj_daily_returns_C(t-5)', 'log_adj_daily_returns_C(t-4)', 'log_adj_daily_returns_C(t-3)', 'log_adj_daily_returns_C(t-2)', 'log_adj_daily_returns_C(t-1)', 'log_adj_daily_returns_C(t+0)', 'log_adj_daily_returns_C(t+1)'], 'docs': ['docs_C(t-5)', 'docs_C(t-4)', 'docs_C(t-3)', 'docs_C(t-2)', 'docs_C(t-1)', 'docs_C(t+0)', 'docs_C(t+1)']}]\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['log_adj_daily_returns', 'docs']\n",
    "col_names_obj = [{fn: [name for name in df.columns if '_'.join([fn, t]) in name] for fn in feature_names}\n",
    "             for t in tickers]\n",
    "print(col_names_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_adj_daily_returns features\n",
      "\n",
      "   log_adj_daily_returns_WFC(t-5)  log_adj_daily_returns_WFC(t-4)  \\\n",
      "1                        0.001219                        0.016905   \n",
      "2                        0.011445                        0.001219   \n",
      "3                        0.010331                        0.011445   \n",
      "4                        0.006877                        0.010331   \n",
      "5                       -0.020491                        0.006877   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-3)  log_adj_daily_returns_WFC(t-2)  \\\n",
      "1                       -0.010431                        0.000403   \n",
      "2                        0.016905                       -0.010431   \n",
      "3                        0.001219                        0.016905   \n",
      "4                        0.011445                        0.001219   \n",
      "5                        0.010331                        0.011445   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t-1)  log_adj_daily_returns_WFC(t+0)  \\\n",
      "1                        0.007230                        0.009758   \n",
      "2                        0.000403                        0.007230   \n",
      "3                       -0.010431                        0.000403   \n",
      "4                        0.016905                       -0.010431   \n",
      "5                        0.001219                        0.016905   \n",
      "\n",
      "   log_adj_daily_returns_WFC(t+1)  \n",
      "1                        0.003166  \n",
      "2                        0.009758  \n",
      "3                        0.007230  \n",
      "4                        0.000403  \n",
      "5                       -0.010431  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_JPM(t-5)  log_adj_daily_returns_JPM(t-4)  \\\n",
      "1                        0.002666                        0.029696   \n",
      "2                        0.016758                        0.002666   \n",
      "3                        0.013931                        0.016758   \n",
      "4                        0.007218                        0.013931   \n",
      "5                       -0.022548                        0.007218   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-3)  log_adj_daily_returns_JPM(t-2)  \\\n",
      "1                       -0.002337                        0.005583   \n",
      "2                        0.029696                       -0.002337   \n",
      "3                        0.002666                        0.029696   \n",
      "4                        0.016758                        0.002666   \n",
      "5                        0.013931                        0.016758   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t-1)  log_adj_daily_returns_JPM(t+0)  \\\n",
      "1                        0.001743                        0.024498   \n",
      "2                        0.005583                        0.001743   \n",
      "3                       -0.002337                        0.005583   \n",
      "4                        0.029696                       -0.002337   \n",
      "5                        0.002666                        0.029696   \n",
      "\n",
      "   log_adj_daily_returns_JPM(t+1)  \n",
      "1                        0.009986  \n",
      "2                        0.024498  \n",
      "3                        0.001743  \n",
      "4                        0.005583  \n",
      "5                       -0.002337  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_BAC(t-5)  log_adj_daily_returns_BAC(t-4)  \\\n",
      "1                        0.007924                        0.020045   \n",
      "2                        0.016039                        0.007924   \n",
      "3                        0.019880                        0.016039   \n",
      "4                        0.009366                        0.019880   \n",
      "5                       -0.024313                        0.009366   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-3)  log_adj_daily_returns_BAC(t-2)  \\\n",
      "1                        0.014691                        0.002979   \n",
      "2                        0.020045                        0.014691   \n",
      "3                        0.007924                        0.020045   \n",
      "4                        0.016039                        0.007924   \n",
      "5                        0.019880                        0.016039   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t-1)  log_adj_daily_returns_BAC(t+0)  \\\n",
      "1                        0.002970                        0.021836   \n",
      "2                        0.002979                        0.002970   \n",
      "3                        0.014691                        0.002979   \n",
      "4                        0.020045                        0.014691   \n",
      "5                        0.007924                        0.020045   \n",
      "\n",
      "   log_adj_daily_returns_BAC(t+1)  \n",
      "1                        0.005786  \n",
      "2                        0.021836  \n",
      "3                        0.002970  \n",
      "4                        0.002979  \n",
      "5                        0.014691  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   log_adj_daily_returns_C(t-5)  log_adj_daily_returns_C(t-4)  \\\n",
      "1                      0.001995                      0.013856   \n",
      "2                      0.021339                      0.001995   \n",
      "3                      0.017494                      0.021339   \n",
      "4                      0.015393                      0.017494   \n",
      "5                     -0.026014                      0.015393   \n",
      "\n",
      "   log_adj_daily_returns_C(t-3)  log_adj_daily_returns_C(t-2)  \\\n",
      "1                     -0.024447                      0.001438   \n",
      "2                      0.013856                     -0.024447   \n",
      "3                      0.001995                      0.013856   \n",
      "4                      0.021339                      0.001995   \n",
      "5                      0.017494                      0.021339   \n",
      "\n",
      "   log_adj_daily_returns_C(t-1)  log_adj_daily_returns_C(t+0)  \\\n",
      "1                      0.002009                      0.029250   \n",
      "2                      0.001438                      0.002009   \n",
      "3                     -0.024447                      0.001438   \n",
      "4                      0.013856                     -0.024447   \n",
      "5                      0.001995                      0.013856   \n",
      "\n",
      "   log_adj_daily_returns_C(t+1)  \n",
      "1                      0.003475  \n",
      "2                      0.029250  \n",
      "3                      0.002009  \n",
      "4                      0.001438  \n",
      "5                     -0.024447  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "docs features\n",
      "\n",
      "                                       docs_WFC(t-5)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "\n",
      "                                       docs_WFC(t-4)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_WFC(t-3)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_WFC(t-2)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "\n",
      "                                       docs_WFC(t-1)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_WFC(t+0)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "\n",
      "                                       docs_WFC(t+1)  \n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "5                                                 []  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  docs_JPM(t-5)                                      docs_JPM(t-4)  \\\n",
      "1            []  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2            []                                                 []   \n",
      "3            []                                                 []   \n",
      "4            []                                                 []   \n",
      "5            []                                                 []   \n",
      "\n",
      "                                       docs_JPM(t-3)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_JPM(t-2)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_JPM(t-1)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_JPM(t+0) docs_JPM(t+1)  \n",
      "1                                                 []            []  \n",
      "2                                                 []            []  \n",
      "3                                                 []            []  \n",
      "4                                                 []            []  \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...            []  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  docs_BAC(t-5) docs_BAC(t-4)  \\\n",
      "1            []            []   \n",
      "2            []            []   \n",
      "3            []            []   \n",
      "4            []            []   \n",
      "5            []            []   \n",
      "\n",
      "                                       docs_BAC(t-3)  \\\n",
      "1  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t-2)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t-1)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t+0)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                       docs_BAC(t+1)  \n",
      "1                                                 []  \n",
      "2                                                 []  \n",
      "3                                                 []  \n",
      "4                                                 []  \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  docs_C(t-5)                                        docs_C(t-4)  \\\n",
      "1          []  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "2          []                                                 []   \n",
      "3          []                                                 []   \n",
      "4          []                                                 []   \n",
      "5          []                                                 []   \n",
      "\n",
      "                                         docs_C(t-3)  \\\n",
      "1                                                 []   \n",
      "2  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                         docs_C(t-2)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "4                                                 []   \n",
      "5                                                 []   \n",
      "\n",
      "                                         docs_C(t-1)  \\\n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [\"/media/Data/Programs/FinTech/data/documents/...   \n",
      "5                                                 []   \n",
      "\n",
      "                                         docs_C(t+0) docs_C(t+1)  \n",
      "1                                                 []          []  \n",
      "2                                                 []          []  \n",
      "3                                                 []          []  \n",
      "4                                                 []          []  \n",
      "5  [\"/media/Data/Programs/FinTech/data/documents/...          []  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = [{key: df[d[key]] for key in d} for d in col_names_obj]\n",
    "\n",
    "print('log_adj_daily_returns features')\n",
    "print()\n",
    "for i in range(len(tickers)):\n",
    "    print(dfs[i]['log_adj_daily_returns'].head())\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "print()\n",
    "print('docs features')\n",
    "print()\n",
    "for i in range(len(tickers)):\n",
    "    print(dfs[i]['docs'].head())\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [{key: d[key].values for key in d} for d in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset's features: ['log_adj_daily_returns', 'docs']\n",
      "Testing if each of test_dataset's features have the same length\n",
      "Test passed, test dataset's shape: (5024, 7)\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets[0] # JPM's dataset\n",
    "print('dataset\\'s features: {}'.format(list(dataset.keys())))\n",
    "print('Testing if each of test_dataset\\'s features have the same length')\n",
    "dataset_shape = dataset[list(dataset.keys())[0]].shape\n",
    "assert (dataset[key].shape == dataset_shape for key in dataset.keys())\n",
    "print('Test passed, test dataset\\'s shape: {}'.format(dataset_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of features of test_dataset with labels included: {'log_adj_daily_returns': (5024, 7), 'docs': (5024, 7)}\n",
      "Shapes of features of test_dataset with labels extracted: {'log_adj_daily_returns': (5024, 6), 'docs': (5024, 6)}\n",
      "Shapes of extracted labels from test_dataset: {'log_adj_daily_returns': (5024,)}\n",
      "Testing if the extracted labels match the last column (the final timestep) of the test_dataset\n",
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(dataset, label_names):\n",
    "    labels = {fname: dataset[fname][:, -1] for fname in dataset.keys() if fname in label_names}\n",
    "    features = {fname: dataset[fname][:, :-1] for fname in dataset.keys()}\n",
    "    return features, labels\n",
    "\n",
    "test_dataset_with_labels = extract_labels(dataset, ['log_adj_daily_returns'])\n",
    "test_features, test_labels = test_dataset_with_labels[0], test_dataset_with_labels[1]\n",
    "print('Shapes of features of test_dataset with labels included: {}'.format({fn: dataset[fn].shape for fn in dataset}))\n",
    "print('Shapes of features of test_dataset with labels extracted: {}'.format({fn: test_features[fn].shape for fn in test_features}))\n",
    "print('Shapes of extracted labels from test_dataset: {}'.format({fn: test_labels[fn].shape for fn in test_labels}))\n",
    "print('Testing if the extracted labels match the last column (the final timestep) of the test_dataset')\n",
    "assert np.array_equal(dataset['log_adj_daily_returns'][:, -1], test_labels['log_adj_daily_returns'])\n",
    "print('Test passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_docs_feature's shape:(7,)\n",
      "sample_docs_feature\n",
      "['[]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000383.pickle\"]'\n",
      " '[]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000393.pickle\"]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007742.pickle\"]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007757.pickle\"]'\n",
      " '[\"/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007803.pickle\"]']\n"
     ]
    }
   ],
   "source": [
    "test_sample_docs_feature = dataset['docs'][0] # sample 0's docs features of WFC's dataset\n",
    "print('sample_docs_feature\\'s shape:{}'.format(test_sample_docs_feature.shape))\n",
    "print('sample_docs_feature')\n",
    "print(test_sample_docs_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000383.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0000072971-19-000393.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007742.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007757.pickle',\n",
       " '/media/Data/Programs/FinTech/data/documents/WFC/normalized/encoded/0001387131-19-007803.pickle']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten_docs_feature(docs_feature):\n",
    "    docs = []\n",
    "    for timestep in docs_feature:\n",
    "        docs_list = json.loads(timestep)\n",
    "        docs.extend(docs_list)\n",
    "    return docs\n",
    "\n",
    "flatten_docs_feature(test_sample_docs_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: [  1   1   1 ... 224 225 226]\n",
      "Testing if each timestep contains the same document that was sampled randomly from the original window\n",
      "Test passed\n",
      "window's shape: (7, 1546)\n",
      "window:\n",
      "[[  1   1   1 ... 224 225 226]\n",
      " [  1   1   1 ... 224 225 226]\n",
      " [  1   1   1 ... 224 225 226]\n",
      " ...\n",
      " [  1   1   1 ... 224 225 226]\n",
      " [  1   1   1 ... 224 225 226]\n",
      " [  1   1   1 ... 224 225 226]]\n"
     ]
    }
   ],
   "source": [
    "def decode_docs_feature(docs_feature, seed):\n",
    "    np.random.seed(seed)\n",
    "    docs_names = flatten_docs_feature(docs_feature)\n",
    "    if len(docs_names) != 0:\n",
    "        windows_doc_name = np.random.choice(docs_names, size=1)[0]\n",
    "        with open(windows_doc_name, 'rb') as f:\n",
    "            windows_doc = pickle.load(f)\n",
    "        window = [windows_doc for _ in range(len(docs_feature))]\n",
    "    else:\n",
    "        window = [[] for _ in range(len(docs_feature))]\n",
    "    return np.stack(window, axis=0)\n",
    "\n",
    "test_window = decode_docs_feature(test_sample_docs_feature, None)\n",
    "test_windows_doc = test_window[0]\n",
    "print('document: {}'.format(test_windows_doc))\n",
    "print('Testing if each timestep contains the same document that was sampled randomly from the original window')\n",
    "assert all(np.array_equal(test_window[i], test_windows_doc) for i in range(len(test_window)))\n",
    "print('Test passed')\n",
    "print('window\\'s shape: {}'.format(test_window.shape))\n",
    "print('window:')\n",
    "print(test_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding features and extracting labels\n",
    "features, labels = extract_labels(dataset, ['log_adj_daily_returns'])\n",
    "features_decoded = {key: (value if key != 'docs'\n",
    "                         else list(map(lambda docf: decode_docs_feature(docf, seed), value)))\n",
    "                   for key, value in features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out samples with no document feature\n",
    "mask = [(sample.shape[1] != 0) for sample in features_decoded['docs']]\n",
    "\n",
    "features_filtered = {key: (value[mask, :] if key != 'docs'\n",
    "                           else [value[i] for i in range(len(mask)) if mask[i]])\n",
    "                     for key, value in features_decoded.items()}\n",
    "\n",
    "labels_filtered = {key: value[mask] for key, value in labels.items()}\n",
    "\n",
    "assert (features_filtered['log_adj_daily_returns'].shape[0] == len(features_filtered['docs']) == labels_filtered['log_adj_daily_returns'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling Dataset\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.choice(len(features_filtered['docs']), size=dataset_size, replace=False)\n",
    "\n",
    "features_shuffled = {key: (value[shuffled_indices] if key != 'docs'\n",
    "                           else [value[i] for i in shuffled_indices])\n",
    "                     for key, value in features_filtered.items()}\n",
    "\n",
    "labels_shuffled = {key: value[shuffled_indices] for key, value in labels_filtered.items()}\n",
    "\n",
    "assert (features_shuffled['log_adj_daily_returns'].shape[0] == len(features_shuffled['docs']) == labels_shuffled['log_adj_daily_returns'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_documents(docs_feature):\n",
    "    shapes = map(lambda arr: arr.shape, docs_feature)\n",
    "    longest_doc_len = max(map(lambda shape: shape[-1], shapes))\n",
    "    pad_doc = lambda arr:  np.pad(arr, ((0, 0), (0, longest_doc_len-arr.shape[-1])), constant_values=0)\n",
    "    return np.stack(list(map(pad_doc, docs_feature)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "# Padding Document Features to the max length of a document\n",
    "X = {key: (pad_documents(value) if key == 'docs' else value) for key, value in features_shuffled.items()}\n",
    "y = labels_shuffled['log_adj_daily_returns']\n",
    "print(X['log_adj_daily_returns'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to construct model layers\n",
    "\n",
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                     weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                     input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                     embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                     activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                     mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00045633 -0.01149596  0.01969069  0.00474809 -0.00474809 -0.01346608]\n",
      " [ 0.0141506   0.01302592  0.00030917  0.0152854  -0.00456189 -0.01442841]\n",
      " [ 0.03178836  0.00458189 -0.01178251 -0.01280198  0.00525521  0.03491873]\n",
      " ...\n",
      " [ 0.01023679 -0.00519479  0.01018749 -0.0103665  -0.00305978 -0.0052389 ]\n",
      " [-0.03552021 -0.01716491  0.          0.00061975 -0.01087095 -0.01859904]\n",
      " [ 0.00563817  0.00800301  0.00635725  0.          0.00263458 -0.013784  ]]\n",
      "Shape of num features: (1000, 6)\n",
      "\n",
      "[-4.58744414e-04  1.44284099e-02  1.61850783e-02  1.03306704e-02\n",
      "  1.73141657e-03  0.00000000e+00 -2.61111440e-02  2.52574449e-03\n",
      " -3.71113578e-03 -5.25012589e-03 -2.59110728e-03  7.78406452e-04\n",
      "  7.57920325e-03 -8.54676319e-03  7.53360010e-04  7.28151782e-03\n",
      "  2.93513889e-04 -1.41144445e-03  1.06813910e-02  3.27892122e-04\n",
      "  2.89563131e-02  3.28871610e-03  3.62221522e-02 -2.42930732e-02\n",
      "  8.00114402e-03  8.93654242e-03  1.74397441e-03 -2.69755529e-03\n",
      " -8.27709547e-03  6.32774261e-03  6.61701761e-03 -1.53849485e-03\n",
      " -1.39365347e-02 -1.20737077e-01 -1.89692813e-02 -8.16164498e-03\n",
      " -1.19074668e-02  2.91301708e-02  0.00000000e+00 -1.55228548e-02\n",
      "  3.62894662e-03  1.19383500e-02 -1.90417599e-03 -1.25582619e-02\n",
      " -4.53834037e-03 -1.55528231e-03  3.48117845e-03 -7.96142202e-03\n",
      "  9.00307028e-03 -1.88346550e-02 -2.13485647e-03  1.34308588e-02\n",
      "  3.50970952e-03  9.22243488e-03 -1.81633788e-02  1.84908015e-02\n",
      " -6.32250005e-04 -4.34482569e-03  2.77956972e-02 -2.15749814e-03\n",
      "  3.86221274e-03 -9.43358994e-03  2.62021633e-02 -3.72593496e-02\n",
      "  7.69294315e-03 -1.21045391e-02 -1.70357345e-02  3.74194041e-03\n",
      " -1.10000794e-02 -2.61285080e-02 -9.74203371e-04 -7.06965293e-03\n",
      "  1.79047111e-02  2.00103442e-02  1.14810944e-02  8.80121744e-03\n",
      " -6.50079385e-03  1.18233240e-02  6.65513507e-03  3.25336468e-03\n",
      " -2.03521638e-03 -1.58090067e-02  3.23536686e-03  3.66522470e-04\n",
      " -5.52316570e-02  4.05746585e-03  1.12723263e-02 -8.76004865e-03\n",
      "  6.37290150e-03  1.68628350e-02 -1.05651596e-02 -2.85076448e-02\n",
      " -8.61458486e-03  6.62997081e-03 -5.91406926e-03 -8.44035500e-04\n",
      "  9.92197416e-03  1.68427473e-03  1.37972596e-02  7.75867333e-02\n",
      " -1.56429962e-02  4.07961855e-02 -8.56979675e-04  1.56818829e-03\n",
      " -9.44423655e-03  8.12166489e-03  8.57605178e-03 -5.66301031e-04\n",
      " -1.74531852e-03 -2.14615994e-03  3.76013687e-03 -8.30671114e-03\n",
      "  9.28589446e-03  1.15344162e-02  3.07927943e-03 -7.96469981e-03\n",
      "  1.07713219e-02  2.95552309e-02  7.51831970e-03  6.04883908e-03\n",
      "  1.94119316e-03 -1.66926001e-03 -4.75368224e-03 -1.77692938e-02\n",
      "  5.96021620e-03 -1.85990378e-02  6.96042793e-04 -6.74806783e-03\n",
      "  5.93961775e-03  4.94871161e-03 -5.70137945e-04 -1.04592482e-03\n",
      " -2.28309278e-03 -3.32858075e-03  1.31034525e-02 -1.15940318e-02\n",
      "  9.98952884e-02 -4.66820501e-03  2.68980312e-02 -9.56660477e-03\n",
      "  2.71321817e-02  2.58505800e-03 -1.05114953e-02  3.74859403e-03\n",
      "  1.19391174e-02  7.12591327e-03 -1.16451123e-02  3.59820736e-03\n",
      "  9.05535301e-03 -1.50778668e-02  4.74808799e-03 -6.31966051e-03\n",
      " -1.62896121e-02  4.89797583e-03 -1.08841930e-02  3.27328676e-03\n",
      " -1.20541997e-03  1.00306989e-02  8.04088747e-03 -4.74808799e-03\n",
      " -8.23727620e-03 -2.24093354e-02  7.11755861e-03  8.08442462e-03\n",
      "  1.02822172e-02 -5.43344082e-03  3.11703398e-02 -6.01728697e-03\n",
      " -7.31975228e-03  3.03836923e-03 -7.91149222e-03  2.90933733e-03\n",
      "  3.51206622e-02 -3.39140748e-02  7.05407038e-03  7.24779970e-03\n",
      "  4.53460018e-03  1.46101990e-02 -1.82757013e-02 -7.68303255e-03\n",
      "  2.04280430e-02  4.19751439e-03  1.21088535e-01 -4.00370990e-03\n",
      "  1.03218918e-03 -2.91326335e-02 -8.30761743e-03 -2.87267539e-02\n",
      " -5.75535542e-03  3.37040369e-02 -1.90648652e-02 -1.82779098e-04\n",
      " -8.16615082e-03  2.97750459e-03 -1.93361236e-02  1.37756357e-02\n",
      " -3.19436222e-02  1.53787791e-03 -1.57792638e-02 -1.26431068e-02\n",
      "  7.83223485e-04 -4.56189188e-03 -1.48927722e-02 -5.11233120e-03\n",
      " -8.36382323e-03  9.31442244e-04  7.06452181e-03  0.00000000e+00\n",
      "  1.26307635e-02 -8.66397704e-03  6.01614454e-04  3.43985383e-03\n",
      "  1.95804951e-02 -1.31630039e-02 -8.43559712e-04 -3.31093377e-02\n",
      "  7.32863934e-03 -1.23700159e-02  3.51544564e-03 -1.76135355e-03\n",
      "  9.85223293e-03  1.31151795e-02 -3.67632901e-03 -5.21956489e-03\n",
      "  1.79764642e-02  5.87523805e-03 -1.02627851e-02  1.15008340e-02\n",
      " -1.04947249e-02 -6.60863088e-03 -1.19856994e-02 -4.70073909e-02\n",
      "  6.01750592e-03 -5.88392572e-03 -2.72874415e-03  6.18178057e-03\n",
      "  6.89917973e-03 -3.23293537e-03 -2.17891551e-03 -5.62647810e-03\n",
      "  2.94729261e-04 -8.49735040e-04  0.00000000e+00 -1.69457180e-02\n",
      " -1.16417559e-02 -2.81375270e-02 -3.81591347e-03  1.64199632e-02\n",
      "  4.20123227e-02 -3.12130061e-03  1.64526647e-02  1.87469095e-02\n",
      "  3.23028631e-03 -2.04325924e-02  1.82305140e-02 -4.60225161e-03\n",
      " -7.29058895e-03  1.19347604e-03  1.12467156e-02  1.06373288e-02\n",
      " -7.24633511e-03 -2.69293369e-02 -4.38918489e-02 -8.20379704e-03\n",
      "  1.53215529e-02 -1.77048805e-03  2.68592407e-02  1.02103764e-02\n",
      " -1.75429520e-01  0.00000000e+00  4.21429091e-03  2.60799180e-02\n",
      "  4.45181663e-03  9.53653673e-03  0.00000000e+00 -7.60968015e-03\n",
      "  6.71435914e-03  5.08130985e-03 -3.23616898e-04  2.20063565e-02\n",
      "  1.51819740e-03 -3.82963305e-03  2.41493128e-02  6.21272333e-03\n",
      " -3.09751827e-03 -8.34445986e-03 -1.74266724e-02 -6.11729697e-03\n",
      "  2.30333931e-03 -1.39921657e-02 -7.31004553e-03  2.16475607e-02\n",
      " -9.47821758e-03 -1.52928423e-02  1.37632514e-02  2.96591039e-03\n",
      " -2.16987005e-03  1.37354150e-03  7.22046089e-03 -6.09037304e-03\n",
      " -5.27511336e-03  3.59623310e-03 -1.61796352e-02 -7.80264222e-03\n",
      "  3.69594185e-02  9.50166451e-04 -4.36705454e-03  2.03890028e-03\n",
      " -2.26043169e-03 -2.56286333e-03 -1.90865902e-02 -7.37882470e-03\n",
      " -2.33911295e-03 -6.32150318e-03  4.46313382e-02 -1.28081843e-02\n",
      "  1.88349628e-02 -1.13355286e-02 -2.17978275e-02 -3.64639432e-03\n",
      "  5.47180832e-03  5.06862056e-03  1.13763418e-02 -2.65265308e-03\n",
      "  2.11266760e-02  2.51979610e-02  1.44281374e-02 -1.32008650e-03\n",
      " -4.29996102e-03  1.31240548e-02 -6.97716487e-03 -4.93589672e-03\n",
      "  1.62019746e-02  1.15131455e-02 -5.02644394e-03  1.08737707e-02\n",
      "  2.41432474e-02 -1.75362333e-02  5.28308150e-03  6.44730920e-03\n",
      "  9.22884571e-03 -3.88161092e-04 -4.12526741e-02  3.39619346e-02\n",
      "  6.27836427e-02 -2.76005678e-03  3.05655519e-03 -3.27105266e-03\n",
      " -8.27003564e-03  4.61150769e-02 -1.25682246e-02  7.42353439e-03\n",
      "  2.95850404e-02  8.84155440e-03  1.43244021e-02  3.83809329e-03\n",
      " -6.71018650e-03 -3.06589361e-02  9.33855489e-03  4.37605201e-04\n",
      "  2.27555400e-02 -9.23205743e-03 -8.24088207e-03 -8.60206668e-03\n",
      " -6.65513507e-03  5.84353922e-03 -1.98877414e-03 -2.28188952e-02\n",
      "  4.45728158e-02 -2.54532382e-02 -3.44752525e-04 -1.40049220e-02\n",
      " -3.39015517e-02 -3.23050007e-02 -1.50018646e-02 -2.17563049e-03\n",
      " -9.60559065e-02 -3.62812531e-03  4.09837463e-04 -6.99679870e-03\n",
      " -6.96072478e-03  2.26208938e-03  2.02468113e-02 -1.52537179e-02\n",
      "  8.31869074e-03  1.45938753e-02  1.50423537e-03 -9.47912850e-02\n",
      " -1.16196524e-02  6.48221523e-03 -6.39880119e-03 -1.52123869e-02\n",
      "  5.30346376e-03  2.18398037e-02  0.00000000e+00 -2.00543925e-04\n",
      "  7.38381600e-04 -1.56117469e-02 -1.21539579e-03  2.57441684e-02\n",
      "  2.33638009e-02  5.38917447e-03 -3.18281661e-02 -1.31771517e-02\n",
      "  2.51336262e-02 -2.04255418e-02  1.14877781e-02  5.88810119e-04\n",
      " -1.37037226e-03  1.76904836e-02  1.27375990e-03 -9.67773266e-02\n",
      " -1.94843146e-02 -1.38048305e-02 -6.28478743e-03 -3.81400433e-02\n",
      "  1.11419688e-02 -1.72104072e-02  4.88787064e-03 -6.54929072e-03\n",
      "  2.41505468e-03 -2.02916308e-03  7.76400511e-03  1.14254430e-02\n",
      "  1.29617811e-02 -1.55382109e-02  1.97782319e-02  0.00000000e+00\n",
      "  1.34015762e-02  1.81350552e-02  1.73908932e-03  5.48952466e-03\n",
      "  3.20374088e-02 -6.50050567e-03 -2.28454362e-02 -1.68063992e-02\n",
      " -6.07814156e-02 -7.12254566e-03 -1.23689159e-02 -3.61547848e-03\n",
      " -7.67365973e-03  4.35077209e-03 -1.07286684e-02 -5.34740814e-03\n",
      "  1.37305262e-02 -3.95291796e-03 -1.92198569e-03 -9.33790992e-03\n",
      "  4.80252908e-03 -1.67332585e-02 -1.99621816e-02 -6.69334905e-03\n",
      " -5.83374508e-03  1.57480031e-02  9.08790574e-03  7.23039904e-03\n",
      "  1.14849499e-02 -7.32716615e-03 -1.60377826e-02 -8.67985598e-03\n",
      "  1.02082492e-03 -1.10009436e-02  2.68933221e-02 -3.07208047e-03\n",
      "  2.25335390e-02  5.64509045e-03  6.93359501e-03 -4.40235289e-03\n",
      "  1.30802820e-02 -2.10850477e-03  1.78030376e-02 -3.02093969e-02\n",
      " -1.63792769e-02  1.91637066e-03  8.78306951e-03  2.56897074e-03\n",
      " -9.80955439e-03 -1.12621489e-03  1.34959064e-02 -2.85121368e-02\n",
      "  1.45758476e-03  8.73347951e-03 -1.02362620e-02 -3.37260516e-03\n",
      " -4.40066506e-03  0.00000000e+00 -7.79810245e-03 -5.56921363e-03\n",
      " -1.69261917e-02  1.08752061e-02 -4.28741811e-03  1.16531597e-02\n",
      "  2.55633922e-03 -4.97588580e-03 -1.26816501e-02  5.70004334e-03\n",
      " -3.94967164e-03  1.08980126e-02 -3.21242097e-02  4.07377619e-02\n",
      " -5.44641722e-04  6.38346783e-02  0.00000000e+00  2.27692868e-02\n",
      " -1.64270799e-02  3.06811198e-03 -1.48158840e-02 -3.50658703e-03\n",
      "  1.64545401e-02 -2.54064373e-03 -5.85781430e-03  6.26670457e-03\n",
      "  9.50363801e-03 -5.91854332e-03 -2.87171765e-02  3.50313057e-03\n",
      " -4.39093215e-03 -3.00411434e-03 -3.19646648e-04  2.02342052e-02\n",
      " -4.41246240e-02  1.09149734e-03 -5.66515496e-04  2.06964256e-02\n",
      " -1.17754512e-03  3.05544774e-03  6.66064355e-02 -5.37624762e-03\n",
      " -7.70209809e-03 -4.39932555e-02 -8.76823764e-03  1.08958636e-03\n",
      "  2.20788113e-03 -2.06862355e-02 -1.35090778e-02 -1.02155673e-02\n",
      " -2.28967909e-02 -3.10384172e-02  9.78761015e-03  3.45921163e-02\n",
      "  4.03571025e-03 -3.27052153e-03  5.99802777e-03 -1.39343546e-02\n",
      " -2.37831792e-02  2.38450336e-02  1.05830880e-02  1.09498144e-03\n",
      "  8.00300942e-03  2.01542352e-02  2.92016058e-02  3.33461695e-02\n",
      "  4.96027084e-02 -6.17173143e-03 -2.49634217e-02  7.61817157e-03\n",
      "  3.44999617e-02 -1.14890561e-03 -4.79232641e-03  1.44351577e-03\n",
      "  1.26862680e-02  2.16697818e-02  2.89581914e-03 -3.96787737e-02\n",
      "  6.02459666e-04  1.11369801e-02  4.91128557e-03  7.15901440e-03\n",
      "  4.09069664e-04  3.17591865e-02  1.77026264e-02  1.83280317e-03\n",
      " -3.34201549e-03 -3.30516509e-03  4.02718157e-03  2.44885237e-02\n",
      "  1.33081781e-02 -1.78862178e-02  1.59874418e-03 -1.29593824e-03\n",
      " -6.63965649e-03  1.07680392e-03  1.75711981e-04  2.13714854e-02\n",
      "  0.00000000e+00  1.00145935e-02 -7.64302936e-03 -1.03931342e-02\n",
      "  1.10399047e-02 -1.42287070e-03 -1.30941392e-02  2.59671468e-03\n",
      " -1.26766959e-02 -6.60345693e-03 -1.38664300e-02 -1.25740838e-02\n",
      "  7.78909830e-03 -3.18358193e-02 -1.04258136e-03 -6.99086147e-03\n",
      " -1.13299721e-02 -2.54079538e-02 -6.80256643e-03 -1.04313885e-02\n",
      "  4.63117995e-03 -6.30267459e-03  1.69052124e-02  2.92287501e-03\n",
      "  3.81725528e-03  6.19729022e-03  1.98153976e-02 -5.31869877e-03\n",
      " -8.40684485e-03 -1.26234895e-02 -1.26776843e-03  3.20025819e-02\n",
      "  4.83825376e-03 -4.77560632e-03  1.78849232e-02  1.78676513e-03\n",
      " -9.77508371e-03 -4.28688394e-02  4.40584020e-03 -9.63830646e-03\n",
      "  5.98959673e-03  1.15648973e-02 -1.30352817e-03  1.08303239e-02\n",
      " -2.55452831e-03 -1.93155341e-02  7.62972759e-03 -1.01966822e-02\n",
      "  3.16503187e-02 -3.15790753e-02  3.02791100e-02 -8.52967595e-04\n",
      " -6.13816320e-03 -3.47291940e-04 -2.10214871e-03  3.40836145e-03\n",
      "  0.00000000e+00  2.53272903e-02 -1.52683917e-03 -5.41748732e-03\n",
      "  5.02792927e-02 -2.81374384e-03  3.47159518e-03 -1.30517993e-02\n",
      "  3.16366970e-02 -4.08830750e-04  6.10234685e-03  6.94858521e-03\n",
      " -9.39935538e-03 -1.92814437e-02  1.32685430e-03  2.71218586e-03\n",
      " -4.92195918e-03 -2.69083570e-02  1.06105921e-02 -5.56529215e-03\n",
      "  4.23143123e-03 -9.02618670e-03  9.48955633e-03  6.28742887e-03\n",
      " -5.89980387e-02  1.45552405e-02 -7.91314043e-03 -1.02724301e-02\n",
      " -1.07726016e-02  1.64994835e-02  1.38798486e-02 -1.66565421e-04\n",
      "  5.28228497e-03  2.36877221e-03 -6.19549605e-03 -5.77021605e-02\n",
      "  3.51123360e-03  8.08960682e-04 -2.06232691e-02 -7.13039126e-04\n",
      " -7.27513997e-03 -2.05187099e-03  2.37592135e-03 -1.69421983e-03\n",
      "  6.15194282e-03  4.69480158e-02  1.96418641e-02  2.78534613e-02\n",
      "  1.17706610e-02 -4.12384638e-02 -7.19451110e-04 -1.26952787e-02\n",
      "  2.26971422e-02 -4.77413305e-03 -1.26331150e-02  2.50101752e-02\n",
      "  8.13324009e-03 -6.22747073e-03  7.39562970e-03 -1.02591066e-02\n",
      " -7.29723590e-03 -4.14663669e-03 -1.61633149e-02 -1.08399922e-02\n",
      "  0.00000000e+00  1.23113686e-02  7.13651557e-03  8.40474391e-03\n",
      "  4.25757350e-03  1.26290718e-02  8.44035500e-04  9.95575305e-03\n",
      "  2.09167776e-03 -2.29447472e-02  4.86524264e-03  3.05793140e-03\n",
      "  6.40224614e-03  2.64256147e-02 -1.84833335e-03 -1.54513394e-02\n",
      "  1.84056872e-02 -9.30710087e-02 -2.72212634e-02 -7.94019882e-03\n",
      "  4.12695564e-03 -1.57238511e-02  7.40224601e-03 -1.07663447e-02\n",
      "  1.81824103e-02 -3.65403935e-03  8.00457592e-03  5.26067575e-03\n",
      "  2.16884863e-03 -2.99643228e-03  1.09216847e-02 -1.92174666e-02\n",
      " -1.52475357e-02  7.35332020e-03  1.19357329e-01 -1.14787762e-02\n",
      " -1.24579640e-02 -1.44284099e-02 -4.87677486e-03  3.56025118e-02\n",
      " -5.29472014e-02  5.25940788e-03  2.35781036e-03 -8.43699175e-03\n",
      "  1.12801205e-02 -1.75502455e-02  8.34199011e-03  7.74633981e-03\n",
      "  6.23349901e-03  7.68908804e-03 -1.98416740e-02 -1.72149367e-02\n",
      "  6.91457032e-04  6.67880577e-03 -2.04912479e-02  2.23907286e-03\n",
      "  7.83598585e-03  1.42735441e-02  1.37198267e-02  7.06532418e-03\n",
      "  1.60624951e-01  7.18090341e-03  8.53321391e-03  9.03528225e-03\n",
      " -2.03122014e-02 -6.01311564e-03  1.44184440e-02 -1.05086600e-02\n",
      "  7.23701801e-03 -5.19478664e-03  2.22126201e-02 -6.95236475e-02\n",
      "  1.61556850e-02 -2.40893595e-02  1.86238586e-03  1.18828427e-02\n",
      "  1.33213615e-02 -1.35041264e-02 -1.97042753e-02 -2.24489153e-03\n",
      "  1.17541323e-02 -6.19819804e-03 -6.01381097e-02 -4.13032155e-03\n",
      " -3.55202122e-02  1.29411199e-02  4.03225812e-04 -2.52891036e-02\n",
      " -7.96399997e-03  5.51444960e-03 -5.77691884e-03  1.91768164e-02\n",
      " -4.77439576e-02 -4.50174691e-03  1.96230646e-02 -1.47373363e-02\n",
      "  4.77667257e-03  3.48943515e-02 -1.01595472e-03  2.10708933e-02\n",
      " -1.75433938e-02 -1.09166301e-02  7.98560669e-03  1.35644042e-03\n",
      "  2.15336791e-02 -1.02386667e-02  2.98422207e-02  1.75414713e-02\n",
      " -2.08387318e-03 -1.27395708e-02  3.94041477e-03  3.73827703e-03\n",
      "  3.26656480e-03 -2.08746666e-02  1.09165363e-02  5.52991068e-04\n",
      " -4.88375669e-03  1.49627341e-02  7.95250193e-03  1.45578488e-02\n",
      " -1.40988844e-02 -6.83530179e-03 -9.36809334e-03 -5.72036848e-03\n",
      "  1.09328085e-02  6.15026401e-03  5.98035518e-02 -3.96283067e-03\n",
      "  2.21721343e-02 -1.71757477e-02 -4.10256986e-03 -7.70876977e-03\n",
      "  1.45859579e-02  1.08369305e-02  3.25118906e-03  1.42987235e-03\n",
      " -8.54837348e-03  7.40529663e-03  7.66937015e-04  1.06876094e-02\n",
      " -1.09561931e-02 -1.16935344e-02 -1.96771124e-04 -1.18318588e-02\n",
      " -2.69425706e-02  7.46894867e-03  6.98191852e-03  1.06765150e-02\n",
      "  2.82089857e-03  1.21889689e-02 -2.07300826e-02  6.32641248e-03\n",
      "  1.24505203e-03 -4.43549738e-03  8.55983621e-03 -2.85801194e-02\n",
      " -6.03366198e-02  5.37347890e-03 -2.79175462e-02  2.04708790e-03\n",
      " -8.07965303e-03 -1.79227165e-04 -8.68971954e-03 -1.18923728e-03\n",
      "  4.30063088e-02  1.22480485e-02 -5.59881560e-03  2.28441768e-02\n",
      " -1.01104394e-02 -1.54091269e-02  1.32998979e-02 -7.69809197e-04\n",
      " -5.04235343e-03 -1.54310286e-02 -2.09454171e-03 -1.96104963e-03\n",
      " -1.43590803e-02  1.00703072e-02 -2.82157946e-04  2.24708532e-02\n",
      " -8.84112377e-03  5.75054054e-03 -1.60474122e-02  0.00000000e+00\n",
      "  9.56211944e-04 -1.70615894e-03 -1.84404798e-02  1.75074242e-03\n",
      "  2.39276831e-02  2.11899763e-03 -1.52110098e-02  4.16897465e-03\n",
      "  1.52379873e-02  4.91187932e-03  7.05619920e-03  3.20557369e-03\n",
      " -1.81839518e-03 -1.32173607e-02 -2.24375338e-02 -8.48920011e-03\n",
      "  2.07216806e-02 -9.43976145e-03  1.04430375e-02  1.01849746e-03\n",
      " -8.30527819e-02  1.73103447e-02 -2.11549278e-02  2.99691065e-03\n",
      " -1.71118988e-02 -4.07436320e-03  1.29600821e-02 -7.56846610e-03\n",
      " -4.70188359e-03  2.15058208e-02  1.64215906e-03  7.28961359e-03\n",
      "  2.22596768e-03 -5.83672883e-03  2.17926502e-02 -1.37815274e-03\n",
      " -5.51818751e-02 -1.22663599e-02  8.36218109e-04 -1.20989890e-02\n",
      "  1.87908478e-02  2.30157134e-02 -2.02755106e-02  1.91884513e-02\n",
      "  5.68622608e-04 -7.80036750e-03 -1.39849030e-02 -2.23910259e-02\n",
      "  1.85970584e-03  5.83610893e-03 -1.33404725e-02 -1.16372768e-02\n",
      " -5.48582492e-03 -9.94189516e-03 -6.94546578e-03  6.71060272e-02\n",
      " -1.08632729e-01  2.26983450e-03  7.51337251e-03 -1.13555753e-02\n",
      " -1.73495552e-02  2.50838414e-03 -1.66458936e-02  1.69744303e-02\n",
      "  8.98271791e-03  2.75344237e-01  1.89403213e-02  1.87918080e-04\n",
      "  1.00710538e-02 -3.65196754e-03  5.83061295e-02  9.16000769e-03\n",
      " -2.26635859e-02  4.90217442e-03  0.00000000e+00 -1.82148704e-03\n",
      " -2.79753283e-03 -5.30295851e-03 -1.58760775e-02  6.77174153e-02\n",
      " -1.63829559e-03 -1.43455746e-02  1.18430236e-02 -1.66588535e-02\n",
      "  2.00574264e-02  1.03015606e-02 -5.08018887e-04  1.89598498e-03\n",
      "  1.51599007e-02  7.80343323e-03  2.80316202e-02  1.19961187e-02\n",
      " -2.43174176e-02  5.42255745e-03  1.22314785e-02 -4.53460018e-03\n",
      " -4.74708554e-03  1.38414839e-02 -6.77894888e-03  4.20298783e-03\n",
      "  1.07814906e-03  2.00198476e-03 -5.66529533e-03  8.73692062e-03\n",
      "  9.93170032e-03 -5.12860764e-03  1.04729982e-02 -5.27679215e-02\n",
      "  2.36897997e-02 -3.99503512e-03  4.44506428e-03 -1.33632621e-03]\n",
      "Shape of labels: (1000,)\n",
      "[[[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]\n",
      "\n",
      " [[64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]\n",
      "  [64 25 65 ...  0  0  0]]]\n",
      "Shapes of docs features: (1000, 6, 2879)\n",
      "Testing if each document at each timestep for all samples in docs feature is equal each other\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test past\n"
     ]
    }
   ],
   "source": [
    "# Inspecting Dataset\n",
    "print(X['log_adj_daily_returns'])\n",
    "print('Shape of num features: {}'.format(X['log_adj_daily_returns'].shape))\n",
    "print()\n",
    "print(y)\n",
    "print('Shape of labels: {}'.format(y.shape))\n",
    "print(X['docs'])\n",
    "print('Shapes of docs features: {}'.format(X['docs'].shape))\n",
    "print('Testing if each document at each timestep for all samples in docs feature is equal each other')\n",
    "assert all(np.array_equal(X['docs'][s, i], X['docs'][s, j]) for s in range(dataset_size) for i in range(6) for j in range(6))\n",
    "print('Test past')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "                                                                 embedding[2][0]                  \n",
      "                                                                 embedding[3][0]                  \n",
      "                                                                 embedding[4][0]                  \n",
      "                                                                 embedding[5][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[5][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "32\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "  32/1000 [..............................] - ETA: 3:16"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function len> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_num_elements\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    615\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`grad` not a Tensor or IndexedSlices.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'NoneType'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7335a7449b62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    596\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No gradients to aggregate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "#word_embedding_layers = [word_embedding(timeslice_layers[timestep]) for timestep in range(6)]\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "#document_embedding_layers = [document_embedding(word_embedding_layers[timestep]) for timestep in range(6)]\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_4,\n",
    "                                                           document_embedding_layer_5])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Investigating crash of regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears from the above cell that the model is crashing somewhere in its backpropagation step. From inspection of the source code it seems like there are some issues with the shapes of gradients when slicing the docs input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 6s 629ms/sample - loss: 0.0358 - val_loss: 0.0505\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 22ms/sample - loss: 0.0449 - val_loss: 0.0110\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 20ms/sample - loss: 0.0194 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 19ms/sample - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0048 - val_loss: 6.3182e-04\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 3.1893e-04 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 16ms/sample - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0017 - val_loss: 6.6464e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above cell it appears that if we take only one slice layer and copy it multiple times then apply our stack layer, the model seems to backpropagate fine. This implies maybe there might be something up with the stack layer: doc_features_layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "                                                                 embedding[2][0]                  \n",
      "                                                                 embedding[3][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 15s 1s/sample - loss: 0.0482 - val_loss: 0.0527\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 62ms/sample - loss: 0.0360 - val_loss: 0.0182\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 62ms/sample - loss: 0.0176 - val_loss: 0.0128\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 61ms/sample - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 60ms/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 62ms/sample - loss: 0.0067 - val_loss: 0.0028\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 61ms/sample - loss: 0.0015 - val_loss: 4.3584e-04\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 61ms/sample - loss: 9.8736e-04 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 57ms/sample - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 63ms/sample - loss: 0.0016 - val_loss: 4.9223e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False, input_length=1466)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "                                                                 embedding[2][0]                  \n",
      "                                                                 embedding[3][0]                  \n",
      "                                                                 embedding[4][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[1][0]                       \n",
      "                                                                 lstm[2][0]                       \n",
      "                                                                 lstm[3][0]                       \n",
      "                                                                 lstm[4][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      " 4/10 [===========>..................] - ETA: 8s"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "PyEval_EvalFrameEx returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_num_elements\u001b[0;34m(grad)\u001b[0m\n\u001b[1;32m    615\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m   \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`grad` not a Tensor or IndexedSlices.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'NoneType'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function len> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0c497bc01f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m: PyEval_EvalFrameEx returned a result with an error set"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(timeslice_layers[0])\n",
    "word_embedding_layer_1 = word_embedding(timeslice_layers[1])\n",
    "word_embedding_layer_2 = word_embedding(timeslice_layers[2])\n",
    "word_embedding_layer_3 = word_embedding(timeslice_layers[3])\n",
    "word_embedding_layer_4 = word_embedding(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(timeslice_layers[5])\n",
    "#word_embedding_layers = [word_embedding(timeslice_layers[timestep]) for timestep in range(6)]\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "#document_embedding_layers = [document_embedding(word_embedding_layers[timestep]) for timestep in range(6)]\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_4,\n",
    "                                                           document_embedding_layer_0])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))\n",
    "\n",
    "# the overall state of the hardware is effected too, when I get a single crash from changing 0 --> 4 \n",
    "# if I change 4 ---> 0 then i get the same crash, if I reset tensorflow then it works "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above to cells we find that the backpropagation crashes when we try to apply our stack layer to a list of more than 3 unique slice layers (as opposed to a list of contains less than 3 unique slice layers where the empty slots are filled with copies of already included slice layers). This further supports that maybe the stacking layer is the cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, None)      0           lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, None)         0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_14[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 6s 571ms/sample - loss: 0.0310 - val_loss: 0.0210\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 19ms/sample - loss: 0.0359 - val_loss: 0.0099\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0094 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0027 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 20ms/sample - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 19ms/sample - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 18ms/sample - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 17ms/sample - loss: 0.0020 - val_loss: 6.8931e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "timeslice_layer_0 = timeslice_layers[0]\n",
    "timeslice_layer_1 = timeslice_layers[1]\n",
    "timeslice_layer_2 = timeslice_layers[2]\n",
    "timeslice_layer_3 = timeslice_layers[3]\n",
    "timeslice_layer_4 = timeslice_layers[4]\n",
    "timeslice_layer_5 = timeslice_layers[5]\n",
    "\n",
    "# Rebuilding Original Input from Time Slices\n",
    "rebuilt_input_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)), \n",
    "                                    output_shape=(6, None))([timeslice_layer_0,\n",
    "                                                            timeslice_layer_1,\n",
    "                                                            timeslice_layer_2,\n",
    "                                                            timeslice_layer_3,\n",
    "                                                            timeslice_layer_4,\n",
    "                                                            timeslice_layer_5])\n",
    "                                    \n",
    "doc_layer_0 = layers.Lambda((lambda x: x[:, 0, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_1 = layers.Lambda((lambda x: x[:, 1, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_2 = layers.Lambda((lambda x: x[:, 2, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_3 = layers.Lambda((lambda x: x[:, 3, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_4 = layers.Lambda((lambda x: x[:, 4, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "doc_layer_5 = layers.Lambda((lambda x: x[:, 5, :]), output_shape=(None,))(rebuilt_input_layer)\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = word_embedding(doc_layer_0)\n",
    "word_embedding_layer_1 = word_embedding(doc_layer_1)\n",
    "word_embedding_layer_2 = word_embedding(doc_layer_2)\n",
    "word_embedding_layer_3 = word_embedding(doc_layer_3)\n",
    "word_embedding_layer_4 = word_embedding(doc_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = word_embedding(doc_layer_5)\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "document_embedding_layer_0 = document_embedding(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = document_embedding(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = document_embedding(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = document_embedding(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = document_embedding(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = document_embedding(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_0])\n",
    "\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "print(batch_size)\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to test our stacking layer, by slicing the input_docs layer, and immediately stacking all unique slices of it, then applying a sequence of layers we know backpropagation doesn't break on. The results show that our stacking layer isn't at fault. This implies that there is something up with the layers that we apply to each slice (word_embedding, and doc_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None)         0           docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    2747100     lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    2747100     lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 300)    2747100     lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 300)    2747100     lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 300)    2747100     lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 300)    2747100     lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100)          160400      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 100)          160400      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 100)          160400      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 100)          160400      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 100)          160400      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 6, 100)       0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "                                                                 lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 17,462,185\n",
      "Trainable params: 979,585\n",
      "Non-trainable params: 16,482,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 23s 2s/sample - loss: 0.0108 - val_loss: 0.0158\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 0.0220 - val_loss: 0.0066\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 82ms/sample - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 85ms/sample - loss: 0.0015 - val_loss: 4.0027e-04\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 82ms/sample - loss: 2.8220e-04 - val_loss: 4.5561e-04\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 87ms/sample - loss: 6.0313e-04 - val_loss: 6.8137e-04\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 84ms/sample - loss: 7.0505e-04 - val_loss: 7.7796e-04\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 82ms/sample - loss: 8.3631e-04 - val_loss: 5.7608e-04\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 80ms/sample - loss: 5.4261e-04 - val_loss: 3.1418e-04\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 83ms/sample - loss: 2.8344e-04 - val_loss: 1.4857e-04\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs', dtype=tf.int64)\n",
    "\n",
    "# Slicing Document Input Layer along time axis\n",
    "timeslice_layers = [layers.Lambda((lambda x: x[:, timestep, :]), output_shape=(None,))(input_docs)\n",
    "                    for timestep in range(6)]\n",
    "\n",
    "# Building Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "word_embedding_layer_0 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[0])\n",
    "word_embedding_layer_1 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[1])\n",
    "word_embedding_layer_2 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[2])\n",
    "word_embedding_layer_3 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[3])\n",
    "word_embedding_layer_4 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[4]) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "word_embedding_layer_5 = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(timeslice_layers[5])\n",
    "\n",
    "# Building Document Embedding Layer\n",
    "document_embedding_layer_0 = layers.LSTM(100)(word_embedding_layer_0)\n",
    "document_embedding_layer_1 = layers.LSTM(100)(word_embedding_layer_1)\n",
    "document_embedding_layer_2 = layers.LSTM(100)(word_embedding_layer_2)\n",
    "document_embedding_layer_3 = layers.LSTM(100)(word_embedding_layer_3)\n",
    "document_embedding_layer_4 = layers.LSTM(100)(word_embedding_layer_4) # adding the 5th timeslice does weird stuf, the model trains with all the previous 4 timeslices\n",
    "document_embedding_layer_5 = layers.LSTM(100)(word_embedding_layer_5)\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features_layer = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)),\n",
    "                                   output_shape=(6, 1))(input_log_returns)\n",
    "doc_features_layer = layers.Lambda((lambda x: keras.backend.stack(x, axis=1)),\n",
    "                                   output_shape=(6, 100))([document_embedding_layer_0,\n",
    "                                                           document_embedding_layer_1,\n",
    "                                                           document_embedding_layer_2,\n",
    "                                                           document_embedding_layer_3,\n",
    "                                                           document_embedding_layer_4,\n",
    "                                                           document_embedding_layer_5])\n",
    "ts_input = layers.Concatenate()([doc_features_layer, num_features_layer])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=10, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we created seperate word_embedding_layers and document_embedding_layers for each slice layer ie the document and word embedding layers are seperated for each slice, and do not share weights between each slice. Backpropagation seems to work which implies that the error is raised because of the logic of sharing weights between slice layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebuilding Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 100)       2907500     docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           time_distributed[0][0]           \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/90\n",
      "1000/1000 [==============================] - 35s 35ms/sample - loss: 0.0017 - val_loss: 4.9786e-04\n",
      "Epoch 2/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 6.5899e-04 - val_loss: 5.7934e-04\n",
      "Epoch 3/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 6.3177e-04 - val_loss: 6.6666e-04\n",
      "Epoch 4/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.9128e-04 - val_loss: 6.4479e-04\n",
      "Epoch 5/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.9067e-04 - val_loss: 5.0854e-04\n",
      "Epoch 6/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 5.7249e-04 - val_loss: 5.7958e-04\n",
      "Epoch 7/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.6090e-04 - val_loss: 9.4620e-04\n",
      "Epoch 8/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.4607e-04 - val_loss: 5.2152e-04\n",
      "Epoch 9/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.3434e-04 - val_loss: 4.6628e-04\n",
      "Epoch 10/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 5.2841e-04 - val_loss: 5.1600e-04\n",
      "Epoch 11/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 5.1052e-04 - val_loss: 5.3288e-04\n",
      "Epoch 12/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 5.0705e-04 - val_loss: 4.8728e-04\n",
      "Epoch 13/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.9052e-04 - val_loss: 4.6473e-04\n",
      "Epoch 14/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.7652e-04 - val_loss: 6.2512e-04\n",
      "Epoch 15/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.8027e-04 - val_loss: 4.7239e-04\n",
      "Epoch 16/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.9658e-04 - val_loss: 4.5157e-04\n",
      "Epoch 17/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.6760e-04 - val_loss: 5.3258e-04\n",
      "Epoch 18/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.7000e-04 - val_loss: 4.3948e-04\n",
      "Epoch 19/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.6141e-04 - val_loss: 4.6436e-04\n",
      "Epoch 20/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.6664e-04 - val_loss: 4.5532e-04\n",
      "Epoch 21/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.5985e-04 - val_loss: 4.2675e-04\n",
      "Epoch 22/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.4986e-04 - val_loss: 4.3588e-04\n",
      "Epoch 23/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.5144e-04 - val_loss: 4.7808e-04\n",
      "Epoch 24/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.5288e-04 - val_loss: 4.3577e-04\n",
      "Epoch 25/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.4376e-04 - val_loss: 4.1846e-04\n",
      "Epoch 26/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.3493e-04 - val_loss: 4.9607e-04\n",
      "Epoch 27/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.4078e-04 - val_loss: 4.4006e-04\n",
      "Epoch 28/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.3552e-04 - val_loss: 4.2236e-04\n",
      "Epoch 29/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.3304e-04 - val_loss: 4.2932e-04\n",
      "Epoch 30/90\n",
      "1000/1000 [==============================] - 30s 30ms/sample - loss: 4.3580e-04 - val_loss: 4.2268e-04\n",
      "Epoch 31/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.3876e-04 - val_loss: 4.4171e-04\n",
      "Epoch 32/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.3573e-04 - val_loss: 4.1188e-04\n",
      "Epoch 33/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2873e-04 - val_loss: 4.0975e-04\n",
      "Epoch 34/90\n",
      "1000/1000 [==============================] - 46s 46ms/sample - loss: 4.2602e-04 - val_loss: 4.0766e-04\n",
      "Epoch 35/90\n",
      "1000/1000 [==============================] - 43s 43ms/sample - loss: 4.2625e-04 - val_loss: 4.4234e-04\n",
      "Epoch 36/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2637e-04 - val_loss: 4.1504e-04\n",
      "Epoch 37/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2436e-04 - val_loss: 4.1370e-04\n",
      "Epoch 38/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2547e-04 - val_loss: 4.0619e-04\n",
      "Epoch 39/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.2309e-04 - val_loss: 4.0600e-04\n",
      "Epoch 40/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2192e-04 - val_loss: 4.0663e-04\n",
      "Epoch 41/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.1907e-04 - val_loss: 4.2560e-04\n",
      "Epoch 42/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2815e-04 - val_loss: 4.1109e-04\n",
      "Epoch 43/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.2260e-04 - val_loss: 4.0065e-04\n",
      "Epoch 44/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1934e-04 - val_loss: 3.9744e-04\n",
      "Epoch 45/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2213e-04 - val_loss: 4.0005e-04\n",
      "Epoch 46/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.1202e-04 - val_loss: 4.7875e-04\n",
      "Epoch 47/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.2042e-04 - val_loss: 3.9435e-04\n",
      "Epoch 48/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.1472e-04 - val_loss: 3.9992e-04\n",
      "Epoch 49/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.1696e-04 - val_loss: 3.9690e-04\n",
      "Epoch 50/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1672e-04 - val_loss: 4.0635e-04\n",
      "Epoch 51/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1065e-04 - val_loss: 4.5467e-04\n",
      "Epoch 52/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1568e-04 - val_loss: 3.9750e-04\n",
      "Epoch 53/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1600e-04 - val_loss: 3.9363e-04\n",
      "Epoch 54/90\n",
      "1000/1000 [==============================] - 29s 29ms/sample - loss: 4.0811e-04 - val_loss: 4.2322e-04\n",
      "Epoch 55/90\n",
      "1000/1000 [==============================] - 28s 28ms/sample - loss: 4.1203e-04 - val_loss: 4.2608e-04\n",
      "Epoch 56/90\n",
      " 998/1000 [============================>.] - ETA: 0s - loss: 4.1252e-04"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs')\n",
    "\n",
    "# Defining document_embedder model\n",
    "def document_embedder():\n",
    "    input_doc = keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = layers.LSTM(100)(word_embedding)\n",
    "    model = keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)), output_shape=(6, 1))(input_log_returns)\n",
    "document_embeddings = layers.TimeDistributed(document_embedder())(input_docs)\n",
    "\n",
    "ts_input = layers.Concatenate()([document_embeddings, num_features])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "print(batch_size)\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=90, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), tight_layout=True)\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.set_title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sampling a 1: 0.5\n",
      "Probability of sampling a 0: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Mapping labels to categorical labels\n",
    "def to_categorical(el):\n",
    "    if el > 0:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = 0\n",
    "    return c\n",
    "\n",
    "y_cls = np.array(list(map(to_categorical, y)))\n",
    "print('Probability of sampling a 1: {}'.format(y_cls.sum()/len(y_cls)))\n",
    "print('Probability of sampling a 0: {}'.format((len(y_cls) - y_cls.sum())/len(y_cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, 6, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 100)       2907500     docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 6, 1)         0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           time_distributed[0][0]           \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "4\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/900\n",
      "10/10 [==============================] - 9s 931ms/sample - loss: 0.7232 - binary_accuracy: 0.4000 - precision: 0.4444 - recall: 0.8000 - val_loss: 0.6295 - val_binary_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 1.0000\n",
      "Epoch 2/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.6247 - binary_accuracy: 0.8000 - precision: 0.7143 - recall: 1.0000 - val_loss: 0.5701 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 3/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.5637 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.5005 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 4/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.4850 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.4236 - val_binary_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 5/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.4067 - binary_accuracy: 0.8000 - precision: 0.7143 - recall: 1.0000 - val_loss: 0.3399 - val_binary_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 6/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.3082 - binary_accuracy: 0.9000 - precision: 0.8333 - recall: 1.0000 - val_loss: 0.1929 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 0.2051 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.1055 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0878 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0811 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0553 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0464 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0359 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 11/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0340 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0291 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 12/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0283 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0247 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 13/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0228 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0184 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 14/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.0173 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0148 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 15/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0141 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0124 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 16/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0121 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0107 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 17/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0103 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 18/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0090 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 19/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0079 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 20/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0071 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 21/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0064 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0059 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0057 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0054 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 23/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0052 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 24/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0048 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0045 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 25/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0045 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0042 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 26/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0041 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0039 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0038 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0037 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 28/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0036 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0034 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 29/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0034 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 30/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0032 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0031 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 31/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 0.0030 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 32/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0029 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0028 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 33/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0027 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0026 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 34/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0026 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0025 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 35/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0025 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0024 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 36/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0024 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0023 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 37/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0023 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0022 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 38/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0022 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0021 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 39/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0021 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0020 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 40/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0020 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 41/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0019 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 42/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0019 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0018 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 43/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0018 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 44/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0017 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 45/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0017 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 46/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0016 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 47/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0016 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 48/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0015 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 49/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0015 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 50/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0014 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 51/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 0.0014 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 52/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 53/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0013 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0013 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 54/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 55/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0012 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 56/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0012 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 57/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 58/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 59/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 0.0011 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0011 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 60/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0010 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 0.0010 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9966e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 62/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9281e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7411e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 63/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6835e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 64/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4426e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2621e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 65/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2054e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0421e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 66/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.9851e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8323e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 67/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7769e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6302e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 68/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.5853e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4349e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 69/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.3829e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2519e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 70/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.2021e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0748e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 71/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.0266e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9037e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 72/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.8589e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7370e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 73/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.6948e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5773e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 74/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.5338e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4239e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 75/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3872e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 76/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.2373e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1315e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 77/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.0947e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9945e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 78/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.9549e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8634e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 79/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.8377e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7343e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 80/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.7029e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6128e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 81/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5798e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4960e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 82/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4651e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3824e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 83/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.3501e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2733e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 84/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.2459e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1667e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 85/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1396e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0647e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 86/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 6.0375e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9670e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 87/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.9406e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8726e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 88/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.8479e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7810e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 89/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 5.7583e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6928e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 90/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.6716e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6077e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 91/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 5.5861e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5256e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 92/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.5047e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4458e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 93/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.4245e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3687e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.3498e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2936e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 95/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2740e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2215e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 96/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2052e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1507e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 97/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1344e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0827e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 98/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0650e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0174e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 99/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0007e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9531e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 100/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9365e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8908e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 101/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8760e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8296e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 102/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.8136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7709e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 103/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.7546e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7135e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 104/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.6983e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6571e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 105/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.6431e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6022e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 106/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.5876e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5489e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 107/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.5349e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4964e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 108/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 4.4840e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4452e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 109/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.4329e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 110/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.3835e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3476e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 111/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.3345e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3010e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 112/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 4.2893e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2545e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 113/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2428e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2095e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 114/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1986e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1653e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 115/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1549e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1222e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 116/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1109e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0803e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 117/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.0695e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0390e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 118/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0277e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9985e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 119/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9873e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9583e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 120/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9473e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9187e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 121/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9077e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8797e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 122/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.8700e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8413e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 123/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8306e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8043e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 124/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.7939e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7676e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 125/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.7585e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7316e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 126/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7222e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6965e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.6880e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6620e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 128/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.6530e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6286e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 129/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6206e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5956e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 130/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5868e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5634e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 131/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5547e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5317e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 132/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5233e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5003e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 133/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4918e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4695e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 134/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4613e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4392e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 135/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.4310e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4092e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 136/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 3.4010e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3798e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 137/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.3716e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3508e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 138/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 3.3438e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3220e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 139/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3148e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2940e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 140/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.2866e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2665e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 141/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2586e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2394e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 142/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2313e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2126e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 143/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2048e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1859e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 144/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1779e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1595e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 145/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1519e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1333e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 146/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1262e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1074e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 147/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1011e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0820e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 148/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0758e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0575e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 149/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0512e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0334e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 150/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0274e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0098e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 151/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.0041e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9865e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 152/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9803e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9637e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 153/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9578e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9413e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 154/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9352e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9190e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 155/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9130e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8969e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 156/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8906e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8751e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 157/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8691e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8534e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 158/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8478e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8319e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 159/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8258e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8051e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7899e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 161/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7849e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7692e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 162/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7639e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7489e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 163/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7438e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7288e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 164/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7242e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7090e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 165/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7039e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6896e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 166/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6847e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6704e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 167/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6650e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6515e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 168/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6471e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 169/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6272e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6140e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 170/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6094e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5955e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 171/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5906e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5773e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 172/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5719e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5593e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 173/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.5542e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5412e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 174/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5365e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 175/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.5189e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5055e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 176/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5009e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4881e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 177/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.4838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4710e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 178/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.4663e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4541e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 179/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.4496e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4373e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 180/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.4331e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4207e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 181/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.4161e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4044e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 182/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.3999e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3883e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 183/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.3838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3721e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 184/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.3679e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3560e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 185/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.3522e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3401e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 186/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.3369e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3244e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 187/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.3202e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.3092e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 188/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 2.3053e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2942e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 189/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.2908e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2794e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 190/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2756e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2649e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 191/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.2611e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2506e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 192/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.2468e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2363e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2330e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2221e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 194/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.2185e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2082e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 195/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.2041e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1944e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 196/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1908e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1805e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 197/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1773e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1668e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 198/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.1633e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1534e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 199/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1499e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1402e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 200/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.1366e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1271e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 201/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.1240e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1140e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 202/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.1109e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1011e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 203/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 2.0976e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0886e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 204/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.0854e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0761e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 205/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.0730e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0638e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 206/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0605e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0516e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 207/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0485e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0394e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 208/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0359e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0274e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 209/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0248e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0152e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 210/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.0121e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.0033e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 211/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.0000e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9916e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 212/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.9888e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9798e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 213/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9766e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9683e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 214/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9654e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 215/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9539e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9456e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 216/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9424e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9344e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 217/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.9316e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 218/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.9204e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9122e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 219/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.9093e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9012e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 220/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.8982e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8903e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 221/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.8876e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8794e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 222/900\n",
      "10/10 [==============================] - 0s 38ms/sample - loss: 1.8767e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8687e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 223/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.8658e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8581e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 224/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8552e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8476e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 225/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.8447e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8372e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.8341e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8268e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 227/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8236e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8165e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 228/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.8062e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 229/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.8035e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7960e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 230/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7936e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7860e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 231/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7838e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7761e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 232/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7735e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7665e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 233/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7642e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 234/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7544e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7475e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 235/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.7450e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7381e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 236/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7357e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7288e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 237/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7266e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7196e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 238/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.7170e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7106e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 239/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.7082e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7016e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 240/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6989e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6927e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 241/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.6902e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6837e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 242/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6812e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6749e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 243/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6727e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6661e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 244/900\n",
      "10/10 [==============================] - 0s 37ms/sample - loss: 1.6636e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6574e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 245/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.6550e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6488e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 246/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.6462e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6403e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 247/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.6382e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6319e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 248/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.6299e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6236e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 249/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.6215e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6156e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 250/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.6136e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.6076e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 251/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.6056e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5998e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 252/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5979e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5921e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 253/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5901e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5845e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 254/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5825e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5769e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 255/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5748e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5694e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 256/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5673e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5619e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 257/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5600e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5544e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 258/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5524e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5470e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5453e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5397e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 260/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.5379e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 261/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.5306e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5254e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 262/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5236e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5184e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 263/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.5164e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5115e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 264/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.5096e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5045e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 265/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.5027e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4977e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 266/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4958e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4909e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 267/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4891e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4841e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 268/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4823e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4774e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 269/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.4757e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4707e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 270/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4691e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4642e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 271/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4625e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4578e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 272/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4560e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4514e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 273/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4496e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4450e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 274/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.4433e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4386e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 275/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4369e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4323e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 276/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4307e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4260e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 277/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.4243e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4199e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 278/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.4183e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4137e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 279/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.4120e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4075e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 280/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.4060e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.4015e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 281/900\n",
      "10/10 [==============================] - 0s 36ms/sample - loss: 1.3999e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3955e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 282/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3939e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3896e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 283/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3881e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3837e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 284/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3821e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3779e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 285/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3763e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3721e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 286/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3706e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3663e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 287/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3648e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3605e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 288/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3590e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3549e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 289/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3533e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3493e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 290/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3477e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3437e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 291/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3423e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3381e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3367e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3325e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 293/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3311e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3271e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 294/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3256e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3216e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 295/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3202e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3162e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 296/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3149e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 297/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.3095e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3056e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 298/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.3042e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.3003e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 299/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2990e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2951e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 300/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2937e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2899e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 301/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2885e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2847e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 302/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2833e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2795e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 303/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2782e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 304/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2731e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2694e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 305/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2680e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2643e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 306/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2630e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2593e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 307/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2580e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2543e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 308/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2530e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2494e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 309/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2481e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2445e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 310/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2433e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2396e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 311/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.2383e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2347e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 312/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2334e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2299e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 313/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2286e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2251e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 314/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2239e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2204e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 315/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2191e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2156e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 316/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2144e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2109e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 317/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2097e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2062e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 318/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.2049e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.2016e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 319/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.2004e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1970e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 320/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1957e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1924e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 321/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1912e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1879e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 322/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1866e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1833e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 323/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1821e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1788e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 324/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1777e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1744e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1733e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1699e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 326/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1687e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1655e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 327/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1645e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1612e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 328/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.1600e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1569e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 329/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.1557e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1526e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 330/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1515e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1483e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 331/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1472e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1440e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 332/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1429e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1398e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 333/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1388e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1356e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 334/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1345e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1315e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 335/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1304e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1273e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 336/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1263e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1232e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 337/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1221e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1191e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 338/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.1181e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1151e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 339/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.1140e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1110e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 340/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1099e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1070e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 341/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1059e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.1030e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 342/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.1019e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0990e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 343/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0979e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0950e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 344/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0940e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0910e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 345/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0900e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0871e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 346/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0861e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0832e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 347/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0822e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0793e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 348/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0783e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0754e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 349/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0744e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0716e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 350/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0706e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0677e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 351/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0668e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0639e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 352/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0630e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0601e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 353/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0592e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0564e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 354/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0554e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0527e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 355/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 1.0517e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0490e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 356/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 1.0480e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0453e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 357/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0443e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0416e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0406e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0380e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 359/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0371e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0344e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 360/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0334e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0308e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 361/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0298e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0272e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 362/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0262e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0236e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 363/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0227e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0201e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 364/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0191e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0165e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 365/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0156e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0130e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 366/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0121e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0095e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 367/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0086e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0060e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 368/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 1.0051e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.0025e-04 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 369/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 1.0016e-04 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9907e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 370/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.9817e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9563e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 371/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9471e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.9222e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 372/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.9135e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8881e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 373/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.8795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8544e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 374/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.8455e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.8209e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 375/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.8119e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7875e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 376/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7788e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7542e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 377/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7454e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.7212e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 378/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.7121e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6883e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 379/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6804e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6554e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 380/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.6464e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.6229e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 381/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.6143e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5904e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 382/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5816e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5582e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 383/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5496e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.5260e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 384/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.5176e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 385/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4855e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4622e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 386/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.4542e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.4305e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 387/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 9.4226e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3992e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 388/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.3910e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3681e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 389/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.3603e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3372e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 390/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.3291e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.3065e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2984e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2760e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 392/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 9.2677e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2456e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 393/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.2372e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.2152e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 394/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.2073e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1848e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 395/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.1769e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1547e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 396/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.1468e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1248e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 397/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 9.1168e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0951e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 398/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 9.0870e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0654e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 399/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.0575e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0359e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 400/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 9.0278e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0064e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 401/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.9983e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9770e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 402/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.9689e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9476e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 403/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.9401e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.9184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 404/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.9108e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8895e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 405/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8816e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 406/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8533e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8321e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 407/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.8249e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8034e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 408/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7959e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7752e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 409/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.7674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7471e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 410/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.7394e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.7190e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 411/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.7117e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6910e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 412/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6835e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6633e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 413/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6561e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 414/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.6284e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.6081e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 415/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.6010e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5807e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 416/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5736e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5535e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 417/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5463e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.5264e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 418/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.5192e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4995e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 419/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4922e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4728e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 420/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 8.4655e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4461e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 421/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4390e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.4194e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 422/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.4121e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3929e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 423/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3859e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3665e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.3593e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3402e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 425/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3332e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.3140e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 426/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.3066e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2879e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 427/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.2807e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2618e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 428/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.2546e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2359e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 429/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.2293e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.2101e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 430/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 8.2032e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1846e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 431/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1778e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1591e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 432/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1521e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1337e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 433/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.1269e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.1083e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 434/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.1019e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0831e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 435/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0767e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0582e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 436/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 8.0519e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0335e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 437/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0268e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.0090e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 438/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 8.0024e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9844e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 439/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.9778e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9599e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 440/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9535e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9353e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 441/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9287e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.9110e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 442/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.9046e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8867e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 443/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.8799e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8626e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 444/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8562e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8385e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 445/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8319e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.8146e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 446/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.8083e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7907e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 447/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.7841e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 448/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.7607e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 449/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.7371e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.7199e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 450/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.7138e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6965e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 451/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.6904e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6732e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 452/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.6674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6501e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 453/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.6439e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6271e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 454/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.6209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.6043e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 455/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5981e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5816e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 456/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.5757e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5527e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5362e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 458/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5302e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.5136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 459/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.5076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4911e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 460/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.4852e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4688e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 461/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.4631e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4466e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 462/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.4408e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4245e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 463/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 7.4186e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.4025e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 464/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3966e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3806e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 465/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3746e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 466/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3528e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3370e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 467/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.3313e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3153e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 468/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.3095e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2937e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 469/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2722e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 470/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2665e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2507e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 471/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2448e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2294e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 472/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.2235e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2081e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 473/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.2024e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1868e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 474/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1811e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1657e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 475/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1601e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1447e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 476/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1391e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1239e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 477/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.1183e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.1031e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 478/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0978e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0825e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 479/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 7.0772e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0620e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 480/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0567e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0417e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 481/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 7.0364e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 482/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 7.0161e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.0012e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 483/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9958e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9811e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 484/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9758e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9610e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 485/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.9556e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9410e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 486/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.9358e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9210e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 487/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.9155e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.9011e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 488/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.8960e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8812e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 489/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.8760e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8615e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.8563e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8419e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 491/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.8369e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8223e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 492/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.8169e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.8028e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 493/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.7978e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7834e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 494/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7641e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 495/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7589e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7448e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 496/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7398e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7257e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 497/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.7205e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.7066e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 498/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.7015e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6876e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 499/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6685e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 500/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6633e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6496e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 501/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6443e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6307e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 502/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.6258e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.6118e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 503/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.6066e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5930e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 504/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.5881e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5743e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 505/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5694e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5557e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 506/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.5507e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5372e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 507/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5322e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5189e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 508/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.5140e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.5006e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 509/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4957e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4824e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 510/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4775e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4642e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 511/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4594e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4462e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 512/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.4414e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4282e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 513/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4236e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.4103e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 514/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.4055e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3925e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 515/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3748e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 516/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.3701e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3571e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 517/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3523e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3395e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 518/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 6.3348e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3219e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 519/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.3174e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3044e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 520/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2998e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2870e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 521/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2697e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 522/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.2652e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2525e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.2480e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2354e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 524/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2310e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 525/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.2139e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.2014e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 526/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.1968e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1845e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 527/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.1800e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 528/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1632e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1507e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 529/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1339e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 530/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1294e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1172e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 531/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.1126e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.1005e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 532/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.0960e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0837e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 533/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 6.0793e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 534/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0627e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0505e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 535/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0341e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 536/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 6.0298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0177e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 537/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 6.0133e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.0015e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 538/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9974e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9853e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 539/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9810e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9692e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 540/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9648e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9531e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 541/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9488e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9371e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 542/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9328e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9211e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 543/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.9170e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.9051e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 544/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.9009e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8893e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 545/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.8851e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8735e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 546/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.8692e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8577e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 547/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8534e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8420e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 548/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8379e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8263e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 549/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.8223e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 550/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.8065e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7952e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 551/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7910e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7797e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 552/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7756e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7642e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 553/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7601e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7488e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 554/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7447e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7334e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 555/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.7294e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7181e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.7140e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.7029e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 557/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6989e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6877e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 558/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6838e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6726e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 559/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6685e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6575e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 560/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6537e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6425e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 561/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.6386e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6277e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 562/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6237e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.6129e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 563/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.6089e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5982e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 564/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5944e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5834e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 565/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.5796e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5688e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 566/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5650e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5542e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 567/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5503e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5397e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 568/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5359e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 569/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.5213e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.5107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 570/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.5069e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4963e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 571/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4926e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4819e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 572/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4677e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 573/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4640e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4534e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 574/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4497e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4393e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 575/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4355e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 576/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.4214e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4112e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 577/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.4076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3971e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 578/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.3934e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3832e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 579/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 580/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3656e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3555e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 581/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.3517e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3417e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 582/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3379e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3278e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 583/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.3242e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3140e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 584/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 5.3103e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3002e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 585/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2967e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2865e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 586/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2827e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2729e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 587/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.2691e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2592e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 588/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2456e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2420e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2321e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 590/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2287e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 591/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.2151e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2054e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 592/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 5.2018e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1920e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 593/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1885e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1787e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 594/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.1750e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1655e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 595/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1620e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1522e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 596/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.1486e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1391e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 597/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1356e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1259e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 598/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1225e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1128e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 599/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.1094e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0998e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 600/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0963e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0868e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 601/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0834e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0739e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 602/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0704e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0611e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 603/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0482e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 604/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0447e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0354e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 605/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0319e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0225e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 606/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 5.0193e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.0097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 607/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 5.0064e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9970e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 608/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.9937e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9844e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 609/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9811e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9719e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 610/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9686e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9593e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 611/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9560e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9469e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 612/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.9435e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9345e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 613/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9312e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9220e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 614/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9187e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.9097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 615/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.9065e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8973e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 616/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8941e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8851e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 617/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.8818e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8728e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 618/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8695e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8607e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 619/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.8574e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8485e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 620/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8452e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8363e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 621/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.8331e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8242e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 622/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.8209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 623/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.8090e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8002e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 624/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7971e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7882e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 625/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7850e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7762e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 626/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7731e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7644e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 627/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7612e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7526e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 628/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7494e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7408e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 629/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7376e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7290e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 630/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7259e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7173e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 631/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.7143e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.7056e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 632/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.7026e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 633/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6909e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6825e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 634/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.6793e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6709e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 635/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6679e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6594e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 636/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.6564e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6478e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 637/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6449e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6363e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 638/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.6332e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6250e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 639/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6219e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 640/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.6105e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6022e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 641/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.5992e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5909e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 642/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5880e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5797e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 643/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.5768e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5685e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 644/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.5655e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5574e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 645/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5544e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5463e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 646/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5433e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5352e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 647/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5322e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5242e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 648/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5212e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5131e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 649/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.5101e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5022e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 650/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4993e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4912e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 651/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4884e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4802e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 652/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4773e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 653/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4664e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4585e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 654/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4477e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.4448e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4369e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 656/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4341e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4261e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 657/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4233e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4154e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 658/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.4125e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.4047e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 659/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.4019e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3941e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 660/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3913e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3835e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 661/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3808e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3729e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 662/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3702e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3625e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 663/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3597e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3520e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 664/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.3493e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3415e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 665/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3387e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3311e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 666/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.3283e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3208e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 667/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 4.3180e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3104e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 668/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.3077e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.3000e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 669/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2973e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2898e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 670/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2870e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2795e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 671/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2768e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2693e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 672/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2665e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2590e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 673/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2563e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2488e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 674/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.2460e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2387e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 675/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2359e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2285e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 676/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2258e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2184e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 677/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 4.2157e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.2083e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 678/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.2056e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1982e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 679/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1956e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1882e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 680/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1856e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1783e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 681/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1756e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1684e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 682/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1658e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1585e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 683/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1559e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1487e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 684/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1461e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1389e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 685/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1363e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1292e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 686/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1267e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1194e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 687/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.1168e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1097e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.1072e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1000e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 689/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0975e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0903e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 690/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.0878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0808e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 691/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0712e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 692/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0687e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0616e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 693/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0591e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0521e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 694/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0496e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0426e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 695/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0401e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0331e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 696/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0306e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0237e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 697/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0212e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0142e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 698/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 4.0118e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.0048e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 699/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 4.0023e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9955e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 700/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9931e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9862e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 701/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.9837e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9769e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 702/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9744e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 703/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9651e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9583e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 704/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.9558e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9491e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 705/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9466e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9398e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 706/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9373e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9306e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 707/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9281e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 708/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9191e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 709/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.9098e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.9031e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 710/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.9006e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8940e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 711/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8916e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8850e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 712/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8759e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 713/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8736e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8669e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 714/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8580e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 715/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8556e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8491e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 716/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8467e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8402e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 717/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8378e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8313e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 718/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8290e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8225e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 719/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.8202e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8136e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 720/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8114e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.8048e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.8025e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7961e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 722/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7939e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7873e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 723/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7850e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7787e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 724/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7764e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7700e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 725/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7677e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7614e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 726/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7592e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7528e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 727/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7505e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7442e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 728/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7419e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 729/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7334e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7271e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 730/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.7250e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 731/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7164e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7102e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 732/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.7079e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7018e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 733/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6995e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6934e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 734/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.6911e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6850e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 735/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6828e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6765e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 736/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.6743e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6681e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 737/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6659e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6598e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 738/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6515e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 739/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6493e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6432e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 740/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6410e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6349e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 741/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6327e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6267e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 742/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.6245e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6185e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 743/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.6163e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6103e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 744/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.6081e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6021e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 745/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5999e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5939e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 746/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5918e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5858e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 747/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5836e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5777e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 748/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5755e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5696e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 749/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5674e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5615e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 750/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5594e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5534e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 751/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5512e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5454e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 752/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5432e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5374e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 753/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.5353e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5294e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 754/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.5273e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5214e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 755/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5193e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5135e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 756/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.5114e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.5056e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 757/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.5035e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4977e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 758/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4956e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 759/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4878e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4821e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 760/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.4800e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4743e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 761/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4722e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4665e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 762/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.4645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4588e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 763/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4567e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4511e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 764/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.4491e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 765/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4413e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4357e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 766/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4337e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4281e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 767/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4261e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4204e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 768/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4184e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4127e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 769/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4107e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.4051e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 770/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.4031e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3975e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 771/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3955e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 772/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3880e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3824e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 773/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3804e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3749e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 774/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3728e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3674e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 775/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3654e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3599e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 776/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3579e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3524e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 777/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.3505e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3449e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 778/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.3430e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3375e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 779/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3356e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3302e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 780/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3282e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3228e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 781/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.3209e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3155e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 782/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3136e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3082e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 783/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.3063e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.3009e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 784/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2990e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2936e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 785/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2917e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2864e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 786/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2844e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2791e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 787/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2773e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2719e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 788/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.2700e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2647e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 789/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2628e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2576e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 790/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.2557e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2505e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 791/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2486e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2433e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 792/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2415e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2362e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 793/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2343e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2291e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 794/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2273e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2221e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 795/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.2202e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2150e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 796/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2132e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2080e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 797/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.2062e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.2011e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 798/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1992e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1941e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 799/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1923e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1871e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 800/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1853e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1802e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 801/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1784e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1733e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 802/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1715e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1664e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 803/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.1645e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1595e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 804/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1576e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1526e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 805/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1508e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1457e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 806/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 3.1439e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1388e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 807/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1371e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1319e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 808/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1301e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1251e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 809/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1233e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1183e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 810/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.1164e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1115e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 811/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1098e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.1047e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 812/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.1029e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0980e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 813/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0962e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0913e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 814/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0895e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0846e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 815/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0828e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0779e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 816/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0761e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0712e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 817/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0695e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0646e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 818/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0629e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0580e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 819/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0562e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0514e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0497e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0448e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 821/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 3.0432e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0382e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 822/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0365e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0317e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 823/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0300e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0252e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 824/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0234e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0187e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 825/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0170e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0122e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 826/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 3.0105e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.0057e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 827/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 3.0040e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9993e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 828/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9975e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9928e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 829/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9911e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9863e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 830/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9846e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9799e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 831/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9783e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9735e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 832/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9719e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9671e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 833/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9654e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 834/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9591e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9545e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 835/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9528e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9481e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 836/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9465e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9418e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 837/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9402e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9356e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 838/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9339e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9293e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 839/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.9277e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9231e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 840/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.9215e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9169e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 841/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.9152e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9107e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 842/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.9090e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.9045e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 843/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.9028e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8983e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 844/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8967e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8921e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 845/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8905e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8860e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 846/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8843e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8798e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 847/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8782e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8737e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 848/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8721e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8676e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 849/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8660e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8616e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 850/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8600e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8555e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 851/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.8539e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8494e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 852/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8478e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8418e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8374e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 854/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.8358e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8314e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 855/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8254e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 856/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8238e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8195e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 857/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8179e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8135e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 858/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8120e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8076e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 859/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.8060e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8017e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 860/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.8001e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7958e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 861/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7942e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7899e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 862/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.7884e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7840e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 863/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7825e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7782e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 864/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.7767e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7724e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 865/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7708e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7666e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 866/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7650e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7608e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 867/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7592e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7550e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 868/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7534e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7492e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 869/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7477e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7434e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 870/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7419e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7377e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 871/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7362e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7319e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 872/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7304e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7262e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 873/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7247e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7205e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 874/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7190e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7148e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 875/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.7133e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7091e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 876/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7076e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.7034e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 877/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.7020e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6978e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 878/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6963e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6922e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 879/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6907e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6866e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 880/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6851e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6810e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 881/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6795e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6754e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 882/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6739e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6698e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 883/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6683e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6643e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 884/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6628e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6587e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 885/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6573e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6532e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6517e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6477e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 887/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6462e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6422e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 888/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6408e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6367e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 889/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6353e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6313e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 890/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.6298e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6258e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 891/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6244e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6204e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 892/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6190e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6150e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 893/900\n",
      "10/10 [==============================] - 0s 33ms/sample - loss: 2.6136e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6096e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 894/900\n",
      "10/10 [==============================] - 0s 32ms/sample - loss: 2.6082e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.6042e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 895/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.6028e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5988e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 896/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5974e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5935e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 897/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5921e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5881e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 898/900\n",
      "10/10 [==============================] - 0s 34ms/sample - loss: 2.5867e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5827e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 899/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5813e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5774e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 900/900\n",
      "10/10 [==============================] - 0s 35ms/sample - loss: 2.5760e-05 - binary_accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.5721e-05 - val_binary_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_docs = keras.Input(shape=(6, None), name='docs')\n",
    "\n",
    "# Defining document_embedder model\n",
    "def document_embedder():\n",
    "    input_doc = keras.Input(shape=(None,), name='doc')\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)(input_doc)\n",
    "    document_embedding = layers.LSTM(100)(word_embedding)\n",
    "    model = keras.Model(input_doc, document_embedding, name='document_embedder')\n",
    "    return model\n",
    "\n",
    "# Creating input to time series layer\n",
    "num_features = layers.Lambda((lambda x: keras.backend.expand_dims(x, axis=-1)), output_shape=(6, 1))(input_log_returns)\n",
    "document_embeddings = layers.TimeDistributed(document_embedder())(input_docs)\n",
    "\n",
    "ts_input = layers.Concatenate()([document_embeddings, num_features])\n",
    "\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1, activation='sigmoid')(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_docs], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "print(model.summary())\n",
    "print(batch_size)\n",
    "#keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "\n",
    "\n",
    "history_cls = model.fit(x=X, y=y_cls, batch_size=batch_size, epochs=900, validation_data =(X, y_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(10, 10), tight_layout=True)\n",
    "ax[0].plot(history_cls.history['val_loss'])\n",
    "ax[0].plot(history_cls.history['loss'])\n",
    "ax[0].set_title('loss: Binary Cross Entropy')\n",
    "ax[1].plot(history_cls.history['binary_accuracy'])\n",
    "ax[1].plot(history_cls.history['val_binary_accuracy'])\n",
    "ax[1].set_title('Binary Accuracy')\n",
    "ax[2].plot(history_cls.history['precision'])\n",
    "ax[2].plot(history_cls.history['val_precision'])\n",
    "ax[2].set_title('Precision')\n",
    "ax[3].plot(history_cls.history['recall'])\n",
    "ax[3].plot(history_cls.history['val_recall'])\n",
    "ax[3].set_title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5024\n",
      "1000\n",
      "(1000, 2879)\n"
     ]
    }
   ],
   "source": [
    "def decode_docs_feature_2(docs_feature, seed):\n",
    "    np.random.seed(seed)\n",
    "    docs_names = flatten_docs_feature(docs_feature)\n",
    "    if len(docs_names) != 0:\n",
    "        windows_doc_name = np.random.choice(docs_names, size=1)[0]\n",
    "        with open(windows_doc_name, 'rb') as f:\n",
    "            windows_doc = pickle.load(f)\n",
    "        window = windows_doc\n",
    "    else:\n",
    "        window = []\n",
    "    return np.asarray(window)\n",
    "\n",
    "features, labels = extract_labels(dataset, ['log_adj_daily_returns'])\n",
    "features_decoded = {key: (value if key != 'docs' \n",
    "                          else list(map(lambda docf: decode_docs_feature_2(docf, seed), value))) \n",
    "                    for key, value in features.items()}\n",
    "# Checking the above steps\n",
    "print(len(features_decoded['docs']))\n",
    "\n",
    "mask = [(sample.shape[0] != 0) for sample in features_decoded['docs']]\n",
    "\n",
    "features_filtered = {key: (value[mask, :] if key != 'docs'\n",
    "                           else [value[i] for i in range(len(mask)) if mask[i]])\n",
    "                     for key, value in features_decoded.items()}\n",
    "\n",
    "labels_filtered = {key: value[mask] for key, value in labels.items()}\n",
    "# Checking the above steps\n",
    "assert all(sample.shape[0] != 0 for sample in features_filtered['docs'])\n",
    "\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.choice(len(features_filtered['docs']), size=dataset_size, replace=False)\n",
    "\n",
    "features_shuffled = {key: (value[shuffled_indices] if key != 'docs'\n",
    "                           else [value[i] for i in shuffled_indices])\n",
    "                     for key, value in features_filtered.items()}\n",
    "\n",
    "labels_shuffled = {key: value[shuffled_indices] for key, value in labels_filtered.items()}\n",
    "\n",
    "assert (features_shuffled['log_adj_daily_returns'].shape[0] == len(features_shuffled['docs']) == labels_shuffled['log_adj_daily_returns'].shape[0])\n",
    "print(features_shuffled['log_adj_daily_returns'].shape[0])\n",
    "\n",
    "def pad_documents_2(docs_feature):\n",
    "    shapes = map(lambda arr: arr.shape, docs_feature)\n",
    "    longest_doc_len = max(map(lambda shape: shape[-1], shapes))\n",
    "    pad_doc = lambda arr:  np.pad(arr, ((0, longest_doc_len-arr.shape[-1])), constant_values=0)\n",
    "    return np.stack(list(map(pad_doc, docs_feature)), axis=0)\n",
    "\n",
    "X = {key: (pad_documents_2(value) if key == 'docs' else value) for key, value in features_shuffled.items()}\n",
    "y = labels_shuffled['log_adj_daily_returns']\n",
    "print(X['docs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "docs (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    2747100     docs[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 100)          160400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_adj_daily_returns (InputLay [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_stack (TensorFlowOp [(None, 6, 100)]     0           lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 6, 1)]       0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 101)       0           tf_op_layer_stack[0][0]          \n",
      "                                                                 tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           17152       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            33          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,924,685\n",
      "Trainable params: 177,585\n",
      "Non-trainable params: 2,747,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "256\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 37s 37ms/sample - loss: 0.0092 - val_loss: 0.0073\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 32s 32ms/sample - loss: 0.0040 - val_loss: 0.0055\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 32s 32ms/sample - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 33s 33ms/sample - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 32s 32ms/sample - loss: 0.0010 - val_loss: 0.0011\n"
     ]
    }
   ],
   "source": [
    "# Creating a Model and attempting to overfit it\n",
    "## Defining Model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Input Layers\n",
    "input_log_returns = keras.Input(shape=(6,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "input_doc = keras.Input(shape=(None,), name='docs', dtype=tf.int64)\n",
    "# Building Word Embedding Layer\n",
    "word_embedding_layer = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False, input_length=1466)(input_doc)\n",
    "# Building Document Embedding Layer\n",
    "document_embedding_layer = layers.LSTM(100)(word_embedding_layer)\n",
    "# Creating input to time series layer\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "doc_features = tf.stack([document_embedding_layer for _ in range(6)], axis=1)\n",
    "ts_input = layers.Concatenate()([doc_features, num_features])\n",
    "# Time series component\n",
    "ts_layer_1 = layers.LSTM(32, return_sequences=False)(ts_input)\n",
    "#ts_layer_2 = layers.LSTM(500, return_sequences=True)(ts_layer_1)\n",
    "#ts_layer_3 = layers.LSTM(300, return_sequences=True)(ts_layer_2)\n",
    "#ts_layer_4 = layers.LSTM(160, return_sequences=True)(ts_layer_3)\n",
    "#ts_layer_5 = layers.LSTM(50, return_sequences=False)(ts_layer_4)\n",
    "output = layers.Dense(1)(ts_layer_1)\n",
    "\n",
    "model = keras.Model([input_log_returns, input_doc], output, name='test_model')\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss='mse', metrics=None)\n",
    "print(model.summary())\n",
    "keras.utils.plot_model(model, 'test.png', show_shapes=True)\n",
    "print(batch_size)\n",
    "history = model.fit(x=X, y=y, batch_size=batch_size, epochs=5, validation_data =(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), tight_layout=True)\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.plot(history.history['loss'])\n",
    "ax.set_title('Loss over epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the tf dataset section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to load the dataset from its TFRecord file\n",
    "\n",
    "def parse_example(example_proto, feature_description):\n",
    "    '''\n",
    "    Parses example proto from\n",
    "    \n",
    "    :param example_proto: \n",
    "    :param feature_description: \n",
    "    '''\n",
    "    \n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    # Reconstructing Ragged Tensors from Example\n",
    "    for t in tickers:\n",
    "        example['_'.join(['docs', t])] = tf.RaggedTensor.from_row_lengths(example['docs_{}/vals'.format(t)].values,\n",
    "                                                           row_lengths=example['docs_{}/lens'.format(t)].values)\n",
    "\n",
    "    # Deleting Redundant Keys\n",
    "    for t in tickers:\n",
    "        del example['docs_{}/vals'.format(t)]\n",
    "        del example['docs_{}/lens'.format(t)]\n",
    "        \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataset\n",
    "\n",
    "# Loading the raw dataset from the TFRecord file\n",
    "dataset = tf.data.TFRecordDataset(os.path.join(path_to_data, 'dataset.tfrecord'))\n",
    "# Loading the dataset's feature_description\n",
    "with open(os.path.join(path_to_data, 'dataset_feature_description.pickle'), 'rb') as f:\n",
    "    feature_description = pickle.load(f)\n",
    "# Decoding the raw dataset using the dataset's feature_description\n",
    "dataset = dataset.map(lambda example_proto: parse_example(example_proto, feature_description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Spliting the dataset by stock ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(example, features, ticker):\n",
    "    return {feature_name: example['_'.join([feature_name, ticker])] for feature_name in features}\n",
    "\n",
    "datasets = [dataset.map(lambda ex: split(ex, ['log_adj_daily_returns', 'docs'], t)) for t in tickers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Reshaping datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to reshape datasets\n",
    "\n",
    "def make_window_dataset(ds, window_size, shift=1, stride=1):\n",
    "    \n",
    "    windows = ds.window(window_size, shift=shift, stride=stride)\n",
    "    \n",
    "    feature_datasets = {key: windows.flat_map(lambda x: x[key].batch(window_size, drop_remainder=True))\n",
    "                        for key in windows.element_spec.keys()}\n",
    "    \n",
    "    return tf.data.Dataset.zip(feature_datasets)\n",
    "\n",
    "def extract_labels(timeslice, label_features):\n",
    "    labels = {}\n",
    "    \n",
    "    for feature_key in timeslice.keys():\n",
    "        feature_timeslice = timeslice[feature_key]\n",
    "        if feature_key in label_features:\n",
    "            labels[feature_key] = feature_timeslice[-1]\n",
    "        timeslice[feature_key] = feature_timeslice[:-1]\n",
    "        \n",
    "    return (timeslice, labels)\n",
    "\n",
    "\n",
    "def to_time_series(ds, label_features, window_size, steps_to_pred=1, num_of_preds=1):\n",
    "    \n",
    "    # making full time series Dataset object (features + labels)\n",
    "    full_ts_ds = make_window_dataset(ds, window_size=window_size+1)\n",
    "    \n",
    "    # mapping dataset to Dataset where each el is: (features: dict, labels)\n",
    "    ts_ds = full_ts_ds.map(lambda s: extract_labels(s, label_features))\n",
    "    \n",
    "    return ts_ds\n",
    "\n",
    "def sample_documents(sample):\n",
    "    # Extracting all documents in the sample\n",
    "    docs_in_sample = sample.values\n",
    "    # Sampling a random document from all the documents in the sample\n",
    "    if docs_in_sample.nrows() != 0:\n",
    "        i = tf.random.uniform([1], maxval=docs_in_sample.nrows(), dtype=tf.int64)[0]\n",
    "        sample_doc = docs_in_sample[i]\n",
    "    else:\n",
    "        sample_doc = tf.constant([], dtype=tf.int64)\n",
    "        \n",
    "    return sample_doc\n",
    "\n",
    "def select_doc(features, labels):\n",
    "    \n",
    "    for fname in features.keys():\n",
    "        feature = features[fname]\n",
    "        timesteps = feature.shape[0]\n",
    "        # Feature is a doc feature\n",
    "        if isinstance(feature, tf.RaggedTensor):\n",
    "            doc = sample_documents(feature)\n",
    "            feature = tf.stack([doc for day in range(timesteps)])\n",
    "            features[fname] = feature\n",
    "        \n",
    "    return (features, *list(labels.values()))\n",
    "\n",
    "def filter_fn(f, l):\n",
    "    shape = tf.shape(f['docs'])[1]\n",
    "    return tf.math.not_equal(shape, 0)\n",
    "\n",
    "def reshape(dataset, window_size, label_name):\n",
    "    # Converting to time series\n",
    "    ds = to_time_series(dataset, label_name, window_size=window_size)\n",
    "    # Selecting document features\n",
    "    ds = ds.map(select_doc)\n",
    "    # Filtering out elements without a document feature\n",
    "    ds = ds.filter(filter_fn)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Datasets\n",
    "reshaped_datasets = list(map(lambda d: reshape(d, TIMESTEPS, 'log_adj_daily_returns'), datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "4. Concatenating datasets, and shuffling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = reduce(lambda a, b: a.concatenate(b), reshaped_datasets).shuffle(1000, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Splitting dataset into train, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions and Classes for splitting datasets into train, validation, and test datasets\n",
    "\n",
    "def k_folds(dataset, k):\n",
    "    '''\n",
    "    Splits :param dataset: into :param k: number of equally sized (or close to equally sized) components.\n",
    "    \n",
    "    :param dataset: tf.data.Dataset, dataset to split into k folds\n",
    "    :param k: int, number of folds to split :param dataset: into\n",
    "    \n",
    "    ---> list, of tf.data.Dataset objets\n",
    "    '''\n",
    "    return [dataset.shard(k, i) for i in range(k)]\n",
    "\n",
    "def train_test_split(dataset, train_size):\n",
    "    '''\n",
    "    Splits :param dataset: into\n",
    "    \n",
    "    :param dataset: tf.data.Dataset, to split into train and test datasets\n",
    "    :param train_size: float between 0 and 1, proportion of :param dataset: to put into train dataset\n",
    "    \n",
    "    ---> (tf.data.Dataset, tf.data.Dataset), representing train, test datasets\n",
    "    '''\n",
    "    train_size = Fraction(train_size).limit_denominator()\n",
    "    x, k = train_size.numerator, train_size.denominator\n",
    "    folds = k_folds(dataset, k)\n",
    "    train = reduce(lambda a, b: a.concatenate(b), folds[:x])\n",
    "    test = reduce(lambda a, b: a.concatenate(b), folds[x:])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our models we will reserve 60% of the dataset for training, 20% for validation, and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our dataset into train, validation, test datasets\n",
    "\n",
    "# Creating datasets\n",
    "train_dataset, test_val_dataset = train_test_split(dataset, train_size=0.6)\n",
    "val_dataset, test_dataset = train_test_split(test_val_dataset, train_size=0.5)\n",
    "\n",
    "# Prepping datasets for modeling\n",
    "train_dataset = (train_dataset.shuffle(10)\n",
    "                 .padded_batch(BATCH_SIZE, \n",
    "                               padded_shapes=({'log_adj_daily_returns': [TIMESTEPS,], \n",
    "                                               'docs': [TIMESTEPS, None]}, [])))\n",
    "val_dataset = (val_dataset.shuffle(10)\n",
    "               .padded_batch(BATCH_SIZE,\n",
    "                             padded_shapes=({'log_adj_daily_returns': [TIMESTEPS,], \n",
    "                                             'docs': [TIMESTEPS, None]}, [])))\n",
    "test_dataset = (test_dataset.shuffle(10)\n",
    "                .padded_batch(BATCH_SIZE, \n",
    "                              padded_shapes=({'log_adj_daily_returns': [TIMESTEPS,], \n",
    "                                              'docs': [TIMESTEPS, None]}, [])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to construct model layers\n",
    "\n",
    "def embedding_matrix(vocab, init):\n",
    "    '''\n",
    "    Constructs the embedding matrix for specific init type for a pre initialized word embedding layer.\n",
    "    \n",
    "    :param vocab: dict, a mapping between keys of words, and values of unique integer identifiers for each word\n",
    "    :param init: string, initialization type currently we only support glove initialization\n",
    "    \n",
    "    ---> numpy array of size (vocab length, embedding dimension) mapping each word encoding to a vector\n",
    "    '''\n",
    "    \n",
    "    if init == 'glove':\n",
    "        glove_dir = 'glove'\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'rb') as f:\n",
    "                embedding_m = pickle.load(f)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            # Building word to vector map\n",
    "            word_embeddings = {}\n",
    "            with open(os.path.join(glove_dir, 'glove.840B.300d.txt')) as f:\n",
    "                for line in f:\n",
    "                    tokens = line.split(' ')\n",
    "                    word = tokens[0]\n",
    "                    embedding = np.asarray(tokens[1:], dtype='float32')\n",
    "                    # Needs to check if dim is changing\n",
    "                    assert len(embedding) == 300\n",
    "                    word_embeddings[word] = embedding\n",
    "            # Building embedding matrix\n",
    "            EMBEDDING_DIM = len(next(iter(word_embeddings.values())))\n",
    "            embedding_m = np.zeros((len(vocab) + 1, EMBEDDING_DIM))\n",
    "            for word, i in vocab.items():\n",
    "                embedding_vector = word_embeddings.get(word)\n",
    "                if embedding_vector is not None:\n",
    "                    embedding_m[i] = embedding_vector\n",
    "            # Saving embedding matrix\n",
    "            with open(os.path.join(glove_dir, 'current_embedding.pickle'), 'wb') as f:\n",
    "                pickle.dump(embedding_m, f)\n",
    "                \n",
    "    else:\n",
    "        raise ValueError('init type not supported, init must be equal to \"glove\"')\n",
    "\n",
    "    return embedding_m\n",
    "\n",
    "def Word_Embedding(vocab, init, \n",
    "                   embeddings_initializer='uniform', embeddings_regularizer=None, \n",
    "                   activity_regularizer=None, embeddings_constraint=None, \n",
    "                   mask_zero=False, input_length=None, **kwargs):\n",
    "    \n",
    "    '''\n",
    "    Creates a keras embedding layer specifically designed to embed the words specified in :param vocab:\n",
    "    \n",
    "    :param vocab: dict, representing the mapping between the words in corpus (keys) and their unique integer\n",
    "                  encodings\n",
    "    :param init: string or int, tells the layer how to initialize its embeddings. If of type int, then\n",
    "                 it tells the layer to initialize its word embeddings with an embedding dimension of :param init:.\n",
    "                 If of type string, then :param init: specifies the type of pretrained word embeddings we will be \n",
    "                 initializing the embedding layer with\n",
    "    \n",
    "    ---> tf.keras.layers.Embedding\n",
    "    '''\n",
    "    \n",
    "    if isinstance(init, str):\n",
    "        current_embedding_matrix = embedding_matrix(vocab, init)\n",
    "        emb_layer = layers.Embedding(current_embedding_matrix.shape[0], current_embedding_matrix.shape[1],\n",
    "                                     weights=[current_embedding_matrix], mask_zero=mask_zero,\n",
    "                                     input_length=None, **kwargs)\n",
    "        \n",
    "    elif isinstance(init, int):\n",
    "        emb_layer = layers.Embedding(len(vocab) + 1, output_dim=init, \n",
    "                                     embeddings_initializer=embeddings_initializer, embeddings_regularizer=embeddings_regularizer, \n",
    "                                     activity_regularizer=activity_regularizer, embeddings_constraint=embeddings_constraint, \n",
    "                                     mask_zero=mask_zero, input_length=input_length, **kwargs)\n",
    "    else:\n",
    "        raise ValueError('init type not supported')\n",
    "        \n",
    "    return emb_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions and classes used to construct models\n",
    "\n",
    "def model_1(timesteps, vocab, doc_embedding_size, ts_layer_1_size, ts_layer_2_size, ts_layer_3_size,\n",
    "            optimizer, learning_rate, loss, metrics):\n",
    "    '''\n",
    "    Constructs a model with the architecture of \n",
    "    '''\n",
    "    \n",
    "    # Building Input Layers\n",
    "    input_docs = keras.Input(shape=(timesteps, None), name='docs', dtype=tf.int64)\n",
    "    input_log_returns = keras.Input(shape=(timesteps,), name='log_adj_daily_returns', dtype=tf.float32)\n",
    "    # Slicing Document Input Layer along time axis\n",
    "    timeslice_layer = [input_docs[:, timestep, :] for timestep in range(timesteps)]\n",
    "    # Building Word Embedding Layer\n",
    "    word_embedding = Word_Embedding(vocab, init='glove', mask_zero=True, trainable=False)\n",
    "    word_embedding_layer = [word_embedding(timeslice) for timeslice in timeslice_layer]\n",
    "    # Building Document Embedding Layer\n",
    "    document_embedding = layers.LSTM(doc_embedding_size)\n",
    "    document_embedding_layer = [document_embedding(timeslice) for timeslice in word_embedding_layer]\n",
    "    # Preparing Features for Time Series Analysis\n",
    "    num_features = tf.expand_dims(input_log_returns, -1)\n",
    "    doc_features = tf.stack(document_embedding_layer, axis=1)\n",
    "    ts_input = num_features #layers.Concatenate()([doc_features, num_features])\n",
    "    # Building Time Series Layer\n",
    "    #ts_layer_1 = layers.LSTM(ts_layer_1_size, return_sequences=True)(ts_input)\n",
    "    ts_layer_2 = layers.LSTM(ts_layer_2_size, return_sequences=True)(ts_input)\n",
    "    ts_layer_3 = layers.LSTM(ts_layer_3_size)(ts_layer_2)\n",
    "    # Building Output Layer\n",
    "    output = layers.Dense(1, activation='sigmoid')(ts_layer_3)\n",
    "    # Building Model\n",
    "    model = keras.Model([input_docs, input_log_returns], output, name='model_1')\n",
    "    # Compiling Model\n",
    "    if learning_rate == None:\n",
    "        opt = optimizer()\n",
    "    else:\n",
    "        opt = optimizer(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "log_adj_daily_returns (InputLay [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims (TensorF [(None, 8, 1)]       0           log_adj_daily_returns[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 8, 1000)      4008000     tf_op_layer_ExpandDims[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 1000)         8004000     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "docs (InputLayer)               [(None, 8, None)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1001        lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 12,013,001\n",
      "Trainable params: 12,013,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/900\n",
      "30/30 [==============================] - 81s 3s/step - loss: 0.6933 - accuracy: 0.5046 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/900\n",
      "30/30 [==============================] - 77s 3s/step - loss: 0.6933 - accuracy: 0.4983 - val_loss: 0.6933 - val_accuracy: 0.4995\n",
      "Epoch 3/900\n",
      "30/30 [==============================] - 76s 3s/step - loss: 0.6933 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.4995\n",
      "Epoch 4/900\n",
      "30/30 [==============================] - 78s 3s/step - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6932 - val_accuracy: 0.4995\n",
      "Epoch 5/900\n",
      " 1/30 [>.............................] - ETA: 1:00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-a8115fd1a423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#print(next(iter(train_dataset.unbatch().map(to_categorical).batch(BATCH_SIZE))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mt_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mhis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Model 1 with the current hyperparameters\n",
    "tf.keras.backend.clear_session()\n",
    "model = model_1(timesteps=TIMESTEPS, vocab=vocab, doc_embedding_size=DOC_EMBEDDING_UNITS,\n",
    "                ts_layer_1_size=TS_LAYER_1_UNITS, ts_layer_2_size=TS_LAYER_2_UNITS, ts_layer_3_size=TS_LAYER_3_UNITS,\n",
    "                optimizer=OPTIMIZER, learning_rate=LEARNING_RATE, loss=LOSS, metrics=METRICS)\n",
    "\n",
    "print(model.summary())\n",
    "# Converting data to catagorical data\n",
    "def to_categorical(f, l):\n",
    "    if l > 0:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = 0\n",
    "    return (f, c)\n",
    "#print(next(iter(train_dataset.unbatch().map(to_categorical).batch(BATCH_SIZE))))\n",
    "t_dataset = train_dataset.unbatch().map(to_categorical).batch(BATCH_SIZE)\n",
    "his = model.fit(t_dataset, epochs=900, validation_data=t_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "loss = keras.losses.MeanSquaredError()\n",
    "metrics = [keras.metrics.Accuracy()]\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "hparams = {'timesteps': window_size, 'vocab': vocab, 'doc_embedding_size': 500, 'ts_layer_1_size': 32,\n",
    "           'ts_layer_2_size': 10, 'ts_layer_3_size': 5}\n",
    "\n",
    "model = get_compiled_model(optimizer=optimizer, loss=loss, metrics=metrics, model=model_1, **hparams)\n",
    "keras.utils.plot_model(model, 'test.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-aab66ff54649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Preparing Inputs for Time Series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_log_returns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mdoc_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_embedding_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;31m#ts_input = layers.Concatenate()([doc_features, num_features])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2139\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2140\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2141\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2142\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2143\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mshape_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_inputs_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mreduced_inputs_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m       \u001b[0mshape_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_inputs_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_set\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "feature_names = ['log_adj_daily_returns', 'docs_WFC', 'docs_JPM', 'docs_C', 'docs_BAC']\n",
    "\n",
    "# destroying already made graph nodes in the tensorflow backend\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "timesteps = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# document embedding Model\n",
    "\n",
    "    \n",
    "with open(os.path.join(path_to_data, 'vocab.json')) as f:\n",
    "    vocab = json.load(f)\n",
    "        \n",
    "#document = keras.Input(shape=(None,), name='document')\n",
    "#word_embedding = Word_Embedding(vocab, trainable=False)(document)\n",
    "#document_embedding = layers.LSTM(400)(word_embedding)\n",
    "#document_embedder = keras.Model(document, document_embedding, name='document_embedder')\n",
    "#print(document_embedder.summary())\n",
    "\n",
    "#keras.utils.plot_model(document_embedder, 'document_embedder.png', show_shapes=True)\n",
    "\n",
    "\n",
    "\n",
    "# Inputs\n",
    "input_docs_WFC = keras.Input(shape=(timesteps, None), name='docs_WFC')\n",
    "#input_docs_JPM = keras.Input(shape=(timesteps, None), name='docs_JPM')\n",
    "#input_docs_BAC = keras.Input(shape=(timesteps, None), name='docs_BAC')\n",
    "#input_docs_C = keras.Input(shape=(timesteps, None), name='docs_C')\n",
    "input_log_returns = keras.Input(shape=(timesteps,), name='log_adj_daily_returns')\n",
    "\n",
    "# Splitting docs_WFC input into its individual timesteps\n",
    "timesteps_layer = [input_docs_WFC[:, t] for t in range(timesteps)]\n",
    "\n",
    "# Flattening Documents Dimension for each timestep (cause I don't know how to deal with the extra dimension for the LSTM)\n",
    "#flattened_timesteps_layer = [tf.reshape(timestep, [-1, tf.reduce_prod(tf.shape(timestep)[1:])]) for timestep in timesteps_layer]\n",
    "\n",
    "# Word Embedding Layer\n",
    "word_embedding = Word_Embedding(vocab, init='glove', trainable=True, mask_zero=True)\n",
    "word_embedding_layer = [word_embedding(timestep) for timestep in timesteps_layer]\n",
    "\n",
    "\n",
    "# Document Embedding Layer\n",
    "document_embedding = layers.LSTM(100)\n",
    "doc_embedding_layer = [document_embedding(timestep) for timestep in word_embedding_layer]\n",
    "\n",
    "# Preparing Inputs for Time Series\n",
    "num_features = tf.expand_dims(input_log_returns, -1)\n",
    "doc_features = tf.stack(doc_embedding_layer, axis=1)\n",
    "ts_input = layers.Concatenate()([doc_features, num_features])\n",
    "\n",
    "\n",
    "\n",
    "# Time Series Component\n",
    "time_series = layers.LSTM(100)(ts_input)\n",
    "\n",
    "# Output\n",
    "output = layers.Dense(1)(time_series)\n",
    "\n",
    "# Creating Model\n",
    "test_model = keras.Model({'docs_WFC': input_docs_WFC, 'log_adj_daily_returns': input_log_returns}, output, name='test_model')\n",
    "\n",
    "# Compiling Model\n",
    "test_model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training Model\n",
    "#test_ds = tsds.batch(1).repeat()\n",
    "\n",
    "\n",
    "#test_model.fit_generator(test_ds, epochs=3, steps_per_epoch=100)\n",
    "keras.utils.plot_model(test_model, 'test.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = tf.data.Dataset.range(10)\n",
    "d.element_spec.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_pm(raw_df):\n",
    "    '''\n",
    "    Preprocessing raw_df into the shape raw_df should have been after coming out of the fetch process, as well as \n",
    "    normalizing the documents.\n",
    "    '''\n",
    "    \n",
    "    # Reshaping DataFrame\n",
    "    reshaped_df = reshape(raw_df)\n",
    "    \n",
    "    # Normalizing and updating documents    \n",
    "    def update_doclist(s):\n",
    "        doclist = json.loads(s)\n",
    "        updated_doclist = []\n",
    "        for docpath in doclist:\n",
    "            save_point = os.path.join(os.path.split(docpath)[0], 'normalized')\n",
    "            norm_docpath = normalize_save_document(docpath, save_point)\n",
    "            updated_doclist.append(norm_docpath)\n",
    "            \n",
    "        return json.dumps(updated_doclist)\n",
    "    \n",
    "    for t in tickers:\n",
    "        reshaped_df['_'.join(['docs', t])] = reshaped_df['_'.join(['docs', t])].map(update_doclist)\n",
    "        \n",
    "    # Preprocessing numerical data\n",
    "    reshaped_df['log_adj_close'] = np.log(reshaped_df['adjusted_close'])\n",
    "    reshaped_df['log_adj_daily_returns'] = reshaped_df['log_adj_close'] - reshaped_df['log_adj_close'].shift(-1)\n",
    "    reshaped_df.dropna(subset=['log_adj_daily_returns'], inplace=True)\n",
    "    \n",
    "    # Building vocabulary json file\n",
    "    path_to_vocab = os.path.join(path_to_data, 'vocab.json')\n",
    "    \n",
    "    def vocab_from_doclist(s):\n",
    "        \n",
    "        doclist = json.loads(s)\n",
    "        \n",
    "        for docpath in doclist:\n",
    "            with open(docpath, 'r') as f:\n",
    "                doc = f.read()\n",
    "            \n",
    "            build_vocab(doc)\n",
    "        \n",
    "        return json.dumps(doclist)\n",
    "    \n",
    "    for t in tickers:\n",
    "        reshaped_df['_'.join(['docs', t])].map(vocab_from_doclist)\n",
    "        \n",
    "    # Encoding documents based off of vocabulary json file\n",
    "    \n",
    "    \n",
    "    return reshaped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing tfrecords\n",
    "\n",
    "feature_names = ['log_adj_daily_returns', 'docs_WFC', 'docs_JPM', 'docs_C', 'docs_BAC']\n",
    "with open(os.path.join(path_to_data, 'vocab.json'), 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "\n",
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    '''Returns a bytes_list from a string / byte.'''\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    '''Returns a float_list from a float / double.'''\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    '''Returns an int64_list from a bool / enum / int / uint.'''\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_example(sample, feature_names):\n",
    "    \n",
    "    feature = {}\n",
    "    \n",
    "    for feature_name in feature_names:\n",
    "        # if feature is a number \n",
    "        if isinstance(sample[feature_name], float):\n",
    "            feature[feature_name] = tf.train.Feature(float_list=tf.train.FloatList(value=[sample[feature_name]]))\n",
    "        \n",
    "        # if feature is a doclist\n",
    "        elif isinstance(sample[feature_name], list):\n",
    "            lens = list(map(len, sample[feature_name]))\n",
    "            values = [word for doc in sample[feature_name] for word in doc]\n",
    "            feature[feature_name + '/vals'] = tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "            feature[feature_name + '/lens'] = tf.train.Feature(int64_list=tf.train.Int64List(value=lens))\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "\n",
    "\n",
    "def unpack_doclist(doclist_string):        \n",
    "    def load_encode_file(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            text = f.read()\n",
    "        return [vocab[word] for word in text.split()]\n",
    "    return list(map(load_encode_file, json.loads(doclist_string)))\n",
    "\n",
    "\n",
    "record_file = 'test.tfrecords'\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for i in range(300, -1, -1):\n",
    "        row = raw_df_fixed.iloc[i].copy(deep=True)\n",
    "        # Unpacking Text Features\n",
    "        row[['_'.join(['docs', t]) for t in tickers]] = row[['_'.join(['docs', t]) for t in tickers]].map(unpack_doclist)\n",
    "        # Serializing Example to disk\n",
    "        example = serialize_example(row, feature_names)\n",
    "        writer.write(example.SerializeToString())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing our data involves:\n",
    "1. Loading the dataset from the TFRecord file\n",
    "2. Splitting the dataset by stock ticker\n",
    "3. Reshaping each dataset to prepare it for training:\n",
    "    1. Windowing the dataset so each element produces a time series of features along with there corresponding label\n",
    "    2. Sampling the document feature for the document that will represent the specific window's document and cloning that document for each timestep in our defined window size\n",
    "    3. Filtering our dataset to include only elements with a document feature\n",
    "4. Concatenating the reshaped datasets together, and shuffling the dataset\n",
    "5. Splitting the dataset into train, validation, and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading the dataset from TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Dataset to TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sucessfully preprocessing our dataset we next write our dataset to a TFRecords file (https://www.tensorflow.org/tutorials/load_data/tfrecord) a binary file format that is read efficiently by the TensorFlow framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions and Classes used to write TFRecord files\n",
    "\n",
    "def serialize_example(sample, feature_names):\n",
    "    '''\n",
    "    Maps dictionary :param sample: to a tf.train.Example object where the list feature_names determines which \n",
    "    subset of :param sample:'s keys are to be used. \n",
    "    \n",
    "    :param sample: dict, where the keys are the names of the features of the specific data sample, and the values \n",
    "                   are the values each feature takes on for the specific data sample\n",
    "    :param feature_names: list, of strings, a subset of sample.keys(), these are the features we will\n",
    "                          be considering for analysis\n",
    "    \n",
    "    ---> tf.train.Example, object representing the data sample\n",
    "    '''\n",
    "    \n",
    "    feature = {}\n",
    "    feature_description = {}\n",
    "    \n",
    "    for feature_name in feature_names:\n",
    "        # if feature is a float number \n",
    "        if isinstance(sample[feature_name], float):\n",
    "            feature[feature_name] = tf.train.Feature(float_list=tf.train.FloatList(value=[sample[feature_name]]))\n",
    "            feature_description[feature_name] = tf.io.FixedLenFeature([], tf.float32)\n",
    "        \n",
    "        # if feature is a list of documents\n",
    "        elif isinstance(sample[feature_name], list) and all(isinstance(word, int) for doc in sample[feature_name] for word in doc):\n",
    "            lens = list(map(len, sample[feature_name]))\n",
    "            values = [word for doc in sample[feature_name] for word in doc]\n",
    "            feature[feature_name + '/vals'] = tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "            feature[feature_name + '/lens'] = tf.train.Feature(int64_list=tf.train.Int64List(value=lens))\n",
    "            feature_description[feature_name + '/vals'] = tf.io.VarLenFeature(dtype=tf.int64)\n",
    "            feature_description[feature_name + '/lens'] = tf.io.VarLenFeature(dtype=tf.int64)\n",
    "        \n",
    "        # if feature is an integer number\n",
    "        elif isinstance(sample[feature_name], int):\n",
    "            feature[feature_name] = tf.train.Feature(int64_list=tf.train.Int64List(value=[sample[feature_name]]))\n",
    "            feature_description[feature_name] = tf.io.FixedLenFeature([], tf.int64)\n",
    "        \n",
    "        # Feature doesn't fit any of the tf example types\n",
    "        else:\n",
    "            raise ValueError('Value of Feature does not fit any of the tf.train.Feature serializable types')\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature)), feature_description\n",
    "\n",
    "\n",
    "def write_tfrecord(df, feature_names, filename='dataset.tfrecord'):\n",
    "    '''\n",
    "    Writes TFRecord file named :param filename: to dataset directory, and generates the corresponding \n",
    "    feature_description dictionary mapping a sample's feature name to the data type description of that\n",
    "    feature.\n",
    "    \n",
    "    :param df: pd.DataFrame, containing data and refrences to data that needs to be written to disk\n",
    "    :param feature_names, list of strings, a subset of the names of columns of df, that represents which subset\n",
    "                          of features from our preprocessed DataFrame that will be considered for modeling\n",
    "    :param filename: string, name of TFRecord file\n",
    "    \n",
    "    ---> dict, of names of features mapping to tf.io.VarLenFeature and tf.io.FixedLenFeature objects\n",
    "    '''\n",
    "    \n",
    "    def unpack_doclist(doclist_string):\n",
    "        '''\n",
    "        Takes a json format string that when loaded contains a list of paths to encoded document pickle files, and\n",
    "        returns a list of the objects loaded from these pickle files.\n",
    "        \n",
    "        :param doclist_string: string, json formated, contain a list of paths to encoded document pickle files\n",
    "        \n",
    "        ---> list, of encoded documents\n",
    "        '''\n",
    "        \n",
    "        def load_file(filename):\n",
    "            '''\n",
    "            Takes a path to a pickle file, and returns the loaded object.\n",
    "            \n",
    "            :param filename: string, path to pickle file\n",
    "            \n",
    "            ---> python object loaded file located at :param filename:\n",
    "            '''\n",
    "            \n",
    "            with open(filename, 'rb') as f:\n",
    "                doc = pickle.load(f)\n",
    "            return doc\n",
    "        \n",
    "        return list(map(load_file, json.loads(doclist_string)))\n",
    "    \n",
    "    with tf.io.TFRecordWriter(os.path.join(path_to_data, filename)) as writer:\n",
    "        print('Writing TFRecord file to: {}'.format(os.path.join(path_to_data, filename)))\n",
    "        for i in range(len(df)-1, -1, -1):\n",
    "            row = df.iloc[i].copy(deep=True)\n",
    "            # Unpacking Text Features\n",
    "            row[['_'.join(['docs', t]) for t in tickers]] = row[['_'.join(['docs', t]) for t in tickers]].map(unpack_doclist)\n",
    "            # Serializing Example to disk\n",
    "            example, feature_description = serialize_example(row, feature_names)\n",
    "            writer.write(example.SerializeToString())\n",
    "    print('Finished writing TFRecord file.')\n",
    "\n",
    "    return feature_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features we will be considering for analysis are: log_adj_daily_returns_WFC, log_adj_daily_returns_JPM, log_adj_daily_returns_BAC, log_adj_daily_returns_C, docs_WFC, docs_JPM, docs_BAC, docs_C\n",
      "\n",
      "Writing TFRecord file to: /media/Data/Programs/FinTech/data/dataset.tfrecord\n",
      "Finished writing TFRecord file.\n"
     ]
    }
   ],
   "source": [
    "# Writing TFRecord file\n",
    "\n",
    "# Defining the subset of features from our preprocessed DataFrame that we will be using for modeling\n",
    "feature_names = ['_'.join([feature, t]) for feature in ['log_adj_daily_returns', 'docs'] for t in tickers]\n",
    "print('The features we will be considering for analysis are: {}'.format(', '.join(feature_names)))\n",
    "print()\n",
    "# Loading the preprocessed DataFrame from disk if it has not been instantiated\n",
    "try:\n",
    "    preprocessed_df\n",
    "except:\n",
    "    preprocessed_df = pd.read_csv(os.path.join(path_to_data, 'preprocessed.csv'), parse_dates=['timestamp'])\n",
    "# Writing the TFRecord file\n",
    "feature_description = write_tfrecord(preprocessed_df, feature_names)\n",
    "# Writing the TFRecord's feature_description object to disk\n",
    "with open(os.path.join(path_to_data, 'dataset_feature_description.pickle'), 'wb') as f:\n",
    "    pickle.dump(feature_description, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook we will be using only the bare minimum amount of features for modeling ie: our text features listed in the doc columns and the feature we are trying to predict in time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 2458s 154s/sample - loss: 0.2878\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 2158s 135s/sample - loss: 0.0603\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 1987s 124s/sample - loss: 0.1277\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 2019s 126s/sample - loss: 0.0161\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 2026s 127s/sample - loss: 0.0145\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 2171s 136s/sample - loss: 0.0319\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 2116s 132s/sample - loss: 0.0158\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 2150s 134s/sample - loss: 0.0013\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 2187s 137s/sample - loss: 0.0047\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 2142s 134s/sample - loss: 0.0105\n",
      "\n",
      "Metrics for model trained on zeroed features.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = sample_dataset(train_dataset, sample_size=1.0, seed=seed)\n",
    "#X_train, y_train = train_dataset\n",
    "X_null = null_features(X)\n",
    "#X_train_null = null_features(X_train)\n",
    "#manually splitting\n",
    "X_small = {fname: X[fname][0:16, :] for fname in X}\n",
    "y_small = {fnamey: y[fnamey][0:16] for fnamey in y}\n",
    "X_small_null = null_features(X_small)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "output_bias_init = 0.0\n",
    "hparams = {'output_bias_init': output_bias_init}\n",
    "\n",
    "m = build_compiled_model(model_0, hparams, loss=LOSS, optimizer=OPTIMIZER, metrics=METRICS)\n",
    "m_history = m.fit(X_small_null, y_small, batch_size=batch_size, epochs=epochs)\n",
    "#m_results = m.evaluate(X, y, batch_size=batch_size, verbose=0)\n",
    "\n",
    "print()\n",
    "print('Metrics for model trained on zeroed features.')\n",
    "print()\n",
    "#print('Loss for Model: {}'.format(m_results))\n",
    "print()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_results = m.evaluate(X_small, y_small, batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model trained on zeroed features.\n",
      "\n",
      "Loss for Model: 0.012423759326338768\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for model trained on zeroed features.')\n",
    "print()\n",
    "print('Loss for Model: {}'.format(m_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/Data/Programs/FinTech/env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: m0_default_E10_B8_train_on_null16/assets\n"
     ]
    }
   ],
   "source": [
    "m.save('m0_default_E10_B8_train_on_null16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012423759326338768\n"
     ]
    }
   ],
   "source": [
    "test_m = tf.keras.models.load_model('m0_default_E10_B8_train_on_null16')\n",
    "print(test_m.evaluate([X_small['docs'], X_small['log_adj_daily_returns']], y_small['log_adj_daily_returns_target'], batch_size=batch_size, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
